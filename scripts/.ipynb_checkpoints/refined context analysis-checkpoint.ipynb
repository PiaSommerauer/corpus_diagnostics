{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze based on semantic categories\n",
    "\n",
    "1.) change tfidf so we compare equivalent categories only - done\n",
    "2.) update ranking accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1446\n",
      "1636\n"
     ]
    }
   ],
   "source": [
    "f_original = os.listdir('../contexts/giga_full/vocab')\n",
    "print(len(f_original))\n",
    "f_update = os.listdir('../contexts/giga_full_updated/vocab')\n",
    "print(len(f_update))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1669\n",
      "1874\n"
     ]
    }
   ],
   "source": [
    "f_original = os.listdir('../contexts/wiki/vocab')\n",
    "print(len(f_original))\n",
    "f_update = os.listdir('../contexts/wiki_updated/vocab')\n",
    "print(len(f_update))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories(prop, model_name):\n",
    "    analysis_type = 'tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    path_dir = f'../results/{model_name}/{analysis_type}'\n",
    "    path_dir = f'{path_dir}/{prop}'\n",
    "    categories = set()\n",
    "    for d in os.listdir(path_dir):\n",
    "        categories.add(d)\n",
    "    return categories\n",
    "\n",
    "def get_context_cnts(prop, cat, label, model_name):\n",
    "    \n",
    "    analysis_type = 'tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    path_dir = f'../results/{model_name}/{analysis_type}'\n",
    "    path_dir = f'{path_dir}/{prop}'\n",
    "    path_label = f'{path_dir}/{cat}/{label}'\n",
    "    \n",
    "    context_cnt = Counter()\n",
    "    for f in os.listdir(path_label):\n",
    "        full_path = f'{path_label}/{f}'\n",
    "        if full_path.endswith('.csv'):\n",
    "            with open(full_path) as infile:\n",
    "                data = list(csv.DictReader(infile))\n",
    "            for d in data:\n",
    "                context = d['']\n",
    "                diff = float(d['diff'])\n",
    "                if diff > 0:\n",
    "                    context_cnt[context] += 1\n",
    "    return context_cnt\n",
    "    \n",
    "def get_n_concepts_total(prop, cat, model_name):\n",
    "    \n",
    "    analysis_type = 'tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    path_dir = f'../results/{model_name}/{analysis_type}'\n",
    "    path_dir = f'{path_dir}/{prop}'\n",
    "    label = 'pos'\n",
    "    path_pos = f'{path_dir}/{cat}/{label}'\n",
    "    label = 'neg'\n",
    "    path_neg = f'{path_dir}/{cat}/{label}'\n",
    "    \n",
    "    files_pos = [f for f in os.listdir(path_pos) if f.endswith('.csv')]\n",
    "    files_neg = [f for f in os.listdir(path_neg) if f.endswith('.csv')]\n",
    "    \n",
    "    return len(files_pos), len(files_neg)\n",
    "\n",
    "def get_f1_distinctiveness(n_pos, n_neg, total_pos, total_neg):\n",
    "    \n",
    "   \n",
    "    total_instances = total_pos + total_neg\n",
    "    labels = []\n",
    "    [labels.append('pos') for i in range(total_pos)]\n",
    "    [labels.append('neg') for i in range(total_neg)]\n",
    "    pred_labels_pos = []\n",
    "    for i in range(total_pos):\n",
    "        if i < n_pos:\n",
    "            pred_labels_pos.append('pos')\n",
    "        else:\n",
    "            pred_labels_pos.append('neg')\n",
    "#     print(n_pos, total_pos)\n",
    "#     print(pred_labels_pos.count('pos'), pred_labels_pos.count('neg'))\n",
    "    \n",
    "    pred_labels_neg = []\n",
    "    for i in range(total_neg):\n",
    "        if i < n_neg:\n",
    "            pred_labels_neg.append('pos')\n",
    "        else:\n",
    "            pred_labels_neg.append('neg')\n",
    "#     print(n_neg, total_neg)\n",
    "#     print(pred_labels_neg.count('pos'), pred_labels_neg.count('neg'))\n",
    "    \n",
    "    predictions = pred_labels_pos + pred_labels_neg\n",
    "    \n",
    "    \n",
    "    #print(len(labels), len(predictions))\n",
    "    #print(pos_predictions, neg_predictions)\n",
    "    \n",
    "    p, r, f1, supp = precision_recall_fscore_support(labels, predictions, average = 'weighted', \n",
    "                                                     zero_division=0)\n",
    "    #average='weighted'\n",
    "    \n",
    "    return p, r, f1\n",
    "\n",
    "\n",
    "    \n",
    "def aggregate_contexts(prop, cutoff, model_name):\n",
    "    aggregation_name = 'aggregated-tfidf-raw-10000-categories'\n",
    "    path_dir_agg = f'../analysis/{model_name}/{aggregation_name}/{prop}'\n",
    "    os.makedirs(path_dir_agg, exist_ok = True)\n",
    "    \n",
    "    context_cnts_all = Counter()\n",
    "    context_cat_dict = defaultdict(set)\n",
    "\n",
    "    cats = get_categories(prop, model_name)\n",
    "\n",
    "    for cat in cats:\n",
    "        context_cnts_pos = get_context_cnts(prop, cat, 'pos', model_name)\n",
    "        context_cnts_neg = get_context_cnts(prop, cat, 'neg', model_name)\n",
    "        total_pos, total_neg = get_n_concepts_total(prop, cat, model_name)\n",
    "        \n",
    "        context_f1_dict = Counter()\n",
    "        context_score_dict = defaultdict(dict)\n",
    "        \n",
    "        # get distinctiveness\n",
    "        for c, cnt_pos in context_cnts_pos.most_common():\n",
    "            cnt_neg = context_cnts_neg[c]\n",
    "            p, r, f1 = get_f1_distinctiveness(cnt_pos, cnt_neg, total_pos, total_neg)\n",
    "            context_f1_dict[c] = f1\n",
    "            context_score_dict[c] = {'p': p,'r':r, 'f1': f1}\n",
    "        \n",
    "        table = []\n",
    "        for c, f1 in context_f1_dict.most_common():\n",
    "            scores = context_score_dict[c]\n",
    "            d = dict()\n",
    "            d['context'] = c\n",
    "            d.update(scores)\n",
    "            d['n_pos'] = context_cnts_pos[c]\n",
    "            d['total_pos'] = total_pos\n",
    "            d['n_neg'] = context_cnts_neg[c]\n",
    "            d['total_neg'] = total_neg\n",
    "            table.append(d)\n",
    "        \n",
    "        # collect and write to file\n",
    "        f = f'{path_dir_agg}/{cat}.csv'\n",
    "        \n",
    "        header = table[0].keys()\n",
    "        with open(f, 'w') as outfile:\n",
    "            writer = csv.DictWriter(outfile, fieldnames = header)\n",
    "            writer.writeheader()\n",
    "            for d in table:\n",
    "                writer.writerow(d)\n",
    "        \n",
    "                \n",
    "def prepare_annotation(prop, model_name, cutoff=3, cutoff_concepts = 5):\n",
    "    \n",
    "    annotation_name = f'annotation-tfidf-top_{cutoff}_{cutoff_concepts}-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    os.makedirs(path_dir_annotation, exist_ok = True)\n",
    "    f_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}/annotation-updated.csv'\n",
    "    \n",
    "    # paths aggregated files:\n",
    "    aggregation_name = 'aggregated-tfidf-raw-10000-categories'\n",
    "    path_dir_agg = f'../analysis/{model_name}/{aggregation_name}/{prop}'\n",
    "\n",
    "    \n",
    "    # get categories\n",
    "    cats = get_categories(prop, model_name)\n",
    "    \n",
    "    # collect all contexts and categories \n",
    "    context_cats_dict = defaultdict(set)\n",
    "    \n",
    "    # load top per category\n",
    "    for cat in cats:\n",
    "        path = f'{path_dir_agg}/{cat}.csv'\n",
    "        with open(path) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "        # sort by f1\n",
    "        f1_dict  = defaultdict(list)\n",
    "        for d in data:\n",
    "            f1 = d['f1']\n",
    "            f1_dict[f1].append(d)\n",
    "        scores = sorted(list(f1_dict.keys()), reverse=True)\n",
    "        top_scores = scores[:cutoff]\n",
    "        top_context_dicts = []\n",
    "        for ts in top_scores:\n",
    "            dicts = f1_dict[ts]\n",
    "            for d in dicts:\n",
    "                n_pos = int(d['n_pos'])\n",
    "                if n_pos > cutoff_concepts:\n",
    "                    top_context_dicts.append(d)\n",
    "    \n",
    "        contexts = [d['context'] for d in top_context_dicts]\n",
    "        # record categories\n",
    "        for c in contexts:\n",
    "            context_cats_dict[c].add(cat)\n",
    "    \n",
    "    with open(f_annotation, 'w') as outfile:\n",
    "        outfile.write('context,evidence_type,categories\\n')\n",
    "        for c, cats in context_cats_dict.items():\n",
    "            outfile.write(f'{c}, ,{\" \".join(cats)}\\n')\n",
    "\n",
    "def get_properties():\n",
    "    properties = []\n",
    "    for path in os.listdir('../data/aggregated/'):\n",
    "        prop = path.split('.')[0]\n",
    "        if 'female-' not in prop and prop != '':\n",
    "            properties.append(prop)\n",
    "    return properties\n",
    "\n",
    "def get_top_distinctive_contexts(properties, model_name, top_cutoff=3, concept_cutoff=3):\n",
    "    aggregation_name = 'aggregated-tfidf-raw-10000-categories'\n",
    "    ann_name = f'annotation-tfidf-top_{top_cutoff}_{concept_cutoff}-raw-10000-categories'\n",
    "    path_results = f'../results/{model_name}/tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    table = []\n",
    "    for prop in properties:\n",
    "        path_dir_agg = f'../analysis/{model_name}/{aggregation_name}/{prop}'\n",
    "        path = path = f'{path_dir_agg}/all.csv'\n",
    "        # load file containing all contexts\n",
    "        with open(path) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "        # top distinctive context\n",
    "        d_prop = dict()\n",
    "        d_prop['property'] = prop\n",
    "        # sort data by f1\n",
    "        f1_dict = defaultdict(list)\n",
    "        for d in data:\n",
    "            f1 = d['f1']\n",
    "            f1_dict[f1].append(d)\n",
    "            \n",
    "        # get n extracted candidates\n",
    "        f_ann =  f'../analysis/{model_name}/{ann_name}/{prop}/annotation-updated.csv'\n",
    "        with open(f_ann) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "        n_contexts = len(data)\n",
    "        \n",
    "        # get number concepts\n",
    "        dir_results = f'{path_results}/{prop}/all/pos/'\n",
    "        n_files = len([f for f in os.listdir(dir_results) if f.endswith('.csv')])\n",
    "        \n",
    "        top_score = max(list(f1_dict.keys()))\n",
    "        top_dicts = f1_dict[top_score]\n",
    "        top_context_dict = top_dicts[0]\n",
    "        top_contexts = ' '.join([d['context'] for d in top_dicts])\n",
    "        d_prop['n_contexts'] = n_contexts\n",
    "        d_prop['n_concepts'] = n_files\n",
    "\n",
    "        for k, v in top_context_dict.items():\n",
    "            if k != 'context':\n",
    "                v = float(v)\n",
    "                d_prop[k] = v\n",
    "        d_prop['contexts'] = top_contexts\n",
    "        table.append(d_prop)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square\n",
      "warm\n",
      "black\n",
      "red\n",
      "fly\n",
      "wings\n",
      "sweet\n",
      "hot\n",
      "used_in_cooking\n",
      "juicy\n",
      "green\n",
      "made_of_wood\n",
      "blue\n",
      "yellow\n",
      "roll\n",
      "female\n",
      "round\n",
      "wheels\n",
      "swim\n"
     ]
    }
   ],
   "source": [
    "model_name = 'giga_full_updated'\n",
    "properties = get_properties()\n",
    "properties_test = ['dangerous', 'cold', 'lay_eggs']\n",
    "properties = [p for p in properties if p not in properties_test]\n",
    "#properties = properties_test\n",
    "cutoff = 3\n",
    "cutoff_concepts = 3\n",
    "\n",
    "for prop in properties:\n",
    "    print(prop)\n",
    "    aggregate_contexts(prop, cutoff, model_name)\n",
    "    prepare_annotation(prop, model_name, cutoff, cutoff_concepts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property</th>\n",
       "      <th>n_contexts</th>\n",
       "      <th>n_concepts</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f1</th>\n",
       "      <th>n_pos</th>\n",
       "      <th>total_pos</th>\n",
       "      <th>n_neg</th>\n",
       "      <th>total_neg</th>\n",
       "      <th>contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>used_in_cooking</td>\n",
       "      <td>572</td>\n",
       "      <td>101</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>93.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>add recipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fly</td>\n",
       "      <td>952</td>\n",
       "      <td>44</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>29.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>flew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>square</td>\n",
       "      <td>1504</td>\n",
       "      <td>87</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "      <td>70.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>built</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lay_eggs</td>\n",
       "      <td>74</td>\n",
       "      <td>33</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>20.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>female</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>77.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>herself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sweet</td>\n",
       "      <td>35</td>\n",
       "      <td>91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>65.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dangerous</td>\n",
       "      <td>1114</td>\n",
       "      <td>65</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>45.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>killed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>blue</td>\n",
       "      <td>2234</td>\n",
       "      <td>59</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "      <td>31.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>magic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wings</td>\n",
       "      <td>560</td>\n",
       "      <td>60</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>36.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>wheels</td>\n",
       "      <td>244</td>\n",
       "      <td>70</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.80</td>\n",
       "      <td>51.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>drove wheel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>juicy</td>\n",
       "      <td>810</td>\n",
       "      <td>88</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>58.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>pineapple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cold</td>\n",
       "      <td>1081</td>\n",
       "      <td>68</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>48.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>variety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>green</td>\n",
       "      <td>578</td>\n",
       "      <td>89</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>59.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>roll</td>\n",
       "      <td>3886</td>\n",
       "      <td>52</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>34.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>half</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>swim</td>\n",
       "      <td>1381</td>\n",
       "      <td>81</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>53.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>yellow</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.76</td>\n",
       "      <td>22.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>warm</td>\n",
       "      <td>2108</td>\n",
       "      <td>124</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>81.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>heavy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>black</td>\n",
       "      <td>1149</td>\n",
       "      <td>79</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>49.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hot</td>\n",
       "      <td>84</td>\n",
       "      <td>100</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.74</td>\n",
       "      <td>62.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>flame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>round</td>\n",
       "      <td>520</td>\n",
       "      <td>97</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.74</td>\n",
       "      <td>62.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>annual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>red</td>\n",
       "      <td>1767</td>\n",
       "      <td>87</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>46.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>burst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>made_of_wood</td>\n",
       "      <td>786</td>\n",
       "      <td>80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>46.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>wooden</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           property  n_contexts  n_concepts     p     r    f1  n_pos  \\\n",
       "9   used_in_cooking         572         101  0.96  0.95  0.95   93.0   \n",
       "4               fly         952          44  0.88  0.87  0.87   29.0   \n",
       "0            square        1504          87  0.91  0.84  0.86   70.0   \n",
       "20         lay_eggs          74          33  0.86  0.84  0.83   20.0   \n",
       "16           female          45         109  0.85  0.84  0.83   77.0   \n",
       "7             sweet          35          91  0.87  0.82  0.83   65.0   \n",
       "5         dangerous        1114          65  0.86  0.82  0.82   45.0   \n",
       "13             blue        2234          59  0.87  0.83  0.81   31.0   \n",
       "6             wings         560          60  0.85  0.82  0.81   36.0   \n",
       "19           wheels         244          70  0.87  0.79  0.80   51.0   \n",
       "10            juicy         810          88  0.86  0.80  0.80   58.0   \n",
       "17             cold        1081          68  0.88  0.78  0.80   48.0   \n",
       "11            green         578          89  0.85  0.79  0.79   59.0   \n",
       "15             roll        3886          52  0.84  0.78  0.78   34.0   \n",
       "21             swim        1381          81  0.85  0.76  0.76   53.0   \n",
       "14           yellow          52          43  0.78  0.78  0.76   22.0   \n",
       "1              warm        2108         124  0.87  0.72  0.75   81.0   \n",
       "2             black        1149          79  0.83  0.74  0.74   49.0   \n",
       "8               hot          84         100  0.86  0.73  0.74   62.0   \n",
       "18            round         520          97  0.90  0.70  0.74   62.0   \n",
       "3               red        1767          87  0.79  0.71  0.70   46.0   \n",
       "12     made_of_wood         786          80  0.82  0.68  0.69   46.0   \n",
       "\n",
       "    total_pos  n_neg  total_neg     contexts  \n",
       "9       101.0    0.0       56.0   add recipe  \n",
       "4        44.0    2.0       90.0         flew  \n",
       "0        87.0    0.0       21.0        built  \n",
       "20       33.0    1.0       57.0         eggs  \n",
       "16      109.0    9.0      144.0      herself  \n",
       "7        91.0    1.0       63.0        sweet  \n",
       "5        65.0    1.0       51.0       killed  \n",
       "13       59.0    0.0      106.0        magic  \n",
       "6        60.0    1.0       77.0         bird  \n",
       "19       70.0    1.0       25.0  drove wheel  \n",
       "10       88.0    0.0       60.0    pineapple  \n",
       "17       68.0    0.0       24.0      variety  \n",
       "11       89.0    2.0       67.0        green  \n",
       "15       52.0    1.0       33.0         half  \n",
       "21       81.0    1.0       38.0         fish  \n",
       "14       43.0    5.0       74.0       yellow  \n",
       "1       124.0    1.0       32.0        heavy  \n",
       "2        79.0    2.0       45.0         fire  \n",
       "8       100.0    0.0       43.0        flame  \n",
       "18       97.0    0.0       18.0       annual  \n",
       "3        87.0    3.0       64.0        burst  \n",
       "12       80.0    2.0       33.0       wooden  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get top distinctive contexts per prop\n",
    "\n",
    "model_name = 'giga_full_updated'\n",
    "properties = get_properties()\n",
    "table = get_top_distinctive_contexts(properties, model_name)\n",
    "df = pd.DataFrame(table)\n",
    "df.sort_values('f1', ascending = False).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrl}\n",
      "\\toprule\n",
      "        property &  n\\_concepts &  n\\_contexts &    f1 &     contexts \\\\\n",
      "\\midrule\n",
      " used\\_in\\_cooking &         101 &         572 &  0.95 &   add recipe \\\\\n",
      "             fly &          44 &         952 &  0.87 &         flew \\\\\n",
      "          square &          87 &        1504 &  0.86 &        built \\\\\n",
      "        lay\\_eggs &          33 &          74 &  0.83 &         eggs \\\\\n",
      "          female &         109 &          45 &  0.83 &      herself \\\\\n",
      "           sweet &          91 &          35 &  0.83 &        sweet \\\\\n",
      "       dangerous &          65 &        1114 &  0.82 &       killed \\\\\n",
      "            blue &          59 &        2234 &  0.81 &        magic \\\\\n",
      "           wings &          60 &         560 &  0.81 &         bird \\\\\n",
      "           juicy &          88 &         810 &  0.80 &    pineapple \\\\\n",
      "            cold &          68 &        1081 &  0.80 &      variety \\\\\n",
      "          wheels &          70 &         244 &  0.80 &  drove wheel \\\\\n",
      "           green &          89 &         578 &  0.79 &        green \\\\\n",
      "            roll &          52 &        3886 &  0.78 &         half \\\\\n",
      "            swim &          81 &        1381 &  0.76 &         fish \\\\\n",
      "          yellow &          43 &          52 &  0.76 &       yellow \\\\\n",
      "            warm &         124 &        2108 &  0.75 &        heavy \\\\\n",
      "           black &          79 &        1149 &  0.74 &         fire \\\\\n",
      "             hot &         100 &          84 &  0.74 &        flame \\\\\n",
      "           round &          97 &         520 &  0.74 &       annual \\\\\n",
      "             red &          87 &        1767 &  0.70 &        burst \\\\\n",
      "    made\\_of\\_wood &          80 &         786 &  0.69 &       wooden \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# latex table for paper:\n",
    "cols = ['property', 'n_concepts', 'n_contexts', 'f1', 'contexts']\n",
    "df = df.sort_values('f1', ascending = False).round(2)\n",
    "print(df[cols].to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top distinctive contexts per prop\n",
    "\n",
    "# model_name = 'wiki_updated'\n",
    "# properties = get_properties()\n",
    "# table = get_top_distinctive_contexts(properties, model_name)\n",
    "# df = pd.DataFrame(table)\n",
    "# df.sort_values('f1', ascending = False).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer old annotations to new files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_properties' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fe648754263e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mproperties\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_name_current\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'giga_full_updated'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_name_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'giga_full'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_properties' is not defined"
     ]
    }
   ],
   "source": [
    "properties = get_properties()\n",
    "model_name_current = 'giga_full_updated'\n",
    "model_name_old = 'giga_full'\n",
    "\n",
    "\n",
    "for prop in properties:\n",
    "    # current file:\n",
    "    annotation_name = 'annotation-tfidf-top20-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    f_annotation_new = f'{path_dir_annotation}/annotation.csv'\n",
    "    f_annotation_tr = f'{path_dir_annotation}/annotation-transferred.csv'\n",
    "\n",
    "    # old file:\n",
    "    annotation_name = 'annotation-tfidf-top20-raw-10000'\n",
    "    path_dir_annotation = f'../analysis/{model_name_old}/{annotation_name}/{prop}-pos'\n",
    "    f_annotation_old = f'{path_dir_annotation}/annotation-done.csv'\n",
    "\n",
    "    # load old annotations\n",
    "    context_annotation_dict=dict()\n",
    "    with open(f_annotation_old) as infile:\n",
    "        data = list(csv.DictReader(infile))\n",
    "        for d in data:\n",
    "            c = d['context']\n",
    "            et = d['evidence']\n",
    "            context_annotation_dict[c] = et\n",
    "            #c = d['context']\n",
    "\n",
    "    # load new candidates\n",
    "\n",
    "    with open(f_annotation_new) as infile:\n",
    "        data = list(csv.DictReader(infile))\n",
    "\n",
    "    # fill in old annotations\n",
    "    for d in data:\n",
    "        c = d['context']\n",
    "        if c in context_annotation_dict:\n",
    "            et = context_annotation_dict[c]\n",
    "        else:\n",
    "            et = 'NA'\n",
    "        d['evidence_type'] = et\n",
    "\n",
    "    # write to new file\n",
    "\n",
    "    with open(f_annotation_tr, 'w') as outfile:\n",
    "        writer = csv.DictWriter(outfile, fieldnames = data[0].keys())\n",
    "        writer.writeheader()\n",
    "        for d in data:\n",
    "            writer.writerow(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found file\n",
      "found file\n",
      "found file\n"
     ]
    }
   ],
   "source": [
    "# transfer new annotations to updated f1 scores\n",
    "\n",
    "properties = get_properties()\n",
    "#properties = ['dangerous']\n",
    "model_name_current = 'giga_full_updated'\n",
    "model_name_old = 'giga_full'\n",
    "\n",
    "\n",
    "for prop in properties:\n",
    "    # current file:\n",
    "    annotation_name = 'annotation-tfidf-top_3_3-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    f_annotation_new = f'{path_dir_annotation}/annotation-updated.csv'\n",
    "    f_annotation_tr = f'{path_dir_annotation}/annotation-transferred-updated.csv'\n",
    "\n",
    "    # old file:\n",
    "    annotation_name = 'annotation-tfidf-top_3_5-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    f_annotation_old = f'{path_dir_annotation}/annotation-updated-done.csv'\n",
    "\n",
    "    # load old annotations\n",
    "    if os.path.isfile(f_annotation_old):\n",
    "        print('found file')\n",
    "        context_annotation_dict=dict()\n",
    "        with open(f_annotation_old) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "            for d in data:\n",
    "                c = d['context']\n",
    "                et = d['evidence_type']\n",
    "                context_annotation_dict[c] = et\n",
    "                #c = d['context']\n",
    "\n",
    "        # load new candidates\n",
    "\n",
    "        with open(f_annotation_new) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "\n",
    "        # fill in old annotations\n",
    "        for d in data:\n",
    "            c = d['context']\n",
    "            if c in context_annotation_dict:\n",
    "                et = context_annotation_dict[c]\n",
    "            else:\n",
    "                et = 'NA'\n",
    "            d['evidence_type'] = et\n",
    "\n",
    "        # write to new file\n",
    "\n",
    "        with open(f_annotation_tr, 'w') as outfile:\n",
    "            writer = csv.DictWriter(outfile, fieldnames = data[0].keys())\n",
    "            writer.writeheader()\n",
    "            for d in data:\n",
    "                writer.writerow(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotation_status(model_name, top_cutoff, concept_cutoff):\n",
    "    dir_path = f'../analysis/{model_name}'\n",
    "    dir_annotations = f'{dir_path}/annotation-tfidf-top_{top_cutoff}_{concept_cutoff}-raw-10000-categories'\n",
    "    annotation_dict = defaultdict(set)\n",
    "    line_dict = dict()\n",
    "\n",
    "    for f in os.listdir(dir_annotations):\n",
    "        if  not f.endswith('.csv') and not f.endswith('.ipynb_checkpoints'):\n",
    "            prop = f.split('/')[-1]\n",
    "            full_path = f'{dir_annotations}/{f}'\n",
    "            \n",
    "            #print(full_path)\n",
    "            # get categories:\n",
    "            files = os.listdir(full_path)\n",
    "            # get number of words\n",
    "            path_file = f'{full_path}/annotation-updated.csv'\n",
    "            with open(path_file) as infile:\n",
    "                lines = infile.read().strip().split('\\n')\n",
    "            line_dict[prop] = len(lines)\n",
    "            if 'annotation-updated-done.csv' in files:\n",
    "                annotation_dict['complete'].add(prop)\n",
    "            else:\n",
    "                annotation_dict['incomplete'].add(prop)\n",
    "                \n",
    "    return annotation_dict, line_dict\n",
    "\n",
    "def show_annotation_status(model_name, top_cutoff, concept_cutoff):\n",
    "    annotation_dict, line_dict = get_annotation_status(model_name, \n",
    "                                        top_cutoff, concept_cutoff)\n",
    "    # same category not annotated:\n",
    "    print('completed:\\n')\n",
    "    for prop in sorted(list(annotation_dict['complete'])):\n",
    "        # cats open:\n",
    "        print(prop, line_dict[prop])\n",
    "    print()\n",
    "    print('Incomplete:\\n')\n",
    "    for prop in sorted(annotation_dict['incomplete']):\n",
    "        if prop not in annotation_dict['complete']:\n",
    "            print(prop, line_dict[prop])\n",
    "    return annotation_dict\n",
    "            \n",
    "            \n",
    "def get_evidence_dict(model_name, prop, top_cutoff, concept_cutoff):\n",
    "    \n",
    "    annotation_name = f'annotation-tfidf-top_{top_cutoff}_{concept_cutoff}-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    f_annotation = f'{path_dir_annotation}/annotation-updated-done.csv'\n",
    "    \n",
    "    ev_dict = dict()\n",
    "    \n",
    "    with open(f_annotation) as infile:\n",
    "        data = list(csv.DictReader(infile))\n",
    "    for d in data:\n",
    "        et = d['evidence_type']\n",
    "        ev = d['context']\n",
    "        ev_dict[ev] = et\n",
    "    return ev_dict\n",
    "        \n",
    "            \n",
    "\n",
    "def get_evidence_distribution(model_name, prop, top_cutoff, concept_cutoff):\n",
    "    \n",
    "    # current file:\n",
    "    annotation_name = f'annotation-tfidf-top_{top_cutoff}_{concept_cutoff}-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    f_annotation = f'{path_dir_annotation}/annotation-updated-done.csv'\n",
    "    \n",
    "    ev_dict = get_evidence_dict(model_name, prop, top_cutoff, concept_cutoff)\n",
    "    \n",
    "    ev_cnts = Counter()\n",
    "    \n",
    "    for e, et in ev_dict.items():\n",
    "        ev_cnts[et] += 1\n",
    "        if et != 'u':\n",
    "            ev_cnts['all'] += 1\n",
    "        if et in ['p', 'l', 'n']:\n",
    "            ev_cnts['prop_specific'] += 1\n",
    "        elif et in ['i', 'r', 'b']:\n",
    "            ev_cnts['non-specific'] += 1\n",
    "    \n",
    "    total_contexts = len(ev_dict)\n",
    "    \n",
    "    ev_counts_norm = dict()\n",
    "    for ev, cnt in ev_cnts.items():\n",
    "        ev_counts_norm[ev]  = cnt/total_contexts\n",
    "    return ev_counts_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed:\n",
      "\n",
      "black 1150\n",
      "blue 2235\n",
      "cold 1082\n",
      "dangerous 1115\n",
      "female 46\n",
      "fly 953\n",
      "green 579\n",
      "hot 85\n",
      "juicy 811\n",
      "lay_eggs 75\n",
      "made_of_wood 787\n",
      "red 1768\n",
      "roll 3887\n",
      "round 521\n",
      "square 1505\n",
      "sweet 36\n",
      "swim 1382\n",
      "used_in_cooking 573\n",
      "warm 2109\n",
      "wheels 245\n",
      "wings 561\n",
      "yellow 53\n",
      "\n",
      "Incomplete:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'giga_full_updated'\n",
    "top_cutoff = 3\n",
    "concept_cutoff = 3\n",
    "ann_dict = show_annotation_status(model_name, top_cutoff, concept_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property</th>\n",
       "      <th>u</th>\n",
       "      <th>all</th>\n",
       "      <th>prop_specific</th>\n",
       "      <th>non-specific</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>l</th>\n",
       "      <th>i</th>\n",
       "      <th>r</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>used_in_cooking</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.327</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sweet</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hot</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.095</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lay_eggs</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.095</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>female</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>green</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>wheels</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.094</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wings</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>juicy</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dangerous</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>round</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>yellow</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cold</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.018</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>made_of_wood</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.034</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>red</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.003</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fly</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>warm</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>black</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.007</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>square</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>swim</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.030</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>roll</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           property      u    all  prop_specific  non-specific      p      n  \\\n",
       "4   used_in_cooking  0.357  0.643          0.014         0.629  0.007  0.003   \n",
       "1             sweet  0.400  0.600          0.057         0.543  0.057    NaN   \n",
       "6               hot  0.702  0.298          0.036         0.262  0.024  0.012   \n",
       "7          lay_eggs  0.703  0.297          0.027         0.270  0.027    NaN   \n",
       "21           female  0.711  0.289          0.044         0.244    NaN    NaN   \n",
       "10            green  0.839  0.161          0.002         0.159  0.002    NaN   \n",
       "19           wheels  0.840  0.160          0.016         0.143  0.008    NaN   \n",
       "13            wings  0.848  0.152          0.011         0.139  0.002    NaN   \n",
       "17            juicy  0.880  0.120          0.002         0.117  0.002    NaN   \n",
       "3         dangerous  0.883  0.117          0.021         0.096  0.002  0.006   \n",
       "18            round  0.921  0.079          0.004         0.075  0.002    NaN   \n",
       "20           yellow  0.923  0.077          0.019         0.058  0.019    NaN   \n",
       "2              blue  0.924  0.076          0.001         0.074  0.001    NaN   \n",
       "11             cold  0.935  0.065          0.006         0.057  0.001  0.005   \n",
       "9      made_of_wood  0.941  0.059          0.004         0.055  0.004    NaN   \n",
       "15              red  0.947  0.053          0.001         0.053  0.001    NaN   \n",
       "5               fly  0.947  0.053          0.008         0.044  0.006  0.001   \n",
       "8              warm  0.948  0.052          0.004         0.048  0.002  0.000   \n",
       "14            black  0.956  0.044          0.002         0.043  0.001    NaN   \n",
       "16           square  0.960  0.040            NaN         0.040    NaN    NaN   \n",
       "0              swim  0.960  0.040          0.001         0.038  0.001    NaN   \n",
       "12             roll  0.963  0.037          0.002         0.035  0.001    NaN   \n",
       "\n",
       "        l      i      r      b  \n",
       "4   0.003  0.302  0.327    NaN  \n",
       "1     NaN  0.543    NaN    NaN  \n",
       "6     NaN  0.167  0.095    NaN  \n",
       "7     NaN  0.176  0.095    NaN  \n",
       "21  0.044  0.156  0.022  0.067  \n",
       "10    NaN  0.145  0.014    NaN  \n",
       "19  0.008  0.049  0.094    NaN  \n",
       "13  0.009  0.045  0.068  0.027  \n",
       "17    NaN  0.102  0.015    NaN  \n",
       "3   0.013  0.037  0.054  0.005  \n",
       "18  0.002  0.071  0.004    NaN  \n",
       "20    NaN  0.058    NaN    NaN  \n",
       "2     NaN  0.070  0.004    NaN  \n",
       "11    NaN  0.040  0.018    NaN  \n",
       "9     NaN  0.020  0.034    NaN  \n",
       "15    NaN  0.049  0.003    NaN  \n",
       "5   0.001  0.008  0.033  0.003  \n",
       "8   0.001  0.037  0.010    NaN  \n",
       "14  0.001  0.036  0.007    NaN  \n",
       "16    NaN  0.039  0.001    NaN  \n",
       "0     NaN  0.009  0.030    NaN  \n",
       "12  0.001  0.023  0.011    NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'giga_full_updated'\n",
    "properties = ann_dict['complete']\n",
    "top_cutoff = 3\n",
    "concept_cutoff = 3\n",
    "\n",
    "cols = ['property', 'u', 'all', 'prop_specific', 'non-specific', 'p', 'n', 'l', 'i', 'r', 'b']\n",
    "table = []\n",
    "for prop in properties:\n",
    "    d = dict()\n",
    "    d['property'] =  prop\n",
    "    d.update(get_evidence_distribution(model_name, prop, top_cutoff, concept_cutoff))\n",
    "    for c in cols:\n",
    "        if c not in d:\n",
    "            d[c] = np.nan\n",
    "    table.append(d)\n",
    "   \n",
    "cols = ['property', 'u', 'all', 'prop_specific', 'non-specific', 'p', 'n', 'l', 'i', 'r', 'b']\n",
    "df = pd.DataFrame(table)[cols]\n",
    "df = df[cols].sort_values('all', ascending = False).round(3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.round(3).fillna('-').to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evidence distribution per semantic category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prop_data(prop):\n",
    "    \n",
    "    path = f'../data/aggregated_semantic_info/{prop}.json'\n",
    "    with open(path) as infile:\n",
    "        concept_dict = json.load(infile)\n",
    "    return concept_dict\n",
    "\n",
    "\n",
    "def load_concept_evidence(concept, prop, model_name, categories):\n",
    "    \n",
    "    categories.add('all')\n",
    "    contexts = set()\n",
    "    dir_path = f'../results/{model_name}/tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    \n",
    "    for cat in categories:\n",
    "        f_path = f'{dir_path}/{prop}/{cat}/pos/{concept}.csv'\n",
    "        if os.path.isfile(f_path):\n",
    "            with open(f_path) as infile:\n",
    "                data = list(csv.DictReader(infile))\n",
    "            for d in data:\n",
    "                context = d['']\n",
    "                diff = float(d['diff'])\n",
    "                if diff > 0:\n",
    "                    contexts.add(context)\n",
    "    return contexts  \n",
    "\n",
    "def get_categories(prop, model_name):\n",
    "    analysis_type = 'tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    path_dir = f'../results/{model_name}/{analysis_type}'\n",
    "    path_dir = f'{path_dir}/{prop}'\n",
    "    categories = set()\n",
    "    for d in os.listdir(path_dir):\n",
    "        if '.' not in d:\n",
    "            categories.add(d)\n",
    "    return categories\n",
    "\n",
    "\n",
    "def get_top_ev_categories(prop, model_name, top_cutoff, concept_cutoff):\n",
    "    table = dict()\n",
    "    aggregation_name = f'aggregated-tfidf-raw-10000-categories'\n",
    "    categories = get_categories(prop, model_name)\n",
    "    \n",
    "    path_dir_agg = f'../analysis/{model_name}/{aggregation_name}/{prop}'\n",
    "    evidence_dict = get_evidence_dict(model_name, prop, top_cutoff, concept_cutoff)\n",
    "    \n",
    "    et_context_dict = defaultdict(set)\n",
    "    for c, et in evidence_dict.items():\n",
    "        et_context_dict[et].add(c)\n",
    "    \n",
    "    # get top performance per evidence type for each category\n",
    "    for cat in categories:\n",
    "        path = path = f'{path_dir_agg}/{cat}.csv'\n",
    "        # load file containing all concepts and simply load first one\n",
    "        with open(path) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "        # sort by performance:\n",
    "        perf_data = defaultdict(list)\n",
    "        for d in data:\n",
    "            f1 = d['f1']\n",
    "            perf_data[f1].append(d)\n",
    "        perf_ranked = sorted(list(perf_data.keys()), reverse = True)\n",
    "        for et, contexts in et_context_dict.items():\n",
    "            for f1 in perf_ranked:\n",
    "                data = perf_data[f1]\n",
    "                d_perf = dict()\n",
    "                for k, v in d.items():\n",
    "                    if k != 'context':\n",
    "                        d_perf[k] = round(float(v), 2)\n",
    "                contexts_ev = set()\n",
    "                for d in data:\n",
    "                    context = d['context']\n",
    "                    if context in contexts:\n",
    "                        contexts_ev.add(context)\n",
    "                if contexts_ev:\n",
    "                    d_perf['n_c'] = len(contexts_ev)\n",
    "                    d_perf['contexts'] = ' '.join(contexts_ev)\n",
    "                    table[(cat, et)] = d_perf\n",
    "                    break\n",
    "                \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f1</th>\n",
       "      <th>n_pos</th>\n",
       "      <th>total_pos</th>\n",
       "      <th>n_neg</th>\n",
       "      <th>total_neg</th>\n",
       "      <th>n_c</th>\n",
       "      <th>contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">plant</th>\n",
       "      <th>u</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>434</td>\n",
       "      <td>contract adam remembers scheduled youth specie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>strokes salmon bass dog fish woman duck birds ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>training sailing wins trophy beach catches lak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>swimming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">no-cat</th>\n",
       "      <th>u</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>walking issuing 75 fully walks focused country...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>fresh beach jumped costume suit blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>swimming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">mammal</th>\n",
       "      <th>u</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.67</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.69</td>\n",
       "      <td>23</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>beach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.31</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>swimming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">object</th>\n",
       "      <th>u</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>40</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>41</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>53</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.42</td>\n",
       "      <td>18</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>39</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>swimming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">bird</th>\n",
       "      <th>u</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>takes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>duck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.74</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.51</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">all</th>\n",
       "      <th>u</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>40</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>41</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>53</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.42</td>\n",
       "      <td>18</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>39</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>swimming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">communication</th>\n",
       "      <th>u</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>294</td>\n",
       "      <td>foot man moment valuable franchise bottom walk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>bass duck boat dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>wins cold trophy beach championship lake lane ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>swimming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">fish</th>\n",
       "      <th>u</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.82</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.33</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.58</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>swimming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">vehicle</th>\n",
       "      <th>u</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1217</td>\n",
       "      <td>natural sold giving universal issuing colin fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>strokes salmon dog fish woman duck birds boat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>training sailing wins competitions catches bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>swimming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">measure</th>\n",
       "      <th>u</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>177</td>\n",
       "      <td>natural scrutiny walking bad walks tests pound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>salmon bass fish duck boat birds animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>cold caught fresh trophy catches race current ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>swimming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">relation</th>\n",
       "      <th>u</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>lion trail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>swimming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">reptile</th>\n",
       "      <th>u</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>foot reportedly eating dragon inspired publish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>race sea island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.77</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>swimming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">food</th>\n",
       "      <th>u</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>bass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.91</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>fishing catch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.31</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.57</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>swimming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">animal</th>\n",
       "      <th>u</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>40</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>41</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>53</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.42</td>\n",
       "      <td>18</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>39</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>swimming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    p     r    f1 n_pos total_pos n_neg total_neg   n_c  \\\n",
       "plant         u  0.83  0.67  0.67     1         1     1         2   434   \n",
       "              i     1     1     1     1         1     0         2    10   \n",
       "              r     1     1     1     1         1     0         2    27   \n",
       "              p  0.83  0.67  0.67     1         1     1         2     1   \n",
       "no-cat        u  0.42  0.17  0.24     1         5     1         1   145   \n",
       "              i     1     1     1     5         5     0         1     1   \n",
       "              r     1     1     1     5         5     0         1     6   \n",
       "                    1     1     1     5         5     0         1     1   \n",
       "              p     1     1     1     5         5     0         1     1   \n",
       "mammal        u  0.11  0.12  0.08     1        38     9        14     1   \n",
       "              i  0.79  0.65  0.67    22        38     2        14     1   \n",
       "              r  0.79  0.67  0.69    23        38     2        14     1   \n",
       "                 0.63  0.48   0.5    16        38     5        14     1   \n",
       "              p  0.43  0.29  0.31     9        38     8        14     1   \n",
       "object        u  0.83  0.66  0.66    40        81     0        38     1   \n",
       "              i  0.78  0.64  0.64    41        81     3        38     1   \n",
       "              r  0.85  0.76  0.76    53        81     1        38     1   \n",
       "                 0.76  0.46  0.42    18        81     1        38     1   \n",
       "              p  0.76  0.61  0.62    39        81     4        38     1   \n",
       "bird          u  0.18  0.14  0.16     1        10    15        18     1   \n",
       "              i  0.86  0.82   0.8     5        10     0        18     1   \n",
       "              r  0.74  0.75  0.74     5        10     2        18     1   \n",
       "                  0.5  0.54  0.51     2        10     5        18     1   \n",
       "all           u  0.83  0.66  0.66    40        81     0        38     1   \n",
       "              i  0.78  0.64  0.64    41        81     3        38     1   \n",
       "              r  0.85  0.76  0.76    53        81     1        38     1   \n",
       "                 0.76  0.46  0.42    18        81     1        38     1   \n",
       "              p  0.76  0.61  0.62    39        81     4        38     1   \n",
       "communication u  0.38  0.25   0.3     1         3     1         1   294   \n",
       "              i     1     1     1     3         3     0         1     4   \n",
       "              r     1     1     1     3         3     0         1    14   \n",
       "                    1     1     1     3         3     0         1     1   \n",
       "              p     1     1     1     3         3     0         1     1   \n",
       "fish          u  0.92  0.82  0.84    22        28     0         5     1   \n",
       "              i  0.91  0.79  0.82    21        28     0         5     1   \n",
       "              r  0.93  0.88  0.89    24        28     0         5     1   \n",
       "                 0.61  0.27  0.33     7        28     3         5     1   \n",
       "              p  0.82  0.52  0.58    13        28     1         5     1   \n",
       "vehicle       u  0.25   0.5  0.33     1         1     1         1  1217   \n",
       "              i     1     1     1     1         1     0         1    10   \n",
       "              r     1     1     1     1         1     0         1    35   \n",
       "                    1     1     1     1         1     0         1     1   \n",
       "              p     1     1     1     1         1     0         1     1   \n",
       "measure       u  0.33  0.33  0.33     1         2     1         1   177   \n",
       "              i     1     1     1     2         2     0         1     7   \n",
       "              r     1     1     1     2         2     0         1     8   \n",
       "                    1     1     1     2         2     0         1     1   \n",
       "              p     1     1     1     2         2     0         1     1   \n",
       "relation      u  0.12   0.1  0.11     1         6     4         4     2   \n",
       "              i     1     1     1     6         6     0         4     1   \n",
       "              r  0.92   0.9   0.9     5         6     0         4     1   \n",
       "                 0.43   0.4   0.4     2         6     2         4     1   \n",
       "              p  0.57   0.5  0.48     2         6     1         4     1   \n",
       "reptile       u  0.38  0.25   0.3     1         3     1         1    67   \n",
       "              i     1     1     1     3         3     0         1     1   \n",
       "              r     1     1     1     3         3     0         1     3   \n",
       "                 0.88  0.75  0.77     2         3     0         1     1   \n",
       "              p     1     1     1     3         3     0         1     1   \n",
       "food          u  0.97  0.97  0.97    25        26     0         4     1   \n",
       "              i  0.96  0.93  0.94    24        26     0         4     1   \n",
       "              r  0.94   0.9  0.91    23        26     0         4     2   \n",
       "                 0.58  0.23  0.31     6        26     3         4     1   \n",
       "              p  0.82   0.5  0.57    12        26     1         4     1   \n",
       "animal        u  0.83  0.66  0.66    40        81     0        38     1   \n",
       "              i  0.78  0.64  0.64    41        81     3        38     1   \n",
       "              r  0.85  0.76  0.76    53        81     1        38     1   \n",
       "                 0.76  0.46  0.42    18        81     1        38     1   \n",
       "              p  0.76  0.61  0.62    39        81     4        38     1   \n",
       "\n",
       "                                                          contexts  \n",
       "plant         u  contract adam remembers scheduled youth specie...  \n",
       "              i  strokes salmon bass dog fish woman duck birds ...  \n",
       "              r  training sailing wins trophy beach catches lak...  \n",
       "              p                                           swimming  \n",
       "no-cat        u  walking issuing 75 fully walks focused country...  \n",
       "              i                                                dog  \n",
       "              r               fresh beach jumped costume suit blue  \n",
       "                                                              step  \n",
       "              p                                           swimming  \n",
       "mammal        u                                               name  \n",
       "              i                                              woman  \n",
       "              r                                              beach  \n",
       "                                                              step  \n",
       "              p                                           swimming  \n",
       "object        u                                                hot  \n",
       "              i                                               fish  \n",
       "              r                                            fishing  \n",
       "                                                              step  \n",
       "              p                                           swimming  \n",
       "bird          u                                              takes  \n",
       "              i                                               duck  \n",
       "              r                                            fishing  \n",
       "                                                              step  \n",
       "all           u                                                hot  \n",
       "              i                                               fish  \n",
       "              r                                            fishing  \n",
       "                                                              step  \n",
       "              p                                           swimming  \n",
       "communication u  foot man moment valuable franchise bottom walk...  \n",
       "              i                                 bass duck boat dog  \n",
       "              r  wins cold trophy beach championship lake lane ...  \n",
       "                                                              step  \n",
       "              p                                           swimming  \n",
       "fish          u                                            species  \n",
       "              i                                               fish  \n",
       "              r                                            fishing  \n",
       "                                                              step  \n",
       "              p                                           swimming  \n",
       "vehicle       u  natural sold giving universal issuing colin fo...  \n",
       "              i  strokes salmon dog fish woman duck birds boat ...  \n",
       "              r  training sailing wins competitions catches bea...  \n",
       "                                                              step  \n",
       "              p                                           swimming  \n",
       "measure       u  natural scrutiny walking bad walks tests pound...  \n",
       "              i            salmon bass fish duck boat birds animal  \n",
       "              r  cold caught fresh trophy catches race current ...  \n",
       "                                                              step  \n",
       "              p                                           swimming  \n",
       "relation      u                                         lion trail  \n",
       "              i                                               fish  \n",
       "              r                                                sea  \n",
       "                                                              step  \n",
       "              p                                           swimming  \n",
       "reptile       u  foot reportedly eating dragon inspired publish...  \n",
       "              i                                              woman  \n",
       "              r                                    race sea island  \n",
       "                                                              step  \n",
       "              p                                           swimming  \n",
       "food          u                                            species  \n",
       "              i                                               bass  \n",
       "              r                                      fishing catch  \n",
       "                                                              step  \n",
       "              p                                           swimming  \n",
       "animal        u                                                hot  \n",
       "              i                                               fish  \n",
       "              r                                            fishing  \n",
       "                                                              step  \n",
       "              p                                           swimming  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop = 'swim'\n",
    "model_name = 'giga_full_updated'\n",
    "top_cutoff = 3\n",
    "concept_cutoff = 3\n",
    "table = get_top_ev_categories(prop, model_name, top_cutoff, concept_cutoff)\n",
    "\n",
    "df = pd.DataFrame(table)\n",
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evidence strength\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evidence_dict(model_name, prop, top_cutoff, concept_cutoff):\n",
    "    \n",
    "    annotation_name = f'annotation-tfidf-top_{top_cutoff}_{concept_cutoff}-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    f_annotation = f'{path_dir_annotation}/annotation-updated-done.csv'\n",
    "    \n",
    "    ev_dict = dict()\n",
    "    \n",
    "    with open(f_annotation) as infile:\n",
    "        data = list(csv.DictReader(infile))\n",
    "    for d in data:\n",
    "        et = d['evidence_type']\n",
    "        ev = d['context']\n",
    "        ev_dict[ev] = et\n",
    "    return ev_dict\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'crashed': 'u',\n",
       " 'similar': 'u',\n",
       " 'visibility': 'u',\n",
       " 'indicating': 'u',\n",
       " 'hunt': 'u',\n",
       " 'northwest': 'u',\n",
       " 'piloted': 'r',\n",
       " 'propeller': 'r',\n",
       " 'conducting': 'u',\n",
       " 'fighter': 'u',\n",
       " 'fighters': ' ',\n",
       " 'supersonic': 'u',\n",
       " 'pilot': 'r',\n",
       " 'flew': 'l',\n",
       " 'runway': 'u',\n",
       " 'flying': 'l',\n",
       " 'flown': 'l',\n",
       " 'aviation': 'r',\n",
       " 'cockpit': 'r',\n",
       " 'downed': 'r',\n",
       " 'wreckage': 'r',\n",
       " 'peruvian': 'u',\n",
       " 'spy': 'b',\n",
       " 'downing': 'r',\n",
       " 'radar': 'r',\n",
       " 'russian': 'b',\n",
       " '270': 'u',\n",
       " 'recorder': 'u',\n",
       " 'missiles': 'r',\n",
       " 'pentagon': 'b',\n",
       " 'fuselage': 'r',\n",
       " 'fired': 'u',\n",
       " 'cuban': 'b',\n",
       " 'us': 'b',\n",
       " 'pakistani': 'b',\n",
       " 'yemeni': 'b',\n",
       " '800': 'u',\n",
       " 'intercept': 'r',\n",
       " 'attacks': 'b',\n",
       " 'pakistan': 'b',\n",
       " 'descended': 'r',\n",
       " 'yemen': 'b',\n",
       " 'strikes': 'b',\n",
       " 'terrorist': 'b',\n",
       " 'terrorists': 'b',\n",
       " 'locate': 'u',\n",
       " 'iranian': 'b',\n",
       " 'confirmed': 'u',\n",
       " 'withstand': 'u',\n",
       " 'controversial': 'u',\n",
       " 'perished': 'u',\n",
       " 'intelligence': 'u',\n",
       " 'gather': 'u',\n",
       " 'thwarted': 'u',\n",
       " 'deciding': 'u',\n",
       " 'publicly': 'u',\n",
       " 'bird': 'i',\n",
       " 'nest': 'r',\n",
       " 'species': 'u',\n",
       " 'birds': 'i',\n",
       " 'wings': 'p',\n",
       " 'found': 'u',\n",
       " 'it': 'u',\n",
       " 'hidden': 'u',\n",
       " 'quail': 'i',\n",
       " 'pigeon': 'i',\n",
       " 'flies': 'l',\n",
       " 'hatched': 'r',\n",
       " 'game': 'i',\n",
       " 'one': 'u',\n",
       " 'near': 'u',\n",
       " 'several': 'u',\n",
       " 'this': 'u',\n",
       " 'commonly': 'u',\n",
       " 'clear': 'u',\n",
       " 'raised': 'u',\n",
       " 'probably': 'u',\n",
       " 'eggs': 'r',\n",
       " 'roasted': 'r',\n",
       " 'outbreaks': 'u',\n",
       " 'manager': 'u',\n",
       " 'owner': 'u',\n",
       " 'chasing': 'u',\n",
       " 'on': 'u',\n",
       " 'but': 'u',\n",
       " 'garden': 'u',\n",
       " 'amp': 'u',\n",
       " 'had': 'u',\n",
       " 'their': 'u',\n",
       " 'home': 'u',\n",
       " 'dog': 'u',\n",
       " 'replaced': 'u',\n",
       " 'beak': 'r',\n",
       " 'dear': 'u',\n",
       " 'nesting': 'r',\n",
       " 'feet': 'u',\n",
       " 'failing': 'u',\n",
       " 'fighting': 'u',\n",
       " 'lake': 'u',\n",
       " '28': 'u',\n",
       " 'distinctive': 'u',\n",
       " '62': 'u',\n",
       " 'bright': 'u',\n",
       " 'following': 'u',\n",
       " 'fat': 'u',\n",
       " 'have': 'u',\n",
       " 'than': 'u',\n",
       " 'plastic': 'u',\n",
       " 'number': 'u',\n",
       " 'go': 'u',\n",
       " 'hours': 'u',\n",
       " 'starting': 'u',\n",
       " 'they': 'u',\n",
       " 'do': 'u',\n",
       " 'large': 'u',\n",
       " '250': 'u',\n",
       " 'turning': 'u',\n",
       " 'weeks': 'u',\n",
       " 'water': 'u',\n",
       " 'includes': 'u',\n",
       " 'young': 'u',\n",
       " 'inside': 'u',\n",
       " 'virus': 'b',\n",
       " 'poultry': 'i',\n",
       " 'detected': 'u',\n",
       " 'chickens': 'i',\n",
       " 'suspected': 'u',\n",
       " 'wild': 'u',\n",
       " 'fowl': 'i',\n",
       " 'farms': 'u',\n",
       " 'farm': 'u',\n",
       " 'feathers': 'r',\n",
       " 'free': 'u',\n",
       " 'said': 'u',\n",
       " 'turkey': 'i',\n",
       " 'pet': 'u',\n",
       " 'dead': 'u',\n",
       " 'culled': 'u',\n",
       " 'wildlife': 'u',\n",
       " 'duck': 'i',\n",
       " 'slaughter': 'u',\n",
       " 'two': 'u',\n",
       " 'so': 'u',\n",
       " 'could': 'u',\n",
       " 'pig': 'u',\n",
       " 'being': 'u',\n",
       " 'flock': 'r',\n",
       " 'thanksgiving': 'r',\n",
       " 'million': 'u',\n",
       " 'foot': 'u',\n",
       " 'baby': 'u',\n",
       " 'them': 'u',\n",
       " 'ostrich': 'i',\n",
       " 'same': 'u',\n",
       " 'least': 'u',\n",
       " 'whether': 'u',\n",
       " 'kind': 'u',\n",
       " 'geese': 'i',\n",
       " 'does': 'u',\n",
       " 'common': 'u',\n",
       " 'appeared': 'u',\n",
       " 'every': 'u',\n",
       " 'farming': 'u',\n",
       " 'sight': 'u',\n",
       " 'brown': 'u',\n",
       " '300': 'u',\n",
       " 'almost': 'u',\n",
       " 'dozen': 'u',\n",
       " 'strange': 'u',\n",
       " 'adding': 'u',\n",
       " 'longer': 'u',\n",
       " 'typical': 'u',\n",
       " 'bought': 'u',\n",
       " 'plants': 'u',\n",
       " 'goose': 'i',\n",
       " 'charge': 'u',\n",
       " 'wash': 'u',\n",
       " 'hens': 'i',\n",
       " 'rabbit': 'u',\n",
       " 'hen': 'i',\n",
       " 'hiding': 'u',\n",
       " 'nobody': 'u',\n",
       " 'wherever': 'u',\n",
       " 'blame': 'u',\n",
       " 'hatching': 'r',\n",
       " 'sparrow': 'i',\n",
       " 'side': 'u',\n",
       " 'like': 'u',\n",
       " '0': 'u',\n",
       " 'chocolate': 'u',\n",
       " 'be': 'u',\n",
       " 'mice': 'u',\n",
       " 'migratory': 'u',\n",
       " 'always': 'u',\n",
       " '20': 'u',\n",
       " 'normally': 'u',\n",
       " 'web': 'u',\n",
       " 'worst': 'u',\n",
       " 'kong': 'u',\n",
       " 'populations': 'u',\n",
       " 'pub': 'u',\n",
       " 'mouse': 'u',\n",
       " 'perched': 'r',\n",
       " 'sweeping': 'u',\n",
       " 'prairie': 'u',\n",
       " 'been': 'u',\n",
       " 'before': 'u',\n",
       " 'away': 'u',\n",
       " 'hard': 'u',\n",
       " 'american': 'u',\n",
       " 'over': 'u',\n",
       " 'flower': 'u',\n",
       " '30': 'u',\n",
       " 'from': 'u',\n",
       " 'would': 'u',\n",
       " 'golden': 'u',\n",
       " 'leg': 'u',\n",
       " 'hit': 'u',\n",
       " 'trade': 'u',\n",
       " 'evolved': 'u',\n",
       " 'announcement': 'u',\n",
       " 'talking': 'u',\n",
       " 'eve': 'u',\n",
       " 'hawk': 'u',\n",
       " 'alternative': 'u',\n",
       " 'nasty': 'u',\n",
       " 'homemade': 'u',\n",
       " 'months': 'u',\n",
       " 'proverbial': 'u',\n",
       " 'honey': 'u',\n",
       " 'serious': 'u',\n",
       " 'neither': 'u',\n",
       " 'chuck': 'u',\n",
       " 'below': 'u',\n",
       " 'ben': 'u',\n",
       " 'field': 'u',\n",
       " 'pudding': 'u',\n",
       " 'netherlands': 'u',\n",
       " 'sent': 'u',\n",
       " 'team': 'u',\n",
       " 'seen': 'u',\n",
       " 'appreciate': 'u',\n",
       " 'unable': 'u',\n",
       " 'increase': 'u',\n",
       " 'research': 'u',\n",
       " 'worry': 'u',\n",
       " 'cages': 'u',\n",
       " 'stupid': 'u',\n",
       " 'engaged': 'u',\n",
       " 'growing': 'u',\n",
       " 'campaign': 'u',\n",
       " 'starts': 'u',\n",
       " 'realized': 'u',\n",
       " 'dick': 'u',\n",
       " 'suggests': 'u',\n",
       " 'habits': 'u',\n",
       " 'acting': 'u',\n",
       " 'weekends': 'u',\n",
       " '51': 'u',\n",
       " 'resulting': 'u',\n",
       " 'maintained': 'u',\n",
       " 'stricken': 'u',\n",
       " 'agent': 'u',\n",
       " 'meets': 'u',\n",
       " 'broke': 'u',\n",
       " 'rain': 'u',\n",
       " 'jumping': 'u',\n",
       " 'epidemic': 'u',\n",
       " 'variation': 'u',\n",
       " 'rolling': 'u',\n",
       " 'friendly': 'u',\n",
       " 'if': 'u',\n",
       " 'hatch': 'u',\n",
       " 'farmers': 'u',\n",
       " 'cat': 'u',\n",
       " 'only': 'u',\n",
       " 'told': 'u',\n",
       " 'cover': 'u',\n",
       " 'some': 'u',\n",
       " '15': 'u',\n",
       " 'started': 'u',\n",
       " 'counting': 'u',\n",
       " 'can': 'u',\n",
       " 'control': 'u',\n",
       " 'sized': 'u',\n",
       " 'her': 'u',\n",
       " 'while': 'u',\n",
       " 'turned': 'u',\n",
       " 'deal': 'u',\n",
       " '23': 'u',\n",
       " 'exotic': 'u',\n",
       " 'even': 'u',\n",
       " 'where': 'u',\n",
       " 'killing': 'u',\n",
       " 'after': 'u',\n",
       " 'kills': 'u',\n",
       " 'die': 'u',\n",
       " '10': 'u',\n",
       " 'different': 'u',\n",
       " 'affected': 'u',\n",
       " 'also': 'u',\n",
       " 'wednesday': 'u',\n",
       " 'used': 'u',\n",
       " 'all': 'u',\n",
       " 'watching': 'u',\n",
       " 've': 'u',\n",
       " 'knew': 'u',\n",
       " 'dance': 'u',\n",
       " 'likes': 'u',\n",
       " 'production': 'u',\n",
       " 'flu': 'r',\n",
       " 'h5n1': 'u',\n",
       " 'outbreak': 'u',\n",
       " 'strain': 'u',\n",
       " 'infected': 'u',\n",
       " 'human': 'u',\n",
       " 'avian': 'r',\n",
       " 'cage': 'u',\n",
       " 'tested': 'u',\n",
       " 'ducks': 'i',\n",
       " 'samples': 'u',\n",
       " 'agriculture': 'u',\n",
       " 'disease': 'u',\n",
       " 'killed': 'u',\n",
       " 'that': 'u',\n",
       " 'animal': 'r',\n",
       " 'tests': 'u',\n",
       " 'rare': 'u',\n",
       " 'people': 'u',\n",
       " 'flocks': 'r',\n",
       " 'national': 'u',\n",
       " 'its': 'u',\n",
       " 'sick': 'u',\n",
       " 'feeding': 'u',\n",
       " 'not': 'u',\n",
       " 'were': 'u',\n",
       " 'roasting': 'r',\n",
       " 'testing': 'u',\n",
       " 'more': 'u',\n",
       " 'slaughtered': 'u',\n",
       " 'turkeys': 'i',\n",
       " 'stuffing': 'r',\n",
       " 'oven': 'r',\n",
       " 'backyard': 'u',\n",
       " 'fly': 'l',\n",
       " 'banned': 'u',\n",
       " 'any': 'u',\n",
       " 'monday': 'u',\n",
       " 'test': 'u',\n",
       " 'lab': 'u',\n",
       " 'africa': 'u',\n",
       " 'ban': 'u',\n",
       " 'head': 'u',\n",
       " 'village': 'u',\n",
       " 'government': 'u',\n",
       " 'third': 'u',\n",
       " 'livestock': 'r',\n",
       " 'contaminated': 'u',\n",
       " 'swan': 'i',\n",
       " '25': 'u',\n",
       " 'animals': 'r',\n",
       " '100': 'u',\n",
       " 'calls': 'u',\n",
       " '90': 'u',\n",
       " 'spokesman': 'u',\n",
       " 'taken': 'u',\n",
       " 'southern': 'u',\n",
       " '500': 'u',\n",
       " 'raising': 'u',\n",
       " 'week': 'u',\n",
       " 'dying': 'u',\n",
       " 'saturday': 'u',\n",
       " 'feather': 'r',\n",
       " 'emerged': 'u',\n",
       " 'according': 'u',\n",
       " 'genes': 'u',\n",
       " 'center': 'u',\n",
       " 'recently': 'u',\n",
       " 'capital': 'u',\n",
       " 'easily': 'u',\n",
       " 'import': 'u',\n",
       " 'keep': 'u',\n",
       " 'amid': 'u',\n",
       " 'reserve': 'u',\n",
       " 'across': 'u',\n",
       " 'north': 'u',\n",
       " '60': 'u',\n",
       " 'hunter': 'u',\n",
       " 'stepped': 'u',\n",
       " 'covered': 'u',\n",
       " 'seven': 'u',\n",
       " 'types': 'u',\n",
       " 'radius': 'u',\n",
       " 'moist': 'u',\n",
       " 'tough': 'u',\n",
       " 'sounds': 'u',\n",
       " 'added': 'u',\n",
       " 'prepared': 'u',\n",
       " 'down': 'u',\n",
       " 'cavity': 'u',\n",
       " 'market': 'u',\n",
       " 'must': 'u',\n",
       " 'shoot': 'u',\n",
       " 'passed': 'u',\n",
       " 'farmer': 'u',\n",
       " 'why': 'u',\n",
       " 'flip': 'u',\n",
       " 'conducted': 'u',\n",
       " 'wing': 'u',\n",
       " '35': 'u',\n",
       " 'rose': 'u',\n",
       " 'month': 'u',\n",
       " 'pass': 'u',\n",
       " 'able': 'u',\n",
       " '40': 'u',\n",
       " 'states': 'u',\n",
       " 'pigeons': 'i',\n",
       " 'doing': 'u',\n",
       " 'mainly': 'u',\n",
       " 'six': 'u',\n",
       " 'word': 'u',\n",
       " 'islands': 'u',\n",
       " 'company': 'u',\n",
       " 'close': 'u',\n",
       " 'grouse': 'u',\n",
       " 'urged': 'u',\n",
       " '2006': 'u',\n",
       " 'quickly': 'u',\n",
       " 'despite': 'u',\n",
       " 'gone': 'u',\n",
       " 'let': 'u',\n",
       " 'pheasant': 'i',\n",
       " 'vice': 'u',\n",
       " 'woods': 'u',\n",
       " '46': 'u',\n",
       " 'lifted': 'u',\n",
       " 'chicks': 'i',\n",
       " 'cooks': 'u',\n",
       " 'regular': 'u',\n",
       " 'appearance': 'u',\n",
       " 'bones': 'u',\n",
       " 'brush': 'u',\n",
       " 'contamination': 'u',\n",
       " 'daily': 'u',\n",
       " 'change': 'u',\n",
       " 'british': 'u',\n",
       " 'compensation': 'u',\n",
       " 'checks': 'u',\n",
       " 'stepping': 'u',\n",
       " 'drive': 'u',\n",
       " 'measure': 'u',\n",
       " 'difficult': 'u',\n",
       " 'refuge': 'u',\n",
       " '48': 'u',\n",
       " 'excrement': 'u',\n",
       " 'raise': 'u',\n",
       " 'cry': 'u',\n",
       " 'continued': 'u',\n",
       " 'indication': 'u',\n",
       " 'numerous': 'u',\n",
       " 'protective': 'u',\n",
       " 'neck': 'u',\n",
       " 'else': 'u',\n",
       " 'juicy': 'u',\n",
       " '65': 'u',\n",
       " 'shooting': 'u',\n",
       " 'putting': 'u',\n",
       " 'questions': 'u',\n",
       " 'ordinary': 'u',\n",
       " 'acre': 'u',\n",
       " 'space': 'u',\n",
       " 'whatever': 'u',\n",
       " '36': 'u',\n",
       " 'disappeared': 'u',\n",
       " 'upon': 'u',\n",
       " 'amazing': 'u',\n",
       " 'fans': 'u',\n",
       " 'rising': 'u',\n",
       " 'rooster': 'i',\n",
       " 'primarily': 'u',\n",
       " 'practice': 'u',\n",
       " 'character': 'u',\n",
       " 'hungry': 'u',\n",
       " 'appropriate': 'u',\n",
       " 'thus': 'u',\n",
       " 'lead': 'u',\n",
       " 'somewhat': 'u',\n",
       " 'reduce': 'u',\n",
       " 'providing': 'u',\n",
       " 'enter': 'u',\n",
       " 'track': 'u',\n",
       " 'inspections': 'u',\n",
       " 'hide': 'u',\n",
       " 'sales': 'u',\n",
       " 'shy': 'u',\n",
       " 'letting': 'u',\n",
       " 'lewis': 'u',\n",
       " 'sides': 'u',\n",
       " 'sisters': 'u',\n",
       " 'memorable': 'u',\n",
       " 'grew': 'u',\n",
       " 'guinea': 'u',\n",
       " 'rearing': 'u',\n",
       " 'complaining': 'u',\n",
       " 'fortune': 'u',\n",
       " 'note': 'u',\n",
       " 'traders': 'u',\n",
       " 'finish': 'u',\n",
       " 'produces': 'u',\n",
       " 'de': 'u',\n",
       " 'sets': 'u',\n",
       " 'pronounced': 'u',\n",
       " 'endless': 'u',\n",
       " 'pen': 'u',\n",
       " 'manages': 'u',\n",
       " 'chick': 'i',\n",
       " 'degree': 'u',\n",
       " 'tend': 'u',\n",
       " 'phrase': 'u',\n",
       " 'grilled': 'r',\n",
       " 'breast': 'r',\n",
       " 'chicken': 'i',\n",
       " 'roast': 'r',\n",
       " 'egg': 'r',\n",
       " 'lamb': 'u',\n",
       " 'veal': 'u',\n",
       " 'tender': 'u',\n",
       " 'bacon': 'u',\n",
       " 'turn': 'u',\n",
       " 'bag': 'u',\n",
       " 'low': 'u',\n",
       " 'out': 'u',\n",
       " 'sheep': 'u',\n",
       " 'sold': 'u',\n",
       " 'because': 'u',\n",
       " 'black': 'u',\n",
       " 'cider': 'u',\n",
       " 'get': 'u',\n",
       " 'often': 'u',\n",
       " 'nicely': 'u',\n",
       " 'fertilized': 'u',\n",
       " 'foie': 'u',\n",
       " 'running': 'u',\n",
       " 'lot': 'u',\n",
       " 'halfway': 'u',\n",
       " 'breed': 'u',\n",
       " 'sitting': 'u',\n",
       " 'set': 'u',\n",
       " 'takes': 'u',\n",
       " '600': 'u',\n",
       " 'begins': 'u',\n",
       " 'truffles': 'u',\n",
       " 'ubiquitous': 'u',\n",
       " 'parent': 'u',\n",
       " 'gras': 'u',\n",
       " 'left': 'u',\n",
       " 'fact': 'u',\n",
       " 'smaller': 'u',\n",
       " 'guess': 'u',\n",
       " 'ahead': 'u'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'giga_full_updated'\n",
    "prop = 'wings'\n",
    "top_cutoff = 3\n",
    "concept_cutoff = 3\n",
    "\n",
    "evidence_dict = get_evidence_dict(model_name, prop, top_cutoff, concept_cutoff)\n",
    "evidence_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import stdev\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tfidf_score(prop, concept, evidence_word, label, \n",
    "                     model_name, top_cutoff, concept_cutoff):\n",
    "    \n",
    "    tfidf_scores = []\n",
    "    dir_res = f'../results/{model_name}/tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    categories = get_categories(prop, model_name)\n",
    "    for cat in categories:\n",
    "        f =  f'{dir_res}/{prop}/{cat}/{label}/{concept}.csv'\n",
    "        if os.path.isfile(f):\n",
    "            with open(f) as infile:\n",
    "                data = list(csv.DictReader(infile))\n",
    "            for d in data:\n",
    "                context = d['']\n",
    "                diff =  float(d['diff'])\n",
    "                if context == evidence_word and diff > 0:\n",
    "                    score = float(d['target'])\n",
    "                    tfidf_scores.append(score)\n",
    "    return tfidf_scores\n",
    "\n",
    "def get_mean(numbers):\n",
    "    if len(numbers) > 0:\n",
    "        mean = sum(numbers)/len(numbers)\n",
    "    else:\n",
    "        mean = 0\n",
    "    return mean\n",
    "\n",
    "  \n",
    "def get_relation_combinations(properties, combinations):\n",
    "    \n",
    "    relation_pair_dict = defaultdict(set)\n",
    "\n",
    "    \n",
    "    for prop in properties:\n",
    "        prop_dict = load_prop_data(prop)\n",
    "        for c, d in prop_dict.items():\n",
    "            ml_label = d['ml_label']\n",
    "            if ml_label in {'all', 'some', 'all-some', 'few-some'}:\n",
    "                l = 'pos'\n",
    "            elif ml_label in {'few'}:\n",
    "                l = 'neg'\n",
    "            relation_pair_dict[l].add((prop, c))\n",
    "            if l == 'pos':\n",
    "                rel_dict = d['relations']\n",
    "                for combination in combinations:\n",
    "                    relations = set([rel for rel, p in rel_dict.items() if p > 0.5])\n",
    "                    if combination == relations:\n",
    "                        l_comb = tuple(sorted(relations))\n",
    "                        relation_pair_dict[l_comb].add((prop, c))\n",
    "    return relation_pair_dict   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg 1545\n",
      "pos 2135\n",
      "('implied_category', 'variability_limited') 21\n",
      "('variability_limited',) 114\n",
      "('implied_category',) 16\n",
      "('implied_category', 'typical_of_concept') 13\n",
      "('typical_of_concept', 'typical_of_property') 4\n",
      "('typical_of_concept',) 4\n",
      "('afforded_unusual',) 20\n",
      "('afforded_usual',) 3\n",
      "\n",
      "{('swim', 'cob'), ('warm', 'brogue'), ('wings', 'roach'), ('wheels', 'tank'), ('dangerous', 'pentobarbital'), ('round', 'pepperoni'), ('roll', 'bike'), ('round', 'patty'), ('round', 'cherry'), ('wheels', 'saloon'), ('lay_eggs', 'neritidae'), ('wings', 'cricket'), ('lay_eggs', 'crane'), ('swim', 'bay'), ('wheels', 'underframe'), ('lay_eggs', 'flounder')}\n",
      "\n",
      "{('square', 'laptop'), ('sweet', 'breadfruit'), ('made_of_wood', 'ladle'), ('round', 'pineapple'), ('roll', 'cart'), ('made_of_wood', 'girder'), ('juicy', 'anjou'), ('fly', 'fowl'), ('round', 'gourd'), ('round', 'sapodilla'), ('round', 'cabbage'), ('square', 'computer'), ('round', 'onion'), ('round', 'lemon'), ('square', 'blackboard'), ('sweet', 'carrot'), ('made_of_wood', 'transom'), ('wings', 'beetle'), ('round', 'nutlet'), ('green', 'fenugreek'), ('red', 'tongue')}\n",
      "\n",
      "{('wheels', 'wheel'), ('made_of_wood', 'club'), ('fly', 'babbler'), ('juicy', 'meat')}\n",
      "\n",
      "{('yellow', 'yolk'), ('dangerous', 'adze'), ('dangerous', 'hippopotamus'), ('black', 'housefly'), ('black', 'pupil'), ('round', 'coconut'), ('round', 'cucurbit'), ('dangerous', 'phencyclidine'), ('wings', 'cock'), ('wings', 'weka'), ('wings', 'weaver'), ('dangerous', 'morphine'), ('yellow', 'buttercup')}\n",
      "\n",
      "set()\n",
      "\n",
      "set()\n",
      "\n",
      "{('red', 'watermelon'), ('red', 'tomato'), ('sweet', 'desert'), ('green', 'jade')}\n",
      "\n",
      "{('lay_eggs', 'stockfish'), ('swim', 'goldeneye'), ('lay_eggs', 'platypus')}\n",
      "\n",
      "{('swim', 'retriever'), ('swim', 'cat'), ('roll', 'windscreen'), ('swim', 'armadillo'), ('swim', 'deer'), ('roll', 'cloth'), ('swim', 'vervet'), ('swim', 'goat'), ('swim', 'painter'), ('roll', 'pen'), ('swim', 'boar'), ('roll', 'pig'), ('swim', 'gnu'), ('swim', 'panther'), ('roll', 'bolt'), ('swim', 'mouse'), ('swim', 'mankind'), ('swim', 'leopard'), ('swim', 'glutton'), ('swim', 'pony')}\n"
     ]
    }
   ],
   "source": [
    "combinations = [\n",
    "                    {'implied_category'},\n",
    "                    {'implied_category', 'variability_limited'},\n",
    "                    {'variability_limited'},\n",
    "                    {'typical_of_property'},\n",
    "                    {'typical_of_concept'},\n",
    "                    {'implied_category', 'typical_of_concept'},\n",
    "                    {'implied_cateogry', 'typical_of_property'},\n",
    "                    {'typical_of_concept', 'typical_of_property'},\n",
    "                    {'afforded_usual'},\n",
    "                    {'afforded_unusual'}\n",
    "                \n",
    "                    ]\n",
    "\n",
    "properties = get_properties()\n",
    "relation_pair_dict = get_relation_combinations(properties, combinations)\n",
    "for rel, pairs in relation_pair_dict.items():\n",
    "    print(rel, len(pairs))\n",
    "print()\n",
    "print(relation_pair_dict[('implied_category',  )]) \n",
    "print()\n",
    "print(relation_pair_dict[('implied_category', 'variability_limited', )])\n",
    "print()\n",
    "print(relation_pair_dict[('typical_of_concept',  )]) \n",
    "print()\n",
    "print(relation_pair_dict[('implied_category', 'typical_of_concept')])\n",
    "print()\n",
    "print(relation_pair_dict[('typical_of_property',  )]) \n",
    "print()\n",
    "print(relation_pair_dict[('implied_category', 'typical_of_property')])\n",
    "print()\n",
    "print(relation_pair_dict[('typical_of_concept', 'typical_of_property')])\n",
    "print()\n",
    "print(relation_pair_dict[('afforded_usual', )])\n",
    "print()\n",
    "print(relation_pair_dict[('afforded_unusual', )])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012380345716773471\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_rel = 'pos'\n",
    "label = 'pos'\n",
    "\n",
    "all_scores = []\n",
    "all_means = []\n",
    "for prop, concept in relation_pair_dict[label_rel]:\n",
    "    evidence_word = prop\n",
    "    if prop == 'lay_eggs':\n",
    "        evidence_word = 'eggs'\n",
    "    elif prop == 'used_in_cooking':\n",
    "        evidence_word = 'cook'\n",
    "    elif prop == 'made_of_wood':\n",
    "        evidence_word = 'wood'\n",
    "    elif prop == 'has_wings':\n",
    "        evidence_word = 'wings'\n",
    "    elif prop == 'has_wheels':\n",
    "        evidence_word = 'wheels'\n",
    "    scores = load_tfidf_score(prop, concept, evidence_word, label, \n",
    "                      model_name, top_cutoff, concept_cutoff)\n",
    "    all_scores.extend(scores)\n",
    "    mean = get_mean(scores)\n",
    "    all_means.append(mean)\n",
    "\n",
    "print(get_mean(all_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0019888443681951185\n"
     ]
    }
   ],
   "source": [
    "label_rel = 'neg'\n",
    "label = 'neg'\n",
    "\n",
    "all_scores = []\n",
    "all_means = []\n",
    "for prop, concept in relation_pair_dict[label_rel]:\n",
    "    evidence_word = prop\n",
    "    if prop == 'lay_eggs':\n",
    "        evidence_word = 'eggs'\n",
    "    elif prop == 'used_in_cooking':\n",
    "        evidence_word = 'cook'\n",
    "    elif prop == 'made_of_wood':\n",
    "        evidence_word = 'wood'\n",
    "    elif prop == 'has_wings':\n",
    "        evidence_word = 'wings'\n",
    "    elif prop == 'has_wheels':\n",
    "        evidence_word = 'wheels'\n",
    "    scores = load_tfidf_score(prop, concept, evidence_word, label, \n",
    "                      model_name, top_cutoff, concept_cutoff)\n",
    "    all_scores.extend(scores)\n",
    "    mean = get_mean(scores)\n",
    "    all_means.append(mean)\n",
    "\n",
    "print(get_mean(all_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0018485234171035732\n"
     ]
    }
   ],
   "source": [
    "label_rel = ('implied_category', )\n",
    "label = 'pos'\n",
    "\n",
    "all_scores = []\n",
    "all_means = []\n",
    "for prop, concept in relation_pair_dict[label_rel]:\n",
    "    evidence_word = prop\n",
    "    if prop == 'lay_eggs':\n",
    "        evidence_word = 'eggs'\n",
    "    elif prop == 'used_in_cooking':\n",
    "        evidence_word = 'cook'\n",
    "    elif prop == 'made_of_wood':\n",
    "        evidence_word = 'wood'\n",
    "    elif prop == 'has_wings':\n",
    "        evidence_word = 'wings'\n",
    "    elif prop == 'has_wheels':\n",
    "        evidence_word = 'wheels'\n",
    "\n",
    "    scores = load_tfidf_score(prop, concept, evidence_word, label, \n",
    "                      model_name, top_cutoff, concept_cutoff)\n",
    "    all_scores.extend(scores)\n",
    "    mean = get_mean(scores)\n",
    "    all_means.append(mean)\n",
    "\n",
    "print(get_mean(all_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011092839659587376\n"
     ]
    }
   ],
   "source": [
    "label_rel = ('variability_limited', )\n",
    "label = 'pos'\n",
    "\n",
    "all_scores = []\n",
    "all_means = []\n",
    "for prop, concept in relation_pair_dict[label_rel]:\n",
    "    evidence_word = prop\n",
    "    if prop == 'lay_eggs':\n",
    "        evidence_word = 'eggs'\n",
    "    elif prop == 'used_in_cooking':\n",
    "        evidence_word = 'cook'\n",
    "    elif prop == 'made_of_wood':\n",
    "        evidence_word = 'wood'\n",
    "    elif prop == 'has_wings':\n",
    "        evidence_word = 'wings'\n",
    "    elif prop == 'has_wheels':\n",
    "        evidence_word = 'wheels'\n",
    "\n",
    "    scores = load_tfidf_score(prop, concept, evidence_word, label, \n",
    "                      model_name, top_cutoff, concept_cutoff)\n",
    "    all_scores.extend(scores)\n",
    "    mean = get_mean(scores)\n",
    "    all_means.append(mean)\n",
    "\n",
    "print(get_mean(all_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006298089086881645\n"
     ]
    }
   ],
   "source": [
    "label_rel = ('implied_category', 'variability_limited')\n",
    "label = 'pos'\n",
    "\n",
    "all_scores = []\n",
    "all_means = []\n",
    "for prop, concept in relation_pair_dict[label_rel]:\n",
    "    evidence_word = prop\n",
    "    if prop == 'lay_eggs':\n",
    "        evidence_word = 'eggs'\n",
    "    elif prop == 'used_in_cooking':\n",
    "        evidence_word = 'cook'\n",
    "    elif prop == 'made_of_wood':\n",
    "        evidence_word = 'wood'\n",
    "    elif prop == 'has_wings':\n",
    "        evidence_word = 'wings'\n",
    "    elif prop == 'has_wheels':\n",
    "        evidence_word = 'wheels'\n",
    "\n",
    "    scores = load_tfidf_score(prop, concept, evidence_word, label, \n",
    "                      model_name, top_cutoff, concept_cutoff)\n",
    "    all_scores.extend(scores)\n",
    "    mean = get_mean(scores)\n",
    "    all_means.append(mean)\n",
    "\n",
    "print(get_mean(all_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025515742044588785\n"
     ]
    }
   ],
   "source": [
    "label_rel = ('afforded_usual', )\n",
    "label = 'pos'\n",
    "\n",
    "all_scores = []\n",
    "all_means = []\n",
    "for prop, concept in relation_pair_dict[label_rel]:\n",
    "    evidence_word = prop\n",
    "    if prop == 'lay_eggs':\n",
    "        evidence_word = 'eggs'\n",
    "    elif prop == 'used_in_cooking':\n",
    "        evidence_word = 'cook'\n",
    "    elif prop == 'made_of_wood':\n",
    "        evidence_word = 'wood'\n",
    "    elif prop == 'has_wings':\n",
    "        evidence_word = 'wings'\n",
    "    elif prop == 'has_wheels':\n",
    "        evidence_word = 'wheels'\n",
    "\n",
    "    scores = load_tfidf_score(prop, concept, evidence_word, label, \n",
    "                      model_name, top_cutoff, concept_cutoff)\n",
    "    all_scores.extend(scores)\n",
    "    mean = get_mean(scores)\n",
    "    all_means.append(mean)\n",
    "\n",
    "\n",
    "print(get_mean(all_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003130250052305159\n"
     ]
    }
   ],
   "source": [
    "label_rel = ('afforded_unusual', )\n",
    "label = 'pos'\n",
    "\n",
    "all_scores = []\n",
    "all_means = []\n",
    "for prop, concept in relation_pair_dict[label_rel]:\n",
    "    evidence_word = prop\n",
    "    if prop == 'lay_eggs':\n",
    "        evidence_word = 'eggs'\n",
    "    elif prop == 'used_in_cooking':\n",
    "        evidence_word = 'cook'\n",
    "    elif prop == 'made_of_wood':\n",
    "        evidence_word = 'wood'\n",
    "    elif prop == 'has_wings':\n",
    "        evidence_word = 'wings'\n",
    "    elif prop == 'has_wheels':\n",
    "        evidence_word = 'wheels'\n",
    "\n",
    "    scores = load_tfidf_score(prop, concept, evidence_word, label, \n",
    "                      model_name, top_cutoff, concept_cutoff)\n",
    "    all_scores.extend(scores)\n",
    "    mean = get_mean(scores)\n",
    "    all_means.append(mean)\n",
    "\n",
    "print(get_mean(all_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021969832408808006\n"
     ]
    }
   ],
   "source": [
    "prop = 'red'\n",
    "concept = 'ambulance'\n",
    "evidence_word = 'red'\n",
    "label = 'pos'\n",
    "#lay_eggs', 'neritidae\n",
    "scores = load_tfidf_score(prop, concept, evidence_word, label, \n",
    "                     model_name, top_cutoff, concept_cutoff)\n",
    "print(get_mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how often direct mentions of property words are mentioned \n",
    "# in the context of the target pairs vs the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
