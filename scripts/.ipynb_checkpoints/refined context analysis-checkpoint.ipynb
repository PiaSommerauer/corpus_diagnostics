{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze based on semantic categories\n",
    "\n",
    "1.) change tfidf so we compare equivalent categories only - done\n",
    "2.) update ranking accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1446\n",
      "1636\n"
     ]
    }
   ],
   "source": [
    "f_original = os.listdir('../contexts/giga_full/vocab')\n",
    "print(len(f_original))\n",
    "f_update = os.listdir('../contexts/giga_full_updated/vocab')\n",
    "print(len(f_update))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1669\n",
      "1874\n"
     ]
    }
   ],
   "source": [
    "f_original = os.listdir('../contexts/wiki/vocab')\n",
    "print(len(f_original))\n",
    "f_update = os.listdir('../contexts/wiki_updated/vocab')\n",
    "print(len(f_update))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories(prop, model_name):\n",
    "    analysis_type = 'tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    path_dir = f'../results/{model_name}/{analysis_type}'\n",
    "    path_dir = f'{path_dir}/{prop}'\n",
    "    categories = set()\n",
    "    for d in os.listdir(path_dir):\n",
    "        categories.add(d)\n",
    "    return categories\n",
    "\n",
    "def get_context_cnts(prop, cat, label, model_name):\n",
    "    \n",
    "    analysis_type = 'tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    path_dir = f'../results/{model_name}/{analysis_type}'\n",
    "    path_dir = f'{path_dir}/{prop}'\n",
    "    path_label = f'{path_dir}/{cat}/{label}'\n",
    "    \n",
    "    context_cnt = Counter()\n",
    "    for f in os.listdir(path_label):\n",
    "        full_path = f'{path_label}/{f}'\n",
    "        if full_path.endswith('.csv'):\n",
    "            with open(full_path) as infile:\n",
    "                data = list(csv.DictReader(infile))\n",
    "            for d in data:\n",
    "                context = d['']\n",
    "                diff = float(d['diff'])\n",
    "                if diff > 0:\n",
    "                    context_cnt[context] += 1\n",
    "    return context_cnt\n",
    "    \n",
    "def get_n_concepts_total(prop, cat, model_name):\n",
    "    \n",
    "    analysis_type = 'tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    path_dir = f'../results/{model_name}/{analysis_type}'\n",
    "    path_dir = f'{path_dir}/{prop}'\n",
    "    label = 'pos'\n",
    "    path_pos = f'{path_dir}/{cat}/{label}'\n",
    "    label = 'neg'\n",
    "    path_neg = f'{path_dir}/{cat}/{label}'\n",
    "    \n",
    "    files_pos = [f for f in os.listdir(path_pos) if f.endswith('.csv')]\n",
    "    files_neg = [f for f in os.listdir(path_neg) if f.endswith('.csv')]\n",
    "    \n",
    "    return len(files_pos), len(files_neg)\n",
    "\n",
    "def get_f1_distinctiveness(n_pos, n_neg, total_pos, total_neg):\n",
    "    \n",
    "   \n",
    "    total_instances = total_pos + total_neg\n",
    "    labels = []\n",
    "    [labels.append('pos') for i in range(total_pos)]\n",
    "    [labels.append('neg') for i in range(total_neg)]\n",
    "    pred_labels_pos = []\n",
    "    for i in range(total_pos):\n",
    "        if i < n_pos:\n",
    "            pred_labels_pos.append('pos')\n",
    "        else:\n",
    "            pred_labels_pos.append('neg')\n",
    "#     print(n_pos, total_pos)\n",
    "#     print(pred_labels_pos.count('pos'), pred_labels_pos.count('neg'))\n",
    "    \n",
    "    pred_labels_neg = []\n",
    "    for i in range(total_neg):\n",
    "        if i < n_neg:\n",
    "            pred_labels_neg.append('pos')\n",
    "        else:\n",
    "            pred_labels_neg.append('neg')\n",
    "#     print(n_neg, total_neg)\n",
    "#     print(pred_labels_neg.count('pos'), pred_labels_neg.count('neg'))\n",
    "    \n",
    "    predictions = pred_labels_pos + pred_labels_neg\n",
    "    \n",
    "    \n",
    "    #print(len(labels), len(predictions))\n",
    "    #print(pos_predictions, neg_predictions)\n",
    "    \n",
    "    p, r, f1, supp = precision_recall_fscore_support(labels, predictions, average = 'weighted', \n",
    "                                                     zero_division=0)\n",
    "    #average='weighted'\n",
    "    \n",
    "    return p, r, f1\n",
    "\n",
    "\n",
    "    \n",
    "def aggregate_contexts(prop, cutoff, model_name):\n",
    "    aggregation_name = 'aggregated-tfidf-raw-10000-categories'\n",
    "    path_dir_agg = f'../analysis/{model_name}/{aggregation_name}/{prop}'\n",
    "    os.makedirs(path_dir_agg, exist_ok = True)\n",
    "    \n",
    "    context_cnts_all = Counter()\n",
    "    context_cat_dict = defaultdict(set)\n",
    "\n",
    "    cats = get_categories(prop, model_name)\n",
    "\n",
    "    for cat in cats:\n",
    "        context_cnts_pos = get_context_cnts(prop, cat, 'pos', model_name)\n",
    "        context_cnts_neg = get_context_cnts(prop, cat, 'neg', model_name)\n",
    "        total_pos, total_neg = get_n_concepts_total(prop, cat, model_name)\n",
    "        \n",
    "        context_f1_dict = Counter()\n",
    "        context_score_dict = defaultdict(dict)\n",
    "        \n",
    "        # get distinctiveness\n",
    "        for c, cnt_pos in context_cnts_pos.most_common():\n",
    "            cnt_neg = context_cnts_neg[c]\n",
    "            p, r, f1 = get_f1_distinctiveness(cnt_pos, cnt_neg, total_pos, total_neg)\n",
    "            context_f1_dict[c] = f1\n",
    "            context_score_dict[c] = {'p': p,'r':r, 'f1': f1}\n",
    "        \n",
    "        table = []\n",
    "        for c, f1 in context_f1_dict.most_common():\n",
    "            scores = context_score_dict[c]\n",
    "            d = dict()\n",
    "            d['context'] = c\n",
    "            d.update(scores)\n",
    "            d['n_pos'] = context_cnts_pos[c]\n",
    "            d['total_pos'] = total_pos\n",
    "            d['n_neg'] = context_cnts_neg[c]\n",
    "            d['total_neg'] = total_neg\n",
    "            table.append(d)\n",
    "        \n",
    "        # collect and write to file\n",
    "        f = f'{path_dir_agg}/{cat}.csv'\n",
    "        \n",
    "        header = table[0].keys()\n",
    "        with open(f, 'w') as outfile:\n",
    "            writer = csv.DictWriter(outfile, fieldnames = header)\n",
    "            writer.writeheader()\n",
    "            for d in table:\n",
    "                writer.writerow(d)\n",
    "        \n",
    "                \n",
    "def prepare_annotation(prop, model_name, cutoff=3, cutoff_concepts = 5):\n",
    "    \n",
    "    annotation_name = f'annotation-tfidf-top_{cutoff}_{cutoff_concepts}-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    os.makedirs(path_dir_annotation, exist_ok = True)\n",
    "    f_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}/annotation-updated.csv'\n",
    "    \n",
    "    # paths aggregated files:\n",
    "    aggregation_name = 'aggregated-tfidf-raw-10000-categories'\n",
    "    path_dir_agg = f'../analysis/{model_name}/{aggregation_name}/{prop}'\n",
    "\n",
    "    \n",
    "    # get categories\n",
    "    cats = get_categories(prop, model_name)\n",
    "    \n",
    "    # collect all contexts and categories \n",
    "    context_cats_dict = defaultdict(set)\n",
    "    \n",
    "    # load top per category\n",
    "    for cat in cats:\n",
    "        path = f'{path_dir_agg}/{cat}.csv'\n",
    "        with open(path) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "        # sort by f1\n",
    "        f1_dict  = defaultdict(list)\n",
    "        for d in data:\n",
    "            f1 = d['f1']\n",
    "            f1_dict[f1].append(d)\n",
    "        scores = sorted(list(f1_dict.keys()), reverse=True)\n",
    "        top_scores = scores[:cutoff]\n",
    "        top_context_dicts = []\n",
    "        for ts in top_scores:\n",
    "            dicts = f1_dict[ts]\n",
    "            for d in dicts:\n",
    "                n_pos = int(d['n_pos'])\n",
    "                if n_pos > cutoff_concepts:\n",
    "                    top_context_dicts.append(d)\n",
    "    \n",
    "        contexts = [d['context'] for d in top_context_dicts]\n",
    "        # record categories\n",
    "        for c in contexts:\n",
    "            context_cats_dict[c].add(cat)\n",
    "    \n",
    "    with open(f_annotation, 'w') as outfile:\n",
    "        outfile.write('context,evidence_type,categories\\n')\n",
    "        for c, cats in context_cats_dict.items():\n",
    "            outfile.write(f'{c}, ,{\" \".join(cats)}\\n')\n",
    "\n",
    "def get_properties():\n",
    "    properties = []\n",
    "    for path in os.listdir('../data/aggregated/'):\n",
    "        prop = path.split('.')[0]\n",
    "        if 'female-' not in prop and prop != '':\n",
    "            properties.append(prop)\n",
    "    return properties\n",
    "\n",
    "def get_top_distinctive_contexts(properties, model_name, top_cutoff=3, concept_cutoff=3):\n",
    "    aggregation_name = 'aggregated-tfidf-raw-10000-categories'\n",
    "    ann_name = f'annotation-tfidf-top_{top_cutoff}_{concept_cutoff}-raw-10000-categories'\n",
    "    path_results = f'../results/{model_name}/tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    table = []\n",
    "    for prop in properties:\n",
    "        path_dir_agg = f'../analysis/{model_name}/{aggregation_name}/{prop}'\n",
    "        path = path = f'{path_dir_agg}/all.csv'\n",
    "        # load file containing all contexts\n",
    "        with open(path) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "        # top distinctive context\n",
    "        d_prop = dict()\n",
    "        d_prop['property'] = prop\n",
    "        # sort data by f1\n",
    "        f1_dict = defaultdict(list)\n",
    "        for d in data:\n",
    "            f1 = d['f1']\n",
    "            f1_dict[f1].append(d)\n",
    "            \n",
    "        # get n extracted candidates\n",
    "        f_ann =  f'../analysis/{model_name}/{ann_name}/{prop}/annotation-updated.csv'\n",
    "        with open(f_ann) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "        n_contexts = len(data)\n",
    "        \n",
    "        # get number concepts\n",
    "        dir_results = f'{path_results}/{prop}/all/pos/'\n",
    "        n_files = len([f for f in os.listdir(dir_results) if f.endswith('.csv')])\n",
    "        \n",
    "        top_score = max(list(f1_dict.keys()))\n",
    "        top_dicts = f1_dict[top_score]\n",
    "        top_context_dict = top_dicts[0]\n",
    "        top_contexts = ' '.join([d['context'] for d in top_dicts])\n",
    "        d_prop['n_contexts'] = n_contexts\n",
    "        d_prop['n_concepts'] = n_files\n",
    "\n",
    "        for k, v in top_context_dict.items():\n",
    "            if k != 'context':\n",
    "                v = float(v)\n",
    "                d_prop[k] = v\n",
    "        d_prop['contexts'] = top_contexts\n",
    "        table.append(d_prop)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square\n",
      "warm\n",
      "black\n",
      "red\n",
      "fly\n",
      "dangerous\n",
      "wings\n",
      "sweet\n",
      "hot\n",
      "used_in_cooking\n",
      "juicy\n",
      "green\n",
      "made_of_wood\n",
      "blue\n",
      "yellow\n",
      "roll\n",
      "female\n",
      "cold\n",
      "round\n",
      "wheels\n",
      "lay_eggs\n",
      "swim\n"
     ]
    }
   ],
   "source": [
    "model_name = 'wiki_updated'\n",
    "properties = get_properties()\n",
    "#properties_test = ['dangerous', 'cold', 'lay_eggs']\n",
    "#properties = [p for p in properties if p not in properties_test]\n",
    "#properties = properties_test\n",
    "cutoff = 3\n",
    "cutoff_concepts = 3\n",
    "\n",
    "for prop in properties:\n",
    "    print(prop)\n",
    "    \n",
    "    aggregate_contexts(prop, cutoff, model_name)\n",
    "    prepare_annotation(prop, model_name, cutoff, cutoff_concepts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property</th>\n",
       "      <th>n_contexts</th>\n",
       "      <th>n_concepts</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f1</th>\n",
       "      <th>n_pos</th>\n",
       "      <th>total_pos</th>\n",
       "      <th>n_neg</th>\n",
       "      <th>total_neg</th>\n",
       "      <th>contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>used_in_cooking</td>\n",
       "      <td>572</td>\n",
       "      <td>101</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>93.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>add recipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fly</td>\n",
       "      <td>952</td>\n",
       "      <td>44</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>29.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>flew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>square</td>\n",
       "      <td>1504</td>\n",
       "      <td>87</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "      <td>70.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>built</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lay_eggs</td>\n",
       "      <td>74</td>\n",
       "      <td>33</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>20.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>female</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>77.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>herself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sweet</td>\n",
       "      <td>35</td>\n",
       "      <td>91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>65.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dangerous</td>\n",
       "      <td>1114</td>\n",
       "      <td>65</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>45.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>killed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>blue</td>\n",
       "      <td>2234</td>\n",
       "      <td>59</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "      <td>31.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>magic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wings</td>\n",
       "      <td>560</td>\n",
       "      <td>60</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>36.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>wheels</td>\n",
       "      <td>244</td>\n",
       "      <td>70</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.80</td>\n",
       "      <td>51.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>drove wheel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>juicy</td>\n",
       "      <td>810</td>\n",
       "      <td>88</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>58.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>pineapple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cold</td>\n",
       "      <td>1081</td>\n",
       "      <td>68</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>48.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>variety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>green</td>\n",
       "      <td>578</td>\n",
       "      <td>89</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>59.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>roll</td>\n",
       "      <td>3886</td>\n",
       "      <td>52</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>34.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>half</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>swim</td>\n",
       "      <td>1381</td>\n",
       "      <td>81</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>53.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>yellow</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.76</td>\n",
       "      <td>22.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>warm</td>\n",
       "      <td>2108</td>\n",
       "      <td>124</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>81.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>heavy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>black</td>\n",
       "      <td>1149</td>\n",
       "      <td>79</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>49.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hot</td>\n",
       "      <td>84</td>\n",
       "      <td>100</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.74</td>\n",
       "      <td>62.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>flame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>round</td>\n",
       "      <td>520</td>\n",
       "      <td>97</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.74</td>\n",
       "      <td>62.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>annual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>red</td>\n",
       "      <td>1767</td>\n",
       "      <td>87</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>46.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>burst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>made_of_wood</td>\n",
       "      <td>786</td>\n",
       "      <td>80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>46.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>wooden</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           property  n_contexts  n_concepts     p     r    f1  n_pos  \\\n",
       "9   used_in_cooking         572         101  0.96  0.95  0.95   93.0   \n",
       "4               fly         952          44  0.88  0.87  0.87   29.0   \n",
       "0            square        1504          87  0.91  0.84  0.86   70.0   \n",
       "20         lay_eggs          74          33  0.86  0.84  0.83   20.0   \n",
       "16           female          45         109  0.85  0.84  0.83   77.0   \n",
       "7             sweet          35          91  0.87  0.82  0.83   65.0   \n",
       "5         dangerous        1114          65  0.86  0.82  0.82   45.0   \n",
       "13             blue        2234          59  0.87  0.83  0.81   31.0   \n",
       "6             wings         560          60  0.85  0.82  0.81   36.0   \n",
       "19           wheels         244          70  0.87  0.79  0.80   51.0   \n",
       "10            juicy         810          88  0.86  0.80  0.80   58.0   \n",
       "17             cold        1081          68  0.88  0.78  0.80   48.0   \n",
       "11            green         578          89  0.85  0.79  0.79   59.0   \n",
       "15             roll        3886          52  0.84  0.78  0.78   34.0   \n",
       "21             swim        1381          81  0.85  0.76  0.76   53.0   \n",
       "14           yellow          52          43  0.78  0.78  0.76   22.0   \n",
       "1              warm        2108         124  0.87  0.72  0.75   81.0   \n",
       "2             black        1149          79  0.83  0.74  0.74   49.0   \n",
       "8               hot          84         100  0.86  0.73  0.74   62.0   \n",
       "18            round         520          97  0.90  0.70  0.74   62.0   \n",
       "3               red        1767          87  0.79  0.71  0.70   46.0   \n",
       "12     made_of_wood         786          80  0.82  0.68  0.69   46.0   \n",
       "\n",
       "    total_pos  n_neg  total_neg     contexts  \n",
       "9       101.0    0.0       56.0   add recipe  \n",
       "4        44.0    2.0       90.0         flew  \n",
       "0        87.0    0.0       21.0        built  \n",
       "20       33.0    1.0       57.0         eggs  \n",
       "16      109.0    9.0      144.0      herself  \n",
       "7        91.0    1.0       63.0        sweet  \n",
       "5        65.0    1.0       51.0       killed  \n",
       "13       59.0    0.0      106.0        magic  \n",
       "6        60.0    1.0       77.0         bird  \n",
       "19       70.0    1.0       25.0  drove wheel  \n",
       "10       88.0    0.0       60.0    pineapple  \n",
       "17       68.0    0.0       24.0      variety  \n",
       "11       89.0    2.0       67.0        green  \n",
       "15       52.0    1.0       33.0         half  \n",
       "21       81.0    1.0       38.0         fish  \n",
       "14       43.0    5.0       74.0       yellow  \n",
       "1       124.0    1.0       32.0        heavy  \n",
       "2        79.0    2.0       45.0         fire  \n",
       "8       100.0    0.0       43.0        flame  \n",
       "18       97.0    0.0       18.0       annual  \n",
       "3        87.0    3.0       64.0        burst  \n",
       "12       80.0    2.0       33.0       wooden  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get top distinctive contexts per prop\n",
    "\n",
    "model_name = 'giga_full_updated'\n",
    "properties = get_properties()\n",
    "table = get_top_distinctive_contexts(properties, model_name)\n",
    "df = pd.DataFrame(table)\n",
    "df.sort_values('f1', ascending = False).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrl}\n",
      "\\toprule\n",
      "        property &  n\\_concepts &  n\\_contexts &    f1 &    contexts \\\\\n",
      "\\midrule\n",
      " used\\_in\\_cooking &         102 &         705 &  0.92 &        meat \\\\\n",
      "           wings &          81 &         332 &  0.89 &       birds \\\\\n",
      "             fly &          63 &          55 &  0.88 &        bird \\\\\n",
      "          female &         122 &         109 &  0.87 &         she \\\\\n",
      "            blue &          60 &        1819 &  0.83 &     evening \\\\\n",
      "          wheels &          78 &         105 &  0.83 &     chassis \\\\\n",
      "            roll &          55 &        3485 &  0.83 &        from \\\\\n",
      "          yellow &          42 &         111 &  0.81 &       tribe \\\\\n",
      "          square &          90 &         442 &  0.81 &       built \\\\\n",
      "           green &          91 &         550 &  0.81 &       green \\\\\n",
      "       dangerous &          76 &         627 &  0.79 &     killing \\\\\n",
      "        lay\\_eggs &          72 &          26 &  0.79 &        bird \\\\\n",
      "             hot &         102 &          92 &  0.78 &         lit \\\\\n",
      "           black &          88 &         820 &  0.78 &         led \\\\\n",
      "            cold &          69 &         590 &  0.77 &        soft \\\\\n",
      "            swim &         100 &        1700 &  0.76 &        fish \\\\\n",
      "           juicy &          89 &         122 &  0.75 &  watermelon \\\\\n",
      "           round &          99 &        1034 &  0.74 &        held \\\\\n",
      "           sweet &          96 &          26 &  0.74 &       berry \\\\\n",
      "             red &          89 &        1275 &  0.69 &     designs \\\\\n",
      "            warm &         126 &        1181 &  0.69 &        thin \\\\\n",
      "    made\\_of\\_wood &          98 &         497 &  0.68 &      wooden \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# latex table for paper:\n",
    "cols = ['property', 'n_concepts', 'n_contexts', 'f1', 'contexts']\n",
    "df = df.sort_values('f1', ascending = False).round(2)\n",
    "print(df[cols].to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top distinctive contexts per prop\n",
    "\n",
    "# model_name = 'wiki_updated'\n",
    "# properties = get_properties()\n",
    "# table = get_top_distinctive_contexts(properties, model_name)\n",
    "# df = pd.DataFrame(table)\n",
    "# df.sort_values('f1', ascending = False).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer old annotations to new files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_properties' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fe648754263e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mproperties\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_name_current\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'giga_full_updated'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_name_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'giga_full'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_properties' is not defined"
     ]
    }
   ],
   "source": [
    "properties = get_properties()\n",
    "model_name_current = 'giga_full_updated'\n",
    "model_name_old = 'giga_full'\n",
    "\n",
    "\n",
    "for prop in properties:\n",
    "    # current file:\n",
    "    annotation_name = 'annotation-tfidf-top20-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    f_annotation_new = f'{path_dir_annotation}/annotation.csv'\n",
    "    f_annotation_tr = f'{path_dir_annotation}/annotation-transferred.csv'\n",
    "\n",
    "    # old file:\n",
    "    annotation_name = 'annotation-tfidf-top20-raw-10000'\n",
    "    path_dir_annotation = f'../analysis/{model_name_old}/{annotation_name}/{prop}-pos'\n",
    "    f_annotation_old = f'{path_dir_annotation}/annotation-done.csv'\n",
    "\n",
    "    # load old annotations\n",
    "    context_annotation_dict=dict()\n",
    "    with open(f_annotation_old) as infile:\n",
    "        data = list(csv.DictReader(infile))\n",
    "        for d in data:\n",
    "            c = d['context']\n",
    "            et = d['evidence']\n",
    "            context_annotation_dict[c] = et\n",
    "            #c = d['context']\n",
    "\n",
    "    # load new candidates\n",
    "\n",
    "    with open(f_annotation_new) as infile:\n",
    "        data = list(csv.DictReader(infile))\n",
    "\n",
    "    # fill in old annotations\n",
    "    for d in data:\n",
    "        c = d['context']\n",
    "        if c in context_annotation_dict:\n",
    "            et = context_annotation_dict[c]\n",
    "        else:\n",
    "            et = 'NA'\n",
    "        d['evidence_type'] = et\n",
    "\n",
    "    # write to new file\n",
    "\n",
    "    with open(f_annotation_tr, 'w') as outfile:\n",
    "        writer = csv.DictWriter(outfile, fieldnames = data[0].keys())\n",
    "        writer.writeheader()\n",
    "        for d in data:\n",
    "            writer.writerow(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found file\n",
      "found file\n",
      "found file\n"
     ]
    }
   ],
   "source": [
    "# transfer new annotations to updated f1 scores\n",
    "\n",
    "properties = get_properties()\n",
    "#properties = ['dangerous']\n",
    "model_name_current = 'giga_full_updated'\n",
    "model_name_old = 'giga_full'\n",
    "\n",
    "\n",
    "for prop in properties:\n",
    "    # current file:\n",
    "    annotation_name = 'annotation-tfidf-top_3_3-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    f_annotation_new = f'{path_dir_annotation}/annotation-updated.csv'\n",
    "    f_annotation_tr = f'{path_dir_annotation}/annotation-transferred-updated.csv'\n",
    "\n",
    "    # old file:\n",
    "    annotation_name = 'annotation-tfidf-top_3_5-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    f_annotation_old = f'{path_dir_annotation}/annotation-updated-done.csv'\n",
    "\n",
    "    # load old annotations\n",
    "    if os.path.isfile(f_annotation_old):\n",
    "        print('found file')\n",
    "        context_annotation_dict=dict()\n",
    "        with open(f_annotation_old) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "            for d in data:\n",
    "                c = d['context']\n",
    "                et = d['evidence_type']\n",
    "                context_annotation_dict[c] = et\n",
    "                #c = d['context']\n",
    "\n",
    "        # load new candidates\n",
    "\n",
    "        with open(f_annotation_new) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "\n",
    "        # fill in old annotations\n",
    "        for d in data:\n",
    "            c = d['context']\n",
    "            if c in context_annotation_dict:\n",
    "                et = context_annotation_dict[c]\n",
    "            else:\n",
    "                et = 'NA'\n",
    "            d['evidence_type'] = et\n",
    "\n",
    "        # write to new file\n",
    "\n",
    "        with open(f_annotation_tr, 'w') as outfile:\n",
    "            writer = csv.DictWriter(outfile, fieldnames = data[0].keys())\n",
    "            writer.writeheader()\n",
    "            for d in data:\n",
    "                writer.writerow(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square\n",
      "found file\n",
      "warm\n",
      "found file\n",
      "black\n",
      "found file\n",
      "red\n",
      "found file\n",
      "fly\n",
      "found file\n",
      "dangerous\n",
      "found file\n",
      "wings\n",
      "found file\n",
      "sweet\n",
      "found file\n",
      "hot\n",
      "found file\n",
      "used_in_cooking\n",
      "found file\n",
      "juicy\n",
      "found file\n",
      "green\n",
      "found file\n",
      "made_of_wood\n",
      "found file\n",
      "blue\n",
      "found file\n",
      "yellow\n",
      "found file\n",
      "roll\n",
      "found file\n",
      "female\n",
      "found file\n",
      "cold\n",
      "found file\n",
      "round\n",
      "found file\n",
      "wheels\n",
      "found file\n",
      "lay_eggs\n",
      "found file\n",
      "swim\n",
      "found file\n"
     ]
    }
   ],
   "source": [
    "# transfer giga annotations to wiki\n",
    "\n",
    "properties = get_properties()\n",
    "#properties = ['dangerous']\n",
    "model_name_current = 'wiki_updated'\n",
    "model_name_old = 'giga_full_updated'\n",
    "\n",
    "\n",
    "for prop in properties:\n",
    "    print(prop)\n",
    "    # current file:\n",
    "    annotation_name = 'annotation-tfidf-top_3_3-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name_current}/{annotation_name}/{prop}'\n",
    "    f_annotation_new = f'{path_dir_annotation}/annotation-updated.csv'\n",
    "    f_annotation_tr = f'{path_dir_annotation}/annotation-transferred-updated.csv'\n",
    "\n",
    "    # old file:\n",
    "    annotation_name = 'annotation-tfidf-top_3_3-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name_old}/{annotation_name}/{prop}'\n",
    "    f_annotation_old = f'{path_dir_annotation}/annotation-updated-done.csv'\n",
    "\n",
    "    # load old annotations\n",
    "    if os.path.isfile(f_annotation_old):\n",
    "        print('found file')\n",
    "        context_annotation_dict=dict()\n",
    "        with open(f_annotation_old) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "            for d in data:\n",
    "                c = d['context']\n",
    "                et = d['evidence_type']\n",
    "                context_annotation_dict[c] = et\n",
    "                #c = d['context']\n",
    "\n",
    "        # load new candidates\n",
    "\n",
    "        with open(f_annotation_new) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "\n",
    "        # fill in old annotations\n",
    "        for d in data:\n",
    "            c = d['context']\n",
    "            if c in context_annotation_dict:\n",
    "                et = context_annotation_dict[c]\n",
    "            else:\n",
    "                et = 'NA'\n",
    "            d['evidence_type'] = et\n",
    "\n",
    "        # write to new file\n",
    "\n",
    "        with open(f_annotation_tr, 'w') as outfile:\n",
    "            writer = csv.DictWriter(outfile, fieldnames = data[0].keys())\n",
    "            writer.writeheader()\n",
    "            for d in data:\n",
    "                writer.writerow(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotation_status(model_name, top_cutoff, concept_cutoff):\n",
    "    dir_path = f'../analysis/{model_name}'\n",
    "    dir_annotations = f'{dir_path}/annotation-tfidf-top_{top_cutoff}_{concept_cutoff}-raw-10000-categories'\n",
    "    annotation_dict = defaultdict(set)\n",
    "    line_dict = dict()\n",
    "\n",
    "    for f in os.listdir(dir_annotations):\n",
    "        if  not f.endswith('.csv') and not f.endswith('.ipynb_checkpoints'):\n",
    "            prop = f.split('/')[-1]\n",
    "            full_path = f'{dir_annotations}/{f}'\n",
    "            \n",
    "            #print(full_path)\n",
    "            # get categories:\n",
    "            files = os.listdir(full_path)\n",
    "            # get number of words\n",
    "            path_file = f'{full_path}/annotation-updated.csv'\n",
    "            with open(path_file) as infile:\n",
    "                lines = infile.read().strip().split('\\n')\n",
    "                not_annotated = [l for l in lines if l.strip().split(',')[1] == 'NA']\n",
    "            line_dict[prop] = (len(lines), len(not_annotated), len(lines)-len(not_annotated))\n",
    "            if 'annotation-updated-done.csv' in files:\n",
    "                annotation_dict['complete'].add(prop)\n",
    "            else:\n",
    "                annotation_dict['incomplete'].add(prop)\n",
    "                \n",
    "    return annotation_dict, line_dict\n",
    "\n",
    "def show_annotation_status(model_name, top_cutoff, concept_cutoff):\n",
    "    annotation_dict, line_dict = get_annotation_status(model_name, \n",
    "                                        top_cutoff, concept_cutoff)\n",
    "    # same category not annotated:\n",
    "    print('completed:\\n')\n",
    "    for prop in sorted(list(annotation_dict['complete'])):\n",
    "        # cats open:\n",
    "        print(prop, line_dict[prop])\n",
    "    print()\n",
    "    print('Incomplete:\\n')\n",
    "    for prop in sorted(annotation_dict['incomplete']):\n",
    "        if prop not in annotation_dict['complete']:\n",
    "            print(prop, line_dict[prop])\n",
    "    return annotation_dict\n",
    "            \n",
    "            \n",
    "def get_evidence_dict(model_name, prop, top_cutoff, concept_cutoff):\n",
    "    \n",
    "    annotation_name = f'annotation-tfidf-top_{top_cutoff}_{concept_cutoff}-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    f_annotation = f'{path_dir_annotation}/annotation-updated-done.csv'\n",
    "    \n",
    "    ev_dict = dict()\n",
    "    \n",
    "    with open(f_annotation) as infile:\n",
    "        data = list(csv.DictReader(infile))\n",
    "    for d in data:\n",
    "        et = d['evidence_type']\n",
    "        ev = d['context']\n",
    "        ev_dict[ev] = et\n",
    "    return ev_dict\n",
    "        \n",
    "            \n",
    "\n",
    "def get_evidence_distribution(model_name, prop, top_cutoff, concept_cutoff):\n",
    "    \n",
    "    # current file:\n",
    "    annotation_name = f'annotation-tfidf-top_{top_cutoff}_{concept_cutoff}-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    f_annotation = f'{path_dir_annotation}/annotation-updated-done.csv'\n",
    "    \n",
    "    ev_dict = get_evidence_dict(model_name, prop, top_cutoff, concept_cutoff)\n",
    "    \n",
    "    ev_cnts = Counter()\n",
    "    \n",
    "    for e, et in ev_dict.items():\n",
    "        ev_cnts[et] += 1\n",
    "        if et != 'u':\n",
    "            ev_cnts['all'] += 1\n",
    "        if et in ['p', 'l', 'n']:\n",
    "            ev_cnts['prop_specific'] += 1\n",
    "        elif et in ['i', 'r', 'b']:\n",
    "            ev_cnts['non-specific'] += 1\n",
    "    \n",
    "    total_contexts = len(ev_dict)\n",
    "    \n",
    "    ev_counts_norm = dict()\n",
    "    for ev, cnt in ev_cnts.items():\n",
    "        ev_counts_norm[ev]  = cnt/total_contexts\n",
    "    return ev_counts_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed:\n",
      "\n",
      "black (1150, 0, 1150)\n",
      "blue (2235, 0, 2235)\n",
      "cold (1082, 0, 1082)\n",
      "dangerous (1115, 0, 1115)\n",
      "female (46, 0, 46)\n",
      "fly (953, 0, 953)\n",
      "green (579, 0, 579)\n",
      "hot (85, 0, 85)\n",
      "juicy (811, 0, 811)\n",
      "lay_eggs (75, 0, 75)\n",
      "made_of_wood (787, 0, 787)\n",
      "red (1768, 0, 1768)\n",
      "roll (3887, 0, 3887)\n",
      "round (521, 0, 521)\n",
      "square (1505, 0, 1505)\n",
      "sweet (36, 0, 36)\n",
      "swim (1382, 0, 1382)\n",
      "used_in_cooking (573, 0, 573)\n",
      "warm (2109, 0, 2109)\n",
      "wheels (245, 0, 245)\n",
      "wings (561, 0, 561)\n",
      "yellow (53, 0, 53)\n",
      "\n",
      "Incomplete:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'giga_full_updated'\n",
    "top_cutoff = 3\n",
    "concept_cutoff = 3\n",
    "ann_dict = show_annotation_status(model_name, top_cutoff, concept_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property</th>\n",
       "      <th>u</th>\n",
       "      <th>all</th>\n",
       "      <th>prop_specific</th>\n",
       "      <th>non-specific</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>l</th>\n",
       "      <th>i</th>\n",
       "      <th>r</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>used_in_cooking</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.327</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sweet</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>female</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hot</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.095</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lay_eggs</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.095</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>green</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>wheels</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.094</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>wings</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>juicy</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dangerous</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>round</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yellow</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>blue</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cold</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.018</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>made_of_wood</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.034</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fly</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>red</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.003</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>warm</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>black</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.007</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>square</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>swim</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.030</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roll</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           property      u    all  prop_specific  non-specific      p      n  \\\n",
       "2   used_in_cooking  0.357  0.643          0.014         0.629  0.007  0.003   \n",
       "15            sweet  0.400  0.600          0.057         0.543  0.057    NaN   \n",
       "8            female  0.667  0.333          0.111         0.222    NaN  0.067   \n",
       "14              hot  0.702  0.298          0.036         0.262  0.024  0.012   \n",
       "13         lay_eggs  0.703  0.297          0.027         0.270  0.027    NaN   \n",
       "4             green  0.839  0.161          0.002         0.159  0.002    NaN   \n",
       "20           wheels  0.840  0.160          0.016         0.143  0.008    NaN   \n",
       "19            wings  0.850  0.150          0.011         0.139  0.002    NaN   \n",
       "18            juicy  0.880  0.120          0.002         0.117  0.002    NaN   \n",
       "10        dangerous  0.883  0.117          0.021         0.096  0.002  0.006   \n",
       "3             round  0.921  0.079          0.004         0.075  0.002    NaN   \n",
       "6            yellow  0.923  0.077          0.019         0.058  0.019    NaN   \n",
       "12             blue  0.925  0.075          0.001         0.074  0.001    NaN   \n",
       "9              cold  0.936  0.064          0.006         0.057  0.001  0.005   \n",
       "7      made_of_wood  0.941  0.059          0.004         0.055  0.004    NaN   \n",
       "11              fly  0.946  0.054          0.009         0.044  0.006  0.001   \n",
       "21              red  0.947  0.053          0.001         0.053  0.001    NaN   \n",
       "17             warm  0.948  0.052          0.004         0.048  0.002  0.000   \n",
       "16            black  0.956  0.044          0.002         0.043  0.001    NaN   \n",
       "5            square  0.960  0.040            NaN         0.040    NaN    NaN   \n",
       "0              swim  0.961  0.039          0.001         0.038  0.001    NaN   \n",
       "1              roll  0.963  0.037          0.002         0.035  0.001    NaN   \n",
       "\n",
       "        l      i      r      b  \n",
       "2   0.003  0.302  0.327    NaN  \n",
       "15    NaN  0.543    NaN    NaN  \n",
       "8   0.044  0.089  0.022  0.111  \n",
       "14    NaN  0.167  0.095    NaN  \n",
       "13    NaN  0.176  0.095    NaN  \n",
       "4     NaN  0.145  0.014    NaN  \n",
       "20  0.008  0.049  0.094    NaN  \n",
       "19  0.009  0.045  0.068  0.027  \n",
       "18    NaN  0.102  0.015    NaN  \n",
       "10  0.013  0.037  0.054  0.005  \n",
       "3   0.002  0.071  0.004    NaN  \n",
       "6     NaN  0.058    NaN    NaN  \n",
       "12    NaN  0.070  0.004    NaN  \n",
       "9     NaN  0.040  0.018    NaN  \n",
       "7     NaN  0.020  0.034    NaN  \n",
       "11  0.002  0.008  0.033  0.003  \n",
       "21    NaN  0.049  0.003    NaN  \n",
       "17  0.001  0.037  0.010    NaN  \n",
       "16  0.001  0.036  0.007    NaN  \n",
       "5     NaN  0.039  0.001    NaN  \n",
       "0     NaN  0.009  0.030    NaN  \n",
       "1   0.001  0.023  0.011    NaN  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'giga_full_updated'\n",
    "properties = ann_dict['complete']\n",
    "top_cutoff = 3\n",
    "concept_cutoff = 3\n",
    "\n",
    "cols = ['property', 'u', 'all', 'prop_specific', 'non-specific', 'p', 'n', 'l', 'i', 'r', 'b']\n",
    "table = []\n",
    "for prop in properties:\n",
    "    d = dict()\n",
    "    d['property'] =  prop\n",
    "    d.update(get_evidence_distribution(model_name, prop, top_cutoff, concept_cutoff))\n",
    "    for c in cols:\n",
    "        if c not in d:\n",
    "            d[c] = np.nan\n",
    "    table.append(d)\n",
    "   \n",
    "cols = ['property', 'u', 'all', 'prop_specific', 'non-specific', 'p', 'n', 'l', 'i', 'r', 'b']\n",
    "df = pd.DataFrame(table)[cols]\n",
    "df = df[cols].sort_values('all', ascending = False).round(3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrlrlllrll}\n",
      "\\toprule\n",
      "        property &      u &    all & prop\\_specific &  non-specific &      p &      n &      l &      i &      r &      b \\\\\n",
      "\\midrule\n",
      " used\\_in\\_cooking &  0.357 &  0.643 &         0.014 &         0.629 &  0.007 &  0.003 &  0.003 &  0.302 &  0.327 &      - \\\\\n",
      "           sweet &  0.400 &  0.600 &         0.057 &         0.543 &  0.057 &      - &      - &  0.543 &      - &      - \\\\\n",
      "          female &  0.667 &  0.333 &         0.111 &         0.222 &      - &  0.067 &  0.044 &  0.089 &  0.022 &  0.111 \\\\\n",
      "             hot &  0.702 &  0.298 &         0.036 &         0.262 &  0.024 &  0.012 &      - &  0.167 &  0.095 &      - \\\\\n",
      "        lay\\_eggs &  0.703 &  0.297 &         0.027 &         0.270 &  0.027 &      - &      - &  0.176 &  0.095 &      - \\\\\n",
      "           green &  0.839 &  0.161 &         0.002 &         0.159 &  0.002 &      - &      - &  0.145 &  0.014 &      - \\\\\n",
      "          wheels &  0.840 &  0.160 &         0.016 &         0.143 &  0.008 &      - &  0.008 &  0.049 &  0.094 &      - \\\\\n",
      "           wings &  0.850 &  0.150 &         0.011 &         0.139 &  0.002 &      - &  0.009 &  0.045 &  0.068 &  0.027 \\\\\n",
      "           juicy &  0.880 &  0.120 &         0.002 &         0.117 &  0.002 &      - &      - &  0.102 &  0.015 &      - \\\\\n",
      "       dangerous &  0.883 &  0.117 &         0.021 &         0.096 &  0.002 &  0.006 &  0.013 &  0.037 &  0.054 &  0.005 \\\\\n",
      "           round &  0.921 &  0.079 &         0.004 &         0.075 &  0.002 &      - &  0.002 &  0.071 &  0.004 &      - \\\\\n",
      "          yellow &  0.923 &  0.077 &         0.019 &         0.058 &  0.019 &      - &      - &  0.058 &      - &      - \\\\\n",
      "            blue &  0.925 &  0.075 &         0.001 &         0.074 &  0.001 &      - &      - &  0.070 &  0.004 &      - \\\\\n",
      "            cold &  0.936 &  0.064 &         0.006 &         0.057 &  0.001 &  0.005 &      - &  0.040 &  0.018 &      - \\\\\n",
      "    made\\_of\\_wood &  0.941 &  0.059 &         0.004 &         0.055 &  0.004 &      - &      - &  0.020 &  0.034 &      - \\\\\n",
      "             fly &  0.946 &  0.054 &         0.009 &         0.044 &  0.006 &  0.001 &  0.002 &  0.008 &  0.033 &  0.003 \\\\\n",
      "             red &  0.947 &  0.053 &         0.001 &         0.053 &  0.001 &      - &      - &  0.049 &  0.003 &      - \\\\\n",
      "            warm &  0.948 &  0.052 &         0.004 &         0.048 &  0.002 &      0 &  0.001 &  0.037 &   0.01 &      - \\\\\n",
      "           black &  0.956 &  0.044 &         0.002 &         0.043 &  0.001 &      - &  0.001 &  0.036 &  0.007 &      - \\\\\n",
      "          square &  0.960 &  0.040 &             - &         0.040 &      - &      - &      - &  0.039 &  0.001 &      - \\\\\n",
      "            swim &  0.961 &  0.039 &         0.001 &         0.038 &  0.001 &      - &      - &  0.009 &   0.03 &      - \\\\\n",
      "            roll &  0.963 &  0.037 &         0.002 &         0.035 &  0.001 &      - &  0.001 &  0.023 &  0.011 &      - \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.round(3).fillna('-').to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evidence distribution per semantic category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prop_data(prop):\n",
    "    \n",
    "    path = f'../data/aggregated_semantic_info/{prop}.json'\n",
    "    with open(path) as infile:\n",
    "        concept_dict = json.load(infile)\n",
    "    return concept_dict\n",
    "\n",
    "\n",
    "def load_concept_evidence(concept, prop, model_name, categories):\n",
    "    \n",
    "    categories.add('all')\n",
    "    contexts = set()\n",
    "    dir_path = f'../results/{model_name}/tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    \n",
    "    for cat in categories:\n",
    "        f_path = f'{dir_path}/{prop}/{cat}/pos/{concept}.csv'\n",
    "        if os.path.isfile(f_path):\n",
    "            with open(f_path) as infile:\n",
    "                data = list(csv.DictReader(infile))\n",
    "            for d in data:\n",
    "                context = d['']\n",
    "                diff = float(d['diff'])\n",
    "                if diff > 0:\n",
    "                    contexts.add(context)\n",
    "    return contexts  \n",
    "\n",
    "def get_categories(prop, model_name):\n",
    "    analysis_type = 'tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    path_dir = f'../results/{model_name}/{analysis_type}'\n",
    "    path_dir = f'{path_dir}/{prop}'\n",
    "    categories = set()\n",
    "    for d in os.listdir(path_dir):\n",
    "        if '.' not in d:\n",
    "            categories.add(d)\n",
    "    return categories\n",
    "\n",
    "def get_n_examples_cat(category, prop, model_name):\n",
    "    \n",
    "    analysis_type = 'tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    path_dir = f'../results/{model_name}/{analysis_type}'\n",
    "    path_dir = f'{path_dir}/{prop}/{category}'\n",
    "    \n",
    "    n_example_dict = dict()\n",
    "    for l in ['pos', 'neg']:\n",
    "        path = f'{path_dir}/{l}'\n",
    "        examples = os.listdir(path)\n",
    "        examples = [f for f in examples if f.endswith('.csv')]\n",
    "        n_example_dict[l] = len(examples)\n",
    "    return n_example_dict\n",
    "\n",
    "def get_top_ev_categories(prop, model_name, top_cutoff, concept_cutoff):\n",
    "    #table = dict()\n",
    "    aggregation_name = f'aggregated-tfidf-raw-10000-categories'\n",
    "    categories = get_categories(prop, model_name)\n",
    "    \n",
    "    path_dir_agg = f'../analysis/{model_name}/{aggregation_name}/{prop}'\n",
    "    evidence_dict = get_evidence_dict(model_name, prop, top_cutoff, concept_cutoff)\n",
    "    \n",
    "    et_context_dict = defaultdict(set)\n",
    "    for c, et in evidence_dict.items():\n",
    "        et_context_dict[et].add(c)\n",
    "    et_sorted = ['p', 'n', 'l', 'i', 'r', 'b', 'u'] \n",
    "    et_cat_context_perf_dict = defaultdict(dict)\n",
    "    \n",
    "    # get top performance per evidence type for each category\n",
    "    for cat in categories:\n",
    "        path = f'{path_dir_agg}/{cat}.csv'\n",
    "        n_example_dict = get_n_examples_cat(cat, prop, model_name)\n",
    "        # load file containing all concepts\n",
    "        with open(path) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "        perf_data = defaultdict(list)\n",
    "        for d in data:\n",
    "            f1 = float(d['f1'])\n",
    "            perf_data[f1].append(d)\n",
    "        perf_ranked =sorted(list(perf_data.keys()), reverse=True)\n",
    "        \n",
    "        # go through evidence types\n",
    "        for et in et_sorted:\n",
    "            contexts = et_context_dict[et]\n",
    "            for f1 in perf_ranked:\n",
    "                data = perf_data[f1]\n",
    "                contexts_f1 = [d['context'] for d in data]\n",
    "                contexts_et = set()\n",
    "                for c in contexts_f1:\n",
    "                    if c in contexts:\n",
    "                        contexts_et.add(c)\n",
    "                if len(contexts_et) > 0:\n",
    "                    et_cat_context_perf_dict[(cat, et)]['f1'] = round(f1, 2)\n",
    "                    et_cat_context_perf_dict[(cat, et)]['contexts'] = ' '.join(contexts_et)\n",
    "                    et_cat_context_perf_dict[(cat, et)].update(n_example_dict)\n",
    "                    break              \n",
    "                \n",
    "    return et_cat_context_perf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>contexts</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">all</th>\n",
       "      <th>p</th>\n",
       "      <td>0.87</td>\n",
       "      <td>flew</td>\n",
       "      <td>44</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0.77</td>\n",
       "      <td>hovering</td>\n",
       "      <td>44</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.75</td>\n",
       "      <td>lands</td>\n",
       "      <td>44</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.81</td>\n",
       "      <td>bird</td>\n",
       "      <td>44</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.82</td>\n",
       "      <td>wings</td>\n",
       "      <td>44</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.64</td>\n",
       "      <td>tourist</td>\n",
       "      <td>44</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0.81</td>\n",
       "      <td>overhead</td>\n",
       "      <td>44</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">food</th>\n",
       "      <th>p</th>\n",
       "      <td>1</td>\n",
       "      <td>fly</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0.8</td>\n",
       "      <td>hovering</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.64</td>\n",
       "      <td>landing</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.89</td>\n",
       "      <td>bird</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.85</td>\n",
       "      <td>mission sky</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.68</td>\n",
       "      <td>terrorist</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>1</td>\n",
       "      <td>shot route</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">object</th>\n",
       "      <th>p</th>\n",
       "      <td>0.86</td>\n",
       "      <td>flew</td>\n",
       "      <td>43</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0.77</td>\n",
       "      <td>hovering</td>\n",
       "      <td>43</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.74</td>\n",
       "      <td>lands</td>\n",
       "      <td>43</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.8</td>\n",
       "      <td>bird</td>\n",
       "      <td>43</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.82</td>\n",
       "      <td>wings</td>\n",
       "      <td>43</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.65</td>\n",
       "      <td>tourist</td>\n",
       "      <td>43</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0.81</td>\n",
       "      <td>overhead</td>\n",
       "      <td>43</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">bird</th>\n",
       "      <th>p</th>\n",
       "      <td>0.8</td>\n",
       "      <td>flying</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0.32</td>\n",
       "      <td>hovering</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.58</td>\n",
       "      <td>lands</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.65</td>\n",
       "      <td>bird</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.72</td>\n",
       "      <td>wings</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.43</td>\n",
       "      <td>tourist</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0.75</td>\n",
       "      <td>as</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">no-cat</th>\n",
       "      <th>p</th>\n",
       "      <td>1</td>\n",
       "      <td>flying fly flight flies</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>1</td>\n",
       "      <td>hovering</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>1</td>\n",
       "      <td>lands landing</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>1</td>\n",
       "      <td>satellite flags plane missile rocket</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>1</td>\n",
       "      <td>mail ticket pilot transportation mission delay...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1</td>\n",
       "      <td>tourists tourist terrorist</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>1</td>\n",
       "      <td>medical nine sitting details power directions ...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">communication</th>\n",
       "      <th>p</th>\n",
       "      <td>1</td>\n",
       "      <td>fly flight flew flown flies</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>1</td>\n",
       "      <td>hovering</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>1</td>\n",
       "      <td>lands</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>1</td>\n",
       "      <td>satellite plane</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>1</td>\n",
       "      <td>sky steered wings transportation arrival</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1</td>\n",
       "      <td>tourist</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>1</td>\n",
       "      <td>nine attached telling possibility luck mystery...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">measure</th>\n",
       "      <th>p</th>\n",
       "      <td>1</td>\n",
       "      <td>flying fly</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.81</td>\n",
       "      <td>flags plane missile airplanes</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>1</td>\n",
       "      <td>radar crew wings</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.84</td>\n",
       "      <td>tourists</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>1</td>\n",
       "      <td>facing la grand defense executive focus injure...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">animal</th>\n",
       "      <th>p</th>\n",
       "      <td>0.88</td>\n",
       "      <td>flew</td>\n",
       "      <td>31</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0.66</td>\n",
       "      <td>hovering</td>\n",
       "      <td>31</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.7</td>\n",
       "      <td>lands</td>\n",
       "      <td>31</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.86</td>\n",
       "      <td>bird</td>\n",
       "      <td>31</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.81</td>\n",
       "      <td>wings</td>\n",
       "      <td>31</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.65</td>\n",
       "      <td>tourist</td>\n",
       "      <td>31</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0.77</td>\n",
       "      <td>habitat</td>\n",
       "      <td>31</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">vehicle</th>\n",
       "      <th>p</th>\n",
       "      <td>0.95</td>\n",
       "      <td>flying</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0.98</td>\n",
       "      <td>hovering</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.93</td>\n",
       "      <td>landing</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.95</td>\n",
       "      <td>airplanes</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.95</td>\n",
       "      <td>ejected aerial altitude</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.77</td>\n",
       "      <td>tourists</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0.98</td>\n",
       "      <td>overhead study experimental payload</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">mammal</th>\n",
       "      <th>p</th>\n",
       "      <td>0.94</td>\n",
       "      <td>flight</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0.88</td>\n",
       "      <td>hovering</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.9</td>\n",
       "      <td>landing</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>1</td>\n",
       "      <td>airplanes</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>1</td>\n",
       "      <td>vehicles</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.9</td>\n",
       "      <td>terrorist</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>1</td>\n",
       "      <td>drawing video throughout industries target con...</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">relation</th>\n",
       "      <th>p</th>\n",
       "      <td>0.87</td>\n",
       "      <td>flown flew</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.87</td>\n",
       "      <td>landing</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.87</td>\n",
       "      <td>drone plane airplanes</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>1</td>\n",
       "      <td>cloud</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.69</td>\n",
       "      <td>tourists terrorist</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>1</td>\n",
       "      <td>black makes checked ranch colors</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">fish</th>\n",
       "      <th>p</th>\n",
       "      <td>1</td>\n",
       "      <td>flying flown flew</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0.94</td>\n",
       "      <td>hovering</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>1</td>\n",
       "      <td>landing</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>1</td>\n",
       "      <td>rocket missile</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>1</td>\n",
       "      <td>delays altitude air sky engine vehicles pilot ...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>1</td>\n",
       "      <td>medical climbed operated engineer 16 officials...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   f1                                           contexts pos  \\\n",
       "all           p  0.87                                               flew  44   \n",
       "              n  0.77                                           hovering  44   \n",
       "              l  0.75                                              lands  44   \n",
       "              i  0.81                                               bird  44   \n",
       "              r  0.82                                              wings  44   \n",
       "              b  0.64                                            tourist  44   \n",
       "              u  0.81                                           overhead  44   \n",
       "food          p     1                                                fly   6   \n",
       "              n   0.8                                           hovering   6   \n",
       "              l  0.64                                            landing   6   \n",
       "              i  0.89                                               bird   6   \n",
       "              r  0.85                                        mission sky   6   \n",
       "              b  0.68                                          terrorist   6   \n",
       "              u     1                                         shot route   6   \n",
       "object        p  0.86                                               flew  43   \n",
       "              n  0.77                                           hovering  43   \n",
       "              l  0.74                                              lands  43   \n",
       "              i   0.8                                               bird  43   \n",
       "              r  0.82                                              wings  43   \n",
       "              b  0.65                                            tourist  43   \n",
       "              u  0.81                                           overhead  43   \n",
       "bird          p   0.8                                             flying  28   \n",
       "              n  0.32                                           hovering  28   \n",
       "              l  0.58                                              lands  28   \n",
       "              i  0.65                                               bird  28   \n",
       "              r  0.72                                              wings  28   \n",
       "              b  0.43                                            tourist  28   \n",
       "              u  0.75                                                 as  28   \n",
       "no-cat        p     1                            flying fly flight flies   4   \n",
       "              n     1                                           hovering   4   \n",
       "              l     1                                      lands landing   4   \n",
       "              i     1               satellite flags plane missile rocket   4   \n",
       "              r     1  mail ticket pilot transportation mission delay...   4   \n",
       "              b     1                         tourists tourist terrorist   4   \n",
       "              u     1  medical nine sitting details power directions ...   4   \n",
       "communication p     1                        fly flight flew flown flies   3   \n",
       "              n     1                                           hovering   3   \n",
       "              l     1                                              lands   3   \n",
       "              i     1                                    satellite plane   3   \n",
       "              r     1           sky steered wings transportation arrival   3   \n",
       "              b     1                                            tourist   3   \n",
       "              u     1  nine attached telling possibility luck mystery...   3   \n",
       "measure       p     1                                         flying fly   2   \n",
       "              i  0.81                      flags plane missile airplanes   2   \n",
       "              r     1                                   radar crew wings   2   \n",
       "              b  0.84                                           tourists   2   \n",
       "              u     1  facing la grand defense executive focus injure...   2   \n",
       "animal        p  0.88                                               flew  31   \n",
       "              n  0.66                                           hovering  31   \n",
       "              l   0.7                                              lands  31   \n",
       "              i  0.86                                               bird  31   \n",
       "              r  0.81                                              wings  31   \n",
       "              b  0.65                                            tourist  31   \n",
       "              u  0.77                                            habitat  31   \n",
       "vehicle       p  0.95                                             flying  10   \n",
       "              n  0.98                                           hovering  10   \n",
       "              l  0.93                                            landing  10   \n",
       "              i  0.95                                          airplanes  10   \n",
       "              r  0.95                            ejected aerial altitude  10   \n",
       "              b  0.77                                           tourists  10   \n",
       "              u  0.98                overhead study experimental payload  10   \n",
       "mammal        p  0.94                                             flight   1   \n",
       "              n  0.88                                           hovering   1   \n",
       "              l   0.9                                            landing   1   \n",
       "              i     1                                          airplanes   1   \n",
       "              r     1                                           vehicles   1   \n",
       "              b   0.9                                          terrorist   1   \n",
       "              u     1  drawing video throughout industries target con...   1   \n",
       "relation      p  0.87                                         flown flew   2   \n",
       "              l  0.87                                            landing   2   \n",
       "              i  0.87                              drone plane airplanes   2   \n",
       "              r     1                                              cloud   2   \n",
       "              b  0.69                                 tourists terrorist   2   \n",
       "              u     1                   black makes checked ranch colors   2   \n",
       "fish          p     1                                  flying flown flew   1   \n",
       "              n  0.94                                           hovering   1   \n",
       "              l     1                                            landing   1   \n",
       "              i     1                                     rocket missile   1   \n",
       "              r     1  delays altitude air sky engine vehicles pilot ...   1   \n",
       "              u     1  medical climbed operated engineer 16 officials...   1   \n",
       "\n",
       "                neg  \n",
       "all           p  90  \n",
       "              n  90  \n",
       "              l  90  \n",
       "              i  90  \n",
       "              r  90  \n",
       "              b  90  \n",
       "              u  90  \n",
       "food          p  14  \n",
       "              n  14  \n",
       "              l  14  \n",
       "              i  14  \n",
       "              r  14  \n",
       "              b  14  \n",
       "              u  14  \n",
       "object        p  89  \n",
       "              n  89  \n",
       "              l  89  \n",
       "              i  89  \n",
       "              r  89  \n",
       "              b  89  \n",
       "              u  89  \n",
       "bird          p   9  \n",
       "              n   9  \n",
       "              l   9  \n",
       "              i   9  \n",
       "              r   9  \n",
       "              b   9  \n",
       "              u   9  \n",
       "no-cat        p   5  \n",
       "              n   5  \n",
       "              l   5  \n",
       "              i   5  \n",
       "              r   5  \n",
       "              b   5  \n",
       "              u   5  \n",
       "communication p   6  \n",
       "              n   6  \n",
       "              l   6  \n",
       "              i   6  \n",
       "              r   6  \n",
       "              b   6  \n",
       "              u   6  \n",
       "measure       p   4  \n",
       "              i   4  \n",
       "              r   4  \n",
       "              b   4  \n",
       "              u   4  \n",
       "animal        p  57  \n",
       "              n  57  \n",
       "              l  57  \n",
       "              i  57  \n",
       "              r  57  \n",
       "              b  57  \n",
       "              u  57  \n",
       "vehicle       p  33  \n",
       "              n  33  \n",
       "              l  33  \n",
       "              i  33  \n",
       "              r  33  \n",
       "              b  33  \n",
       "              u  33  \n",
       "mammal        p  34  \n",
       "              n  34  \n",
       "              l  34  \n",
       "              i  34  \n",
       "              r  34  \n",
       "              b  34  \n",
       "              u  34  \n",
       "relation      p   7  \n",
       "              l   7  \n",
       "              i   7  \n",
       "              r   7  \n",
       "              b   7  \n",
       "              u   7  \n",
       "fish          p  14  \n",
       "              n  14  \n",
       "              l  14  \n",
       "              i  14  \n",
       "              r  14  \n",
       "              u  14  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop = 'fly'\n",
    "model_name = 'giga_full_updated'\n",
    "top_cutoff = 3\n",
    "concept_cutoff = 3\n",
    "table = get_top_ev_categories(prop, model_name, top_cutoff, concept_cutoff)\n",
    "df = pd.DataFrame(table)\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean per cat\n",
    "\n",
    "properties = get_properties()\n",
    "prop_table = []\n",
    "for prop in properties:\n",
    "    table = get_top_ev_categories(prop, model_name, top_cutoff, concept_cutoff)\n",
    "    type_scores = defaultdict(list)\n",
    "    ev_type_mean_scores = dict()\n",
    "    for (cat, ev_type), f1_dict in table.items():\n",
    "        type_scores[ev_type].append(f1_dict['f1'])\n",
    "    for ev_type, scores in type_scores.items():\n",
    "        mean = sum(scores)/len(scores)\n",
    "        prop_dict = dict()\n",
    "        ev_type_mean_scores[ev_type] = mean\n",
    "    prop_dict['property'] = prop\n",
    "    prop_dict.update(ev_type_mean_scores)\n",
    "    prop_table.append(prop_dict)\n",
    "    \n",
    "cols = ['property', 'p', 'n', 'l', 'i', 'r', 'b', 'u']\n",
    "df = pd.DataFrame(prop_table)\n",
    "df = df[cols].sort_values('p', ascending = False).round(2).fillna('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>l</th>\n",
       "      <th>i</th>\n",
       "      <th>r</th>\n",
       "      <th>b</th>\n",
       "      <th>u</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>used_in_cooking</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fly</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>wheels</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>made_of_wood</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.88</td>\n",
       "      <td>-</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sweet</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>roll</td>\n",
       "      <td>0.87</td>\n",
       "      <td>-</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lay_eggs</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.88</td>\n",
       "      <td>-</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>green</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wings</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>juicy</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hot</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dangerous</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>red</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.77</td>\n",
       "      <td>-</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>blue</td>\n",
       "      <td>0.79</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>yellow</td>\n",
       "      <td>0.79</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>black</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.77</td>\n",
       "      <td>-</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cold</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>round</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>warm</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>swim</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>-</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>square</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.79</td>\n",
       "      <td>-</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>female</td>\n",
       "      <td>-</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           property     p     n     l     i     r     b     u\n",
       "9   used_in_cooking  0.95  0.74   0.9  0.98  0.98     -  0.96\n",
       "4               fly  0.93  0.81  0.83  0.89  0.91  0.75  0.93\n",
       "19           wheels   0.9     -  0.81  0.92  0.92     -  0.87\n",
       "12     made_of_wood   0.9     -     -  0.86  0.88     -  0.92\n",
       "7             sweet   0.9     -     -  0.92     -     -  0.88\n",
       "15             roll  0.87     -  0.76  0.91  0.92     -  0.95\n",
       "20         lay_eggs  0.86     -     -  0.92  0.88     -  0.90\n",
       "11            green  0.86     -     -  0.87  0.81     -  0.93\n",
       "6             wings  0.85     -  0.85  0.89  0.88  0.81  0.90\n",
       "10            juicy  0.83     -     -  0.90  0.86     -  0.91\n",
       "8               hot  0.83  0.69     -  0.92  0.89     -  0.88\n",
       "5         dangerous  0.81  0.92  0.88  0.92  0.94   0.8  0.96\n",
       "3               red   0.8     -     -  0.88  0.77     -  0.91\n",
       "13             blue  0.79     -     -  0.95   0.9     -  0.96\n",
       "14           yellow  0.79     -     -  0.81     -     -  0.94\n",
       "2             black  0.75     -  0.66  0.87  0.77     -  0.93\n",
       "17             cold   0.7  0.85     -  0.90  0.81     -  0.94\n",
       "18            round  0.68     -   0.5  0.90  0.64     -  0.93\n",
       "1              warm  0.67  0.75  0.72  0.87  0.86     -  0.93\n",
       "21             swim  0.67     -     -  0.89  0.88     -  0.88\n",
       "0            square     -     -     -  0.96  0.79     -  0.97\n",
       "16           female     -  0.86   0.7  0.89  0.58  0.85  0.91"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllrllr}\n",
      "\\toprule\n",
      "        property &     p &     n &     l &     i &     r &     b &     u \\\\\n",
      "\\midrule\n",
      " used\\_in\\_cooking &  0.95 &  0.74 &   0.9 &  0.98 &  0.98 &     - &  0.96 \\\\\n",
      "             fly &  0.93 &  0.81 &  0.83 &  0.89 &  0.91 &  0.75 &  0.93 \\\\\n",
      "          wheels &   0.9 &     - &  0.81 &  0.92 &  0.92 &     - &  0.87 \\\\\n",
      "    made\\_of\\_wood &   0.9 &     - &     - &  0.86 &  0.88 &     - &  0.92 \\\\\n",
      "           sweet &   0.9 &     - &     - &  0.92 &     - &     - &  0.88 \\\\\n",
      "            roll &  0.87 &     - &  0.76 &  0.91 &  0.92 &     - &  0.95 \\\\\n",
      "        lay\\_eggs &  0.86 &     - &     - &  0.92 &  0.88 &     - &  0.90 \\\\\n",
      "           green &  0.86 &     - &     - &  0.87 &  0.81 &     - &  0.93 \\\\\n",
      "           wings &  0.85 &     - &  0.85 &  0.89 &  0.88 &  0.81 &  0.90 \\\\\n",
      "           juicy &  0.83 &     - &     - &  0.90 &  0.86 &     - &  0.91 \\\\\n",
      "             hot &  0.83 &  0.69 &     - &  0.92 &  0.89 &     - &  0.88 \\\\\n",
      "       dangerous &  0.81 &  0.92 &  0.88 &  0.92 &  0.94 &   0.8 &  0.96 \\\\\n",
      "             red &   0.8 &     - &     - &  0.88 &  0.77 &     - &  0.91 \\\\\n",
      "            blue &  0.79 &     - &     - &  0.95 &   0.9 &     - &  0.96 \\\\\n",
      "          yellow &  0.79 &     - &     - &  0.81 &     - &     - &  0.94 \\\\\n",
      "           black &  0.75 &     - &  0.66 &  0.87 &  0.77 &     - &  0.93 \\\\\n",
      "            cold &   0.7 &  0.85 &     - &  0.90 &  0.81 &     - &  0.94 \\\\\n",
      "           round &  0.68 &     - &   0.5 &  0.90 &  0.64 &     - &  0.93 \\\\\n",
      "            warm &  0.67 &  0.75 &  0.72 &  0.87 &  0.86 &     - &  0.93 \\\\\n",
      "            swim &  0.67 &     - &     - &  0.89 &  0.88 &     - &  0.88 \\\\\n",
      "          square &     - &     - &     - &  0.96 &  0.79 &     - &  0.97 \\\\\n",
      "          female &     - &  0.86 &   0.7 &  0.89 &  0.58 &  0.85 &  0.91 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evidence strength\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_tfidf_scores_context(prop, cat, contexts, model_name):\n",
    "    \n",
    "    # collect scores here:\n",
    "    context_tfidf_dict = defaultdict(dict)\n",
    "\n",
    "    # get tfidf scores\n",
    "    path_tfidfs = f'../results/{model_name}/tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    path_tfidfs = f'{path_tfidfs}/{prop}/{cat}/pos'\n",
    "    concept_files = [f for f in os.listdir(path_tfidfs) if f.endswith('.csv')]\n",
    "    \n",
    "    for cf in concept_files:\n",
    "        full_path = f'{path_tfidfs}/{cf}'\n",
    "        concept = cf.split('.')[0]\n",
    "        with open(full_path) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "        for cw_target in contexts:\n",
    "            found = False\n",
    "            for d in data:\n",
    "                cw = d['']\n",
    "                score = d['target']\n",
    "                if cw == cw_target:\n",
    "                    context_tfidf_dict[cw][concept] = (float(score))\n",
    "                    found = True\n",
    "                    break\n",
    "            if found == False:\n",
    "                context_tfidf_dict[cw_target][concept]  = 0.0\n",
    "    return context_tfidf_dict\n",
    "\n",
    "\n",
    "def evidence_strength_to_file(prop, et, contexts, model_name, top_cutoff, concept_cutoff):\n",
    "\n",
    "    filepath_target = f'../analysis/{model_name}/evidence_{top_cutoff}_{concept_cutoff}-raw-10000-categories'\n",
    "    filepath_target_et = f'{filepath_target}/{prop}/{et}'\n",
    "    os.makedirs(filepath_target_et, exist_ok=True)\n",
    "    categories = get_categories(prop, model_name)\n",
    "    tfidf_scores_cats = dict()\n",
    "              \n",
    "    for context in contexts:\n",
    "        full_filepath = f'{filepath_target_et}/{context}.csv'\n",
    "        for cat in categories:\n",
    "            tfidf_scores_cats[cat] = get_tfidf_scores_context(prop, cat, contexts, model_name)[context]\n",
    "            #print(cat, tfidf_scores_cats[cat]['wren'])\n",
    "        df = pd.DataFrame(tfidf_scores_cats)\n",
    "        df['mean'] = df.mean(numeric_only=True, axis = 1)\n",
    "        df.to_csv(full_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-c14ebfa57db6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mcontexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'contexts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mevidence_strength_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0met_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcept_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-116-5af26de7de1f>\u001b[0m in \u001b[0;36mevidence_strength_to_file\u001b[0;34m(prop, et, contexts, model_name, top_cutoff, concept_cutoff)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mfull_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{filepath_target_et}/{context}.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mtfidf_scores_cats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tfidf_scores_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0;31m#print(cat, tfidf_scores_cats[cat]['wren'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_scores_cats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-116-5af26de7de1f>\u001b[0m in \u001b[0;36mget_tfidf_scores_context\u001b[0;34m(prop, cat, contexts, model_name)\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mcw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mcw\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcw_target\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                     \u001b[0mcontext_tfidf_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconcept\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name = 'giga_full_updated'\n",
    "properties = get_properties()\n",
    "\n",
    "top_cutoff = 3\n",
    "concept_cutoff = 3\n",
    "\n",
    "\n",
    "for prop in properties:\n",
    "    table = get_top_ev_categories(prop, model_name, top_cutoff, concept_cutoff)\n",
    "\n",
    "    ets = ['i', 'r', 'b']\n",
    "    for et_target in ets:\n",
    "        contexts = set()\n",
    "        for (cat, et), d in table.items():\n",
    "            if et_target == et:\n",
    "                contexts.update(set(d['contexts'].split(' ')))\n",
    "        if len(contexts) > 0:\n",
    "            evidence_strength_to_file(prop, et_target, contexts, model_name, top_cutoff, concept_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prop_specific</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>juicy</th>\n",
       "      <td>0.0521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red</th>\n",
       "      <td>0.0332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lay_eggs</th>\n",
       "      <td>0.0284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yellow</th>\n",
       "      <td>0.0277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hot</th>\n",
       "      <td>0.0264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.0255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>green</th>\n",
       "      <td>0.0224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>made_of_wood</th>\n",
       "      <td>0.0208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wheels</th>\n",
       "      <td>0.0149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>used_in_cooking</th>\n",
       "      <td>0.0144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue</th>\n",
       "      <td>0.0144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sweet</th>\n",
       "      <td>0.0131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wings</th>\n",
       "      <td>0.0107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fly</th>\n",
       "      <td>0.0106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>0.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.0079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roll</th>\n",
       "      <td>0.0066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dangerous</th>\n",
       "      <td>0.0051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>round</th>\n",
       "      <td>0.0051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swim</th>\n",
       "      <td>0.0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warm</th>\n",
       "      <td>0.0042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>square</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 prop_specific\n",
       "juicy                   0.0521\n",
       "red                     0.0332\n",
       "lay_eggs                0.0284\n",
       "yellow                  0.0277\n",
       "hot                     0.0264\n",
       "female                  0.0255\n",
       "green                   0.0224\n",
       "made_of_wood            0.0208\n",
       "wheels                  0.0149\n",
       "used_in_cooking         0.0144\n",
       "blue                    0.0144\n",
       "sweet                   0.0131\n",
       "wings                   0.0107\n",
       "fly                     0.0106\n",
       "black                   0.0104\n",
       "cold                    0.0079\n",
       "roll                    0.0066\n",
       "dangerous               0.0051\n",
       "round                   0.0051\n",
       "swim                    0.0043\n",
       "warm                    0.0042\n",
       "square                  0.0000"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare evidence strength across properties - may not make too much sense...\n",
    "\n",
    "ets = ['p', 'l', 'n']\n",
    "properties = get_properties()\n",
    "\n",
    "model_name = 'giga_full_updated'\n",
    "\n",
    "top_cutoff = 3\n",
    "concept_cutoff = 3\n",
    "\n",
    "prop_et_strength_dict = defaultdict(dict)\n",
    "\n",
    "path_evidence = f'../analysis/{model_name}/evidence_{top_cutoff}_{concept_cutoff}-raw-10000-categories'\n",
    "\n",
    "for prop in properties:\n",
    "    means_prop = []\n",
    "    for et in ets:\n",
    "        means_et = []\n",
    "        path_dir = f'{path_evidence}/{prop}/{et}'\n",
    "        if os.path.isdir(path_dir):\n",
    "            ev_files = [f for f in os.listdir(path_dir) if f.endswith('.csv')]\n",
    "            for f in ev_files:\n",
    "                full_path = f'{path_dir}/{f}'\n",
    "                with open(full_path) as infile:\n",
    "                    data = list(csv.DictReader(infile))\n",
    "                    means = [float(d['mean']) for d in data]\n",
    "                    mean = sum(means)/len(means)\n",
    "                    #means_et.append(mean)\n",
    "                    means_prop.append(mean)\n",
    "    if len(means_prop) > 0:\n",
    "        mean_prop = sum(means_prop)/len(means_prop)\n",
    "    else:\n",
    "        mean_prop = 0.0\n",
    "    prop_et_strength_dict[prop]['prop_specific'] = mean_prop\n",
    "            \n",
    "df = pd.DataFrame(prop_et_strength_dict)\n",
    "df.T.sort_values('prop_specific', ascending=False).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import stdev\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  \n",
    "def get_relation_combinations(properties, combinations):\n",
    "    \n",
    "    relation_pair_dict = defaultdict(set)\n",
    "    for prop in properties:\n",
    "        prop_dict = load_prop_data(prop)\n",
    "        for c, d in prop_dict.items():\n",
    "            ml_label = d['ml_label']\n",
    "            if ml_label in {'all', 'some', 'all-some', 'few-some'}:\n",
    "                l = 'pos'\n",
    "            elif ml_label in {'few'}:\n",
    "                l = 'neg'\n",
    "#             relation_pair_dict[l].add((prop, c))\n",
    "            if l == 'pos':\n",
    "                rel_dict = d['relations']\n",
    "                for combination in combinations:\n",
    "                    relations = set([rel for rel, p in rel_dict.items() if p > 0.5])\n",
    "                    if combination == relations:\n",
    "                        l_comb = tuple(sorted(relations))\n",
    "                        relation_pair_dict[l_comb].add((prop, c))\n",
    "    return relation_pair_dict   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('implied_category', 'variability_limited') 21\n",
      "('implied_category',) 16\n",
      "\n",
      "{('swim', 'cob'), ('round', 'pepperoni'), ('wheels', 'saloon'), ('lay_eggs', 'crane'), ('wings', 'roach'), ('roll', 'bike'), ('wheels', 'underframe'), ('wings', 'cricket'), ('swim', 'bay'), ('wheels', 'tank'), ('round', 'patty'), ('lay_eggs', 'neritidae'), ('round', 'cherry'), ('dangerous', 'pentobarbital'), ('lay_eggs', 'flounder'), ('warm', 'brogue')}\n",
      "\n",
      "{('made_of_wood', 'girder'), ('green', 'fenugreek'), ('wings', 'beetle'), ('square', 'blackboard'), ('round', 'lemon'), ('juicy', 'anjou'), ('round', 'pineapple'), ('fly', 'fowl'), ('round', 'gourd'), ('sweet', 'carrot'), ('round', 'cabbage'), ('made_of_wood', 'transom'), ('square', 'laptop'), ('made_of_wood', 'ladle'), ('square', 'computer'), ('round', 'nutlet'), ('roll', 'cart'), ('sweet', 'breadfruit'), ('round', 'sapodilla'), ('round', 'onion'), ('red', 'tongue')}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get prop concept pairs with a certain relation-configuration:\n",
    "combinations = [\n",
    "                    {'implied_category'},\n",
    "                    {'implied_category', 'variability_limited'},\n",
    "                    ]\n",
    "\n",
    "properties = get_properties()\n",
    "relation_pair_dict = get_relation_combinations(properties, combinations)\n",
    "for rel, pairs in relation_pair_dict.items():\n",
    "     print(rel, len(pairs)) \n",
    "print()\n",
    "print(relation_pair_dict[('implied_category',  )]) \n",
    "print()\n",
    "print(relation_pair_dict[('implied_category', 'variability_limited', )])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus on prop-specific evidence types\n",
    "\n",
    "\n",
    "def get_tfidf_pair(prop, concept, model_name, top_cutoff, concept_cutoff):\n",
    "    \n",
    "    path_evidence = f'../analysis/{model_name}/evidence_{top_cutoff}_{concept_cutoff}-raw-10000-categories'\n",
    "    tfidf_scores = []\n",
    "    for et in ets:\n",
    "        path_prop_et = f'{path_evidence}/{prop}/{et}'\n",
    "        if os.path.isdir(path_prop_et):\n",
    "            files = [f for f in os.listdir(path_prop_et) if f.endswith('.csv')]\n",
    "            for f in files:\n",
    "                full_path = f'{path_prop_et}/{f}'\n",
    "                with open(full_path) as infile:\n",
    "                    data = list(csv.DictReader(infile))\n",
    "                for d in data:\n",
    "                    if d[''] == concept:\n",
    "                        tfidf = d['mean']\n",
    "                        tfidf_scores.append(float(tfidf))\n",
    "                        break\n",
    "    if len(tfidf_scores) > 0:\n",
    "        mean = sum(tfidf_scores)/len(tfidf_scores)\n",
    "    else:\n",
    "        mean = 0.0\n",
    "    return mean\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027778310835282503\n"
     ]
    }
   ],
   "source": [
    "# test for one pair:\n",
    "\n",
    "pair = ('red', 'tomato')\n",
    "\n",
    "ets = ['p', 'l', 'n']\n",
    "\n",
    "properties = get_properties()\n",
    "\n",
    "model_name = 'giga_full_updated'\n",
    "\n",
    "top_cutoff = 3\n",
    "concept_cutoff = 3\n",
    "prop, concept = pair\n",
    "mean = get_tfidf_pair(prop, concept, model_name, top_cutoff, concept_cutoff)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002814759990160404\n"
     ]
    }
   ],
   "source": [
    "combination = ('implied_category', )\n",
    "combinations = [set(combination)]\n",
    "relation_pair_dict = get_relation_combinations(properties, combinations)\n",
    "pairs = relation_pair_dict[combination]\n",
    "means = []\n",
    "for prop, concept in pairs:\n",
    "    means.append(get_tfidf_pair(prop, concept, model_name, top_cutoff, concept_cutoff))\n",
    "print(sum(means)/len(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012240007649826072\n"
     ]
    }
   ],
   "source": [
    "combination = ('variability_limited', )\n",
    "combinations = [set(combination)]\n",
    "relation_pair_dict = get_relation_combinations(properties, combinations)\n",
    "pairs = relation_pair_dict[combination]\n",
    "means = []\n",
    "for prop, concept in pairs:\n",
    "    means.append(get_tfidf_pair(prop, concept, model_name, top_cutoff, concept_cutoff))\n",
    "print(sum(means)/len(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004005841600065764\n"
     ]
    }
   ],
   "source": [
    "combination = ('implied_category', 'variability_limited')\n",
    "combinations = [set(combination)]\n",
    "relation_pair_dict = get_relation_combinations(properties, combinations)\n",
    "pairs = relation_pair_dict[combination]\n",
    "means = []\n",
    "for prop, concept in pairs:\n",
    "    means.append(get_tfidf_pair(prop, concept, model_name, top_cutoff, concept_cutoff))\n",
    "print(sum(means)/len(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006245812417314189\n"
     ]
    }
   ],
   "source": [
    "combination = ('variability_open', )\n",
    "combinations = [set(combination)]\n",
    "relation_pair_dict = get_relation_combinations(properties, combinations)\n",
    "pairs = relation_pair_dict[combination]\n",
    "means = []\n",
    "for prop, concept in pairs:\n",
    "    means.append(get_tfidf_pair(prop, concept, model_name, top_cutoff, concept_cutoff))\n",
    "print(sum(means)/len(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0028201754340966283\n"
     ]
    }
   ],
   "source": [
    "combination = ('implied_category', 'variability_open')\n",
    "combinations = [set(combination)]\n",
    "relation_pair_dict = get_relation_combinations(properties, combinations)\n",
    "pairs = relation_pair_dict[combination]\n",
    "means = []\n",
    "for prop, concept in pairs:\n",
    "    means.append(get_tfidf_pair(prop, concept, model_name, top_cutoff, concept_cutoff))\n",
    "print(sum(means)/len(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-8514a5be60f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcept\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_tfidf_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcept_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "combination = ('typical_of_property', )\n",
    "combinations = [set(combination)]\n",
    "relation_pair_dict = get_relation_combinations(properties, combinations)\n",
    "pairs = relation_pair_dict[combination]\n",
    "means = []\n",
    "for prop, concept in pairs:\n",
    "    means.append(get_tfidf_pair(prop, concept, model_name, top_cutoff, concept_cutoff))\n",
    "print(sum(means)/len(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01861648532852521\n"
     ]
    }
   ],
   "source": [
    "combination = ('typical_of_concept', )\n",
    "combinations = [set(combination)]\n",
    "relation_pair_dict = get_relation_combinations(properties, combinations)\n",
    "pairs = relation_pair_dict[combination]\n",
    "means = []\n",
    "for prop, concept in pairs:\n",
    "    means.append(get_tfidf_pair(prop, concept, model_name, top_cutoff, concept_cutoff))\n",
    "print(sum(means)/len(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03678590649896033\n"
     ]
    }
   ],
   "source": [
    "combination = ('afforded_usual', )\n",
    "combinations = [set(combination)]\n",
    "relation_pair_dict = get_relation_combinations(properties, combinations)\n",
    "pairs = relation_pair_dict[combination]\n",
    "means = []\n",
    "for prop, concept in pairs:\n",
    "    means.append(get_tfidf_pair(prop, concept, model_name, top_cutoff, concept_cutoff))\n",
    "print(sum(means)/len(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0016719489904147\n"
     ]
    }
   ],
   "source": [
    "combination = ('afforded_unusual', )\n",
    "combinations = [set(combination)]\n",
    "relation_pair_dict = get_relation_combinations(properties, combinations)\n",
    "pairs = relation_pair_dict[combination]\n",
    "means = []\n",
    "for prop, concept in pairs:\n",
    "    means.append(get_tfidf_pair(prop, concept, model_name, top_cutoff, concept_cutoff))\n",
    "print(sum(means)/len(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009296119434532655\n"
     ]
    }
   ],
   "source": [
    "combination = ('afforded_unusual', 'implied_category')\n",
    "combinations = [set(combination)]\n",
    "relation_pair_dict = get_relation_combinations(properties, combinations)\n",
    "pairs = relation_pair_dict[combination]\n",
    "means = []\n",
    "for prop, concept in pairs:\n",
    "    means.append(get_tfidf_pair(prop, concept, model_name, top_cutoff, concept_cutoff))\n",
    "print(sum(means)/len(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014956343039217359\n"
     ]
    }
   ],
   "source": [
    "combination = ('afforded_usual', 'implied_category')\n",
    "combinations = [set(combination)]\n",
    "relation_pair_dict = get_relation_combinations(properties, combinations)\n",
    "pairs = relation_pair_dict[combination]\n",
    "means = []\n",
    "for prop, concept in pairs:\n",
    "    means.append(get_tfidf_pair(prop, concept, model_name, top_cutoff, concept_cutoff))\n",
    "print(sum(means)/len(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
