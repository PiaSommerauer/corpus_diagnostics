{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze based on semantic categories\n",
    "\n",
    "1.) change tfidf so we compare equivalent categories only - done\n",
    "2.) update ranking accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1446\n",
      "1636\n"
     ]
    }
   ],
   "source": [
    "f_original = os.listdir('../contexts/giga_full/vocab')\n",
    "print(len(f_original))\n",
    "f_update = os.listdir('../contexts/giga_full_updated/vocab')\n",
    "print(len(f_update))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1669\n",
      "1874\n"
     ]
    }
   ],
   "source": [
    "f_original = os.listdir('../contexts/wiki/vocab')\n",
    "print(len(f_original))\n",
    "f_update = os.listdir('../contexts/wiki_updated/vocab')\n",
    "print(len(f_update))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories(prop, model_name):\n",
    "    analysis_type = 'tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    path_dir = f'../results/{model_name}/{analysis_type}'\n",
    "    path_dir = f'{path_dir}/{prop}'\n",
    "    categories = set()\n",
    "    for d in os.listdir(path_dir):\n",
    "        categories.add(d)\n",
    "    return categories\n",
    "\n",
    "def get_context_cnts(prop, cat, label, model_name):\n",
    "    \n",
    "    analysis_type = 'tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    path_dir = f'../results/{model_name}/{analysis_type}'\n",
    "    path_dir = f'{path_dir}/{prop}'\n",
    "    path_label = f'{path_dir}/{cat}/{label}'\n",
    "    \n",
    "    context_cnt = Counter()\n",
    "    for f in os.listdir(path_label):\n",
    "        full_path = f'{path_label}/{f}'\n",
    "        if full_path.endswith('.csv'):\n",
    "            with open(full_path) as infile:\n",
    "                data = list(csv.DictReader(infile))\n",
    "            for d in data:\n",
    "                context = d['']\n",
    "                diff = float(d['diff'])\n",
    "                if diff > 0:\n",
    "                    context_cnt[context] += 1\n",
    "    return context_cnt\n",
    "    \n",
    "def get_n_concepts_total(prop, cat, model_name):\n",
    "    \n",
    "    analysis_type = 'tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    path_dir = f'../results/{model_name}/{analysis_type}'\n",
    "    path_dir = f'{path_dir}/{prop}'\n",
    "    label = 'pos'\n",
    "    path_pos = f'{path_dir}/{cat}/{label}'\n",
    "    label = 'neg'\n",
    "    path_neg = f'{path_dir}/{cat}/{label}'\n",
    "    \n",
    "    files_pos = [f for f in os.listdir(path_pos) if f.endswith('.csv')]\n",
    "    files_neg = [f for f in os.listdir(path_neg) if f.endswith('.csv')]\n",
    "    \n",
    "    return len(files_pos), len(files_neg)\n",
    "\n",
    "def get_f1_distinctiveness(n_pos, n_neg, total_pos, total_neg):\n",
    "    \n",
    "   \n",
    "    total_instances = total_pos + total_neg\n",
    "    labels = []\n",
    "    [labels.append('pos') for i in range(total_pos)]\n",
    "    [labels.append('neg') for i in range(total_neg)]\n",
    "    pred_labels_pos = []\n",
    "    for i in range(total_pos):\n",
    "        if i < n_pos:\n",
    "            pred_labels_pos.append('pos')\n",
    "        else:\n",
    "            pred_labels_pos.append('neg')\n",
    "#     print(n_pos, total_pos)\n",
    "#     print(pred_labels_pos.count('pos'), pred_labels_pos.count('neg'))\n",
    "    \n",
    "    pred_labels_neg = []\n",
    "    for i in range(total_neg):\n",
    "        if i < n_neg:\n",
    "            pred_labels_neg.append('pos')\n",
    "        else:\n",
    "            pred_labels_neg.append('neg')\n",
    "#     print(n_neg, total_neg)\n",
    "#     print(pred_labels_neg.count('pos'), pred_labels_neg.count('neg'))\n",
    "    \n",
    "    predictions = pred_labels_pos + pred_labels_neg\n",
    "    \n",
    "    \n",
    "    #print(len(labels), len(predictions))\n",
    "    #print(pos_predictions, neg_predictions)\n",
    "    \n",
    "    p, r, f1, supp = precision_recall_fscore_support(labels, predictions, average = 'weighted', \n",
    "                                                     zero_division=0)\n",
    "    #average='weighted'\n",
    "    \n",
    "    return p, r, f1\n",
    "\n",
    "\n",
    "    \n",
    "def aggregate_contexts(prop, cutoff, model_name):\n",
    "    aggregation_name = 'aggregated-tfidf-raw-10000-categories'\n",
    "    path_dir_agg = f'../analysis/{model_name}/{aggregation_name}/{prop}'\n",
    "    os.makedirs(path_dir_agg, exist_ok = True)\n",
    "    \n",
    "    context_cnts_all = Counter()\n",
    "    context_cat_dict = defaultdict(set)\n",
    "\n",
    "    cats = get_categories(prop, model_name)\n",
    "\n",
    "    for cat in cats:\n",
    "        context_cnts_pos = get_context_cnts(prop, cat, 'pos', model_name)\n",
    "        context_cnts_neg = get_context_cnts(prop, cat, 'neg', model_name)\n",
    "        total_pos, total_neg = get_n_concepts_total(prop, cat, model_name)\n",
    "        \n",
    "        context_f1_dict = Counter()\n",
    "        context_score_dict = defaultdict(dict)\n",
    "        \n",
    "        # get distinctiveness\n",
    "        for c, cnt_pos in context_cnts_pos.most_common():\n",
    "            cnt_neg = context_cnts_neg[c]\n",
    "            p, r, f1 = get_f1_distinctiveness(cnt_pos, cnt_neg, total_pos, total_neg)\n",
    "            context_f1_dict[c] = f1\n",
    "            context_score_dict[c] = {'p': p,'r':r, 'f1': f1}\n",
    "        \n",
    "        table = []\n",
    "        for c, f1 in context_f1_dict.most_common():\n",
    "            scores = context_score_dict[c]\n",
    "            d = dict()\n",
    "            d['context'] = c\n",
    "            d.update(scores)\n",
    "            d['n_pos'] = context_cnts_pos[c]\n",
    "            d['total_pos'] = total_pos\n",
    "            d['n_neg'] = context_cnts_neg[c]\n",
    "            d['total_neg'] = total_neg\n",
    "            table.append(d)\n",
    "        \n",
    "        # collect and write to file\n",
    "        f = f'{path_dir_agg}/{cat}.csv'\n",
    "        \n",
    "        header = table[0].keys()\n",
    "        with open(f, 'w') as outfile:\n",
    "            writer = csv.DictWriter(outfile, fieldnames = header)\n",
    "            writer.writeheader()\n",
    "            for d in table:\n",
    "                writer.writerow(d)\n",
    "        \n",
    "                \n",
    "def prepare_annotation(prop, model_name, cutoff=3, cutoff_concepts = 5):\n",
    "    \n",
    "    annotation_name = f'annotation-tfidf-top_{cutoff}_{cutoff_concepts}-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    os.makedirs(path_dir_annotation, exist_ok = True)\n",
    "    f_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}/annotation-updated.csv'\n",
    "    \n",
    "    # paths aggregated files:\n",
    "    aggregation_name = 'aggregated-tfidf-raw-10000-categories'\n",
    "    path_dir_agg = f'../analysis/{model_name}/{aggregation_name}/{prop}'\n",
    "\n",
    "    \n",
    "    # get categories\n",
    "    cats = get_categories(prop, model_name)\n",
    "    \n",
    "    # collect all contexts and categories \n",
    "    context_cats_dict = defaultdict(set)\n",
    "    \n",
    "    # load top per category\n",
    "    for cat in cats:\n",
    "        path = f'{path_dir_agg}/{cat}.csv'\n",
    "        with open(path) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "        # sort by f1\n",
    "        f1_dict  = defaultdict(list)\n",
    "        for d in data:\n",
    "            f1 = d['f1']\n",
    "            f1_dict[f1].append(d)\n",
    "        scores = sorted(list(f1_dict.keys()), reverse=True)\n",
    "        top_scores = scores[:cutoff]\n",
    "        top_context_dicts = []\n",
    "        for ts in top_scores:\n",
    "            dicts = f1_dict[ts]\n",
    "            for d in dicts:\n",
    "                n_pos = int(d['n_pos'])\n",
    "                if n_pos > cutoff_concepts:\n",
    "                    top_context_dicts.append(d)\n",
    "    \n",
    "        contexts = [d['context'] for d in top_context_dicts]\n",
    "        # record categories\n",
    "        for c in contexts:\n",
    "            context_cats_dict[c].add(cat)\n",
    "    \n",
    "    with open(f_annotation, 'w') as outfile:\n",
    "        outfile.write('context,evidence_type,categories\\n')\n",
    "        for c, cats in context_cats_dict.items():\n",
    "            outfile.write(f'{c}, ,{\" \".join(cats)}\\n')\n",
    "\n",
    "def get_properties():\n",
    "    properties = []\n",
    "    for path in os.listdir('../data/aggregated/'):\n",
    "        prop = path.split('.')[0]\n",
    "        if 'female-' not in prop and prop != '':\n",
    "            properties.append(prop)\n",
    "    return properties\n",
    "\n",
    "def get_top_distinctive_contexts(properties, model_name, top_cutoff=3, concept_cutoff=3):\n",
    "    aggregation_name = 'aggregated-tfidf-raw-10000-categories'\n",
    "    ann_name = f'annotation-tfidf-top_{top_cutoff}_{concept_cutoff}-raw-10000-categories'\n",
    "    path_results = f'../results/{model_name}/tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    table = []\n",
    "    for prop in properties:\n",
    "        path_dir_agg = f'../analysis/{model_name}/{aggregation_name}/{prop}'\n",
    "        path = path = f'{path_dir_agg}/all.csv'\n",
    "        # load file containing all contexts\n",
    "        with open(path) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "        # top distinctive context\n",
    "        d_prop = dict()\n",
    "        d_prop['property'] = prop\n",
    "        # sort data by f1\n",
    "        f1_dict = defaultdict(list)\n",
    "        for d in data:\n",
    "            f1 = d['f1']\n",
    "            f1_dict[f1].append(d)\n",
    "            \n",
    "        # get n extracted candidates\n",
    "        f_ann =  f'../analysis/{model_name}/{ann_name}/{prop}/annotation-updated.csv'\n",
    "        with open(f_ann) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "        n_contexts = len(data)\n",
    "        \n",
    "        # get number concepts\n",
    "        dir_results = f'{path_results}/{prop}/all/pos/'\n",
    "        n_files = len([f for f in os.listdir(dir_results) if f.endswith('.csv')])\n",
    "        \n",
    "        top_score = max(list(f1_dict.keys()))\n",
    "        top_dicts = f1_dict[top_score]\n",
    "        top_context_dict = top_dicts[0]\n",
    "        top_contexts = ' '.join([d['context'] for d in top_dicts])\n",
    "        d_prop['n_contexts'] = n_contexts\n",
    "        d_prop['n_concepts'] = n_files\n",
    "\n",
    "        for k, v in top_context_dict.items():\n",
    "            if k != 'context':\n",
    "                v = float(v)\n",
    "                d_prop[k] = v\n",
    "        d_prop['contexts'] = top_contexts\n",
    "        table.append(d_prop)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square\n",
      "warm\n",
      "black\n",
      "red\n",
      "fly\n",
      "dangerous\n",
      "wings\n",
      "sweet\n",
      "hot\n",
      "used_in_cooking\n",
      "juicy\n",
      "green\n",
      "made_of_wood\n",
      "blue\n",
      "yellow\n",
      "roll\n",
      "female\n",
      "cold\n",
      "round\n",
      "wheels\n",
      "lay_eggs\n",
      "swim\n"
     ]
    }
   ],
   "source": [
    "model_name = 'wiki_updated'\n",
    "properties = get_properties()\n",
    "#properties_test = ['dangerous', 'cold', 'lay_eggs']\n",
    "#properties = [p for p in properties if p not in properties_test]\n",
    "#properties = properties_test\n",
    "cutoff = 3\n",
    "cutoff_concepts = 3\n",
    "\n",
    "for prop in properties:\n",
    "    print(prop)\n",
    "    \n",
    "    aggregate_contexts(prop, cutoff, model_name)\n",
    "    prepare_annotation(prop, model_name, cutoff, cutoff_concepts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property</th>\n",
       "      <th>n_contexts</th>\n",
       "      <th>n_concepts</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f1</th>\n",
       "      <th>n_pos</th>\n",
       "      <th>total_pos</th>\n",
       "      <th>n_neg</th>\n",
       "      <th>total_neg</th>\n",
       "      <th>contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>used_in_cooking</td>\n",
       "      <td>705</td>\n",
       "      <td>102</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>88.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wings</td>\n",
       "      <td>332</td>\n",
       "      <td>81</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>64.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>birds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fly</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>47.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>female</td>\n",
       "      <td>109</td>\n",
       "      <td>122</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.87</td>\n",
       "      <td>98.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>blue</td>\n",
       "      <td>1819</td>\n",
       "      <td>60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.83</td>\n",
       "      <td>34.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>wheels</td>\n",
       "      <td>105</td>\n",
       "      <td>78</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>59.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>chassis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>roll</td>\n",
       "      <td>3485</td>\n",
       "      <td>55</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>45.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>yellow</td>\n",
       "      <td>111</td>\n",
       "      <td>42</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "      <td>21.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>tribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>square</td>\n",
       "      <td>442</td>\n",
       "      <td>90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.81</td>\n",
       "      <td>67.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>built</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>green</td>\n",
       "      <td>550</td>\n",
       "      <td>91</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>64.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dangerous</td>\n",
       "      <td>627</td>\n",
       "      <td>76</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>49.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>killing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lay_eggs</td>\n",
       "      <td>26</td>\n",
       "      <td>72</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hot</td>\n",
       "      <td>92</td>\n",
       "      <td>102</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.78</td>\n",
       "      <td>69.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>lit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>black</td>\n",
       "      <td>820</td>\n",
       "      <td>88</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.78</td>\n",
       "      <td>61.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>led</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cold</td>\n",
       "      <td>590</td>\n",
       "      <td>69</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.77</td>\n",
       "      <td>46.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>swim</td>\n",
       "      <td>1700</td>\n",
       "      <td>100</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.76</td>\n",
       "      <td>63.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>juicy</td>\n",
       "      <td>122</td>\n",
       "      <td>89</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.75</td>\n",
       "      <td>53.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>watermelon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>round</td>\n",
       "      <td>1034</td>\n",
       "      <td>99</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.74</td>\n",
       "      <td>65.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>held</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sweet</td>\n",
       "      <td>26</td>\n",
       "      <td>96</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>58.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>berry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>red</td>\n",
       "      <td>1275</td>\n",
       "      <td>89</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>47.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>designs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>warm</td>\n",
       "      <td>1181</td>\n",
       "      <td>126</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.69</td>\n",
       "      <td>74.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>thin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>made_of_wood</td>\n",
       "      <td>497</td>\n",
       "      <td>98</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>54.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>wooden</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           property  n_contexts  n_concepts     p     r    f1  n_pos  \\\n",
       "9   used_in_cooking         705         102  0.93  0.92  0.92   88.0   \n",
       "6             wings         332          81  0.91  0.89  0.89   64.0   \n",
       "4               fly          55          63  0.89  0.89  0.88   47.0   \n",
       "16           female         109         122  0.88  0.88  0.87   98.0   \n",
       "13             blue        1819          60  0.88  0.85  0.83   34.0   \n",
       "19           wheels         105          78  0.89  0.82  0.83   59.0   \n",
       "15             roll        3485          55  0.83  0.82  0.83   45.0   \n",
       "14           yellow         111          42  0.85  0.83  0.81   21.0   \n",
       "0            square         442          90  0.89  0.78  0.81   67.0   \n",
       "11            green         550          91  0.84  0.81  0.81   64.0   \n",
       "5         dangerous         627          76  0.85  0.79  0.79   49.0   \n",
       "20         lay_eggs          26          72  0.85  0.79  0.79   44.0   \n",
       "8               hot          92         102  0.86  0.77  0.78   69.0   \n",
       "2             black         820          88  0.82  0.77  0.78   61.0   \n",
       "17             cold         590          69  0.88  0.75  0.77   46.0   \n",
       "21             swim        1700         100  0.86  0.75  0.76   63.0   \n",
       "10            juicy         122          89  0.84  0.76  0.75   53.0   \n",
       "18            round        1034          99  0.88  0.70  0.74   65.0   \n",
       "7             sweet          26          96  0.81  0.74  0.74   58.0   \n",
       "3               red        1275          89  0.78  0.70  0.69   47.0   \n",
       "1              warm        1181         126  0.83  0.66  0.69   74.0   \n",
       "12     made_of_wood         497          98  0.80  0.67  0.68   54.0   \n",
       "\n",
       "    total_pos  n_neg  total_neg    contexts  \n",
       "9       102.0    0.0       64.0        meat  \n",
       "6        81.0    1.0       84.0       birds  \n",
       "4        63.0    3.0      104.0        bird  \n",
       "16      122.0   10.0      150.0         she  \n",
       "13       60.0    0.0      109.0     evening  \n",
       "19       78.0    0.0       27.0     chassis  \n",
       "15       55.0    7.0       42.0        from  \n",
       "14       42.0    1.0       85.0       tribe  \n",
       "0        90.0    1.0       21.0       built  \n",
       "11       91.0    4.0       68.0       green  \n",
       "5        76.0    1.0       59.0     killing  \n",
       "20       72.0    1.0       69.0        bird  \n",
       "8       102.0    1.0       43.0         lit  \n",
       "2        88.0    5.0       52.0         led  \n",
       "17       69.0    0.0       23.0        soft  \n",
       "21      100.0    0.0       47.0        fish  \n",
       "10       89.0    1.0       64.0  watermelon  \n",
       "18       99.0    1.0       18.0        held  \n",
       "7        96.0    4.0       64.0       berry  \n",
       "3        89.0    4.0       65.0     designs  \n",
       "1       126.0    3.0       35.0        thin  \n",
       "12       98.0    3.0       43.0      wooden  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get top distinctive contexts per prop\n",
    "\n",
    "model_name = 'wiki_updated'\n",
    "properties = get_properties()\n",
    "table = get_top_distinctive_contexts(properties, model_name)\n",
    "df = pd.DataFrame(table)\n",
    "df.sort_values('f1', ascending = False).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrl}\n",
      "\\toprule\n",
      "        property &  n\\_concepts &  n\\_contexts &    f1 &    contexts \\\\\n",
      "\\midrule\n",
      " used\\_in\\_cooking &         102 &         705 &  0.92 &        meat \\\\\n",
      "           wings &          81 &         332 &  0.89 &       birds \\\\\n",
      "             fly &          63 &          55 &  0.88 &        bird \\\\\n",
      "          female &         122 &         109 &  0.87 &         she \\\\\n",
      "            blue &          60 &        1819 &  0.83 &     evening \\\\\n",
      "          wheels &          78 &         105 &  0.83 &     chassis \\\\\n",
      "            roll &          55 &        3485 &  0.83 &        from \\\\\n",
      "          yellow &          42 &         111 &  0.81 &       tribe \\\\\n",
      "          square &          90 &         442 &  0.81 &       built \\\\\n",
      "           green &          91 &         550 &  0.81 &       green \\\\\n",
      "       dangerous &          76 &         627 &  0.79 &     killing \\\\\n",
      "        lay\\_eggs &          72 &          26 &  0.79 &        bird \\\\\n",
      "             hot &         102 &          92 &  0.78 &         lit \\\\\n",
      "           black &          88 &         820 &  0.78 &         led \\\\\n",
      "            cold &          69 &         590 &  0.77 &        soft \\\\\n",
      "            swim &         100 &        1700 &  0.76 &        fish \\\\\n",
      "           juicy &          89 &         122 &  0.75 &  watermelon \\\\\n",
      "           round &          99 &        1034 &  0.74 &        held \\\\\n",
      "           sweet &          96 &          26 &  0.74 &       berry \\\\\n",
      "             red &          89 &        1275 &  0.69 &     designs \\\\\n",
      "            warm &         126 &        1181 &  0.69 &        thin \\\\\n",
      "    made\\_of\\_wood &          98 &         497 &  0.68 &      wooden \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# latex table for paper:\n",
    "cols = ['property', 'n_concepts', 'n_contexts', 'f1', 'contexts']\n",
    "df = df.sort_values('f1', ascending = False).round(2)\n",
    "print(df[cols].to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top distinctive contexts per prop\n",
    "\n",
    "# model_name = 'wiki_updated'\n",
    "# properties = get_properties()\n",
    "# table = get_top_distinctive_contexts(properties, model_name)\n",
    "# df = pd.DataFrame(table)\n",
    "# df.sort_values('f1', ascending = False).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer old annotations to new files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_properties' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fe648754263e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mproperties\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_name_current\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'giga_full_updated'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_name_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'giga_full'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_properties' is not defined"
     ]
    }
   ],
   "source": [
    "properties = get_properties()\n",
    "model_name_current = 'giga_full_updated'\n",
    "model_name_old = 'giga_full'\n",
    "\n",
    "\n",
    "for prop in properties:\n",
    "    # current file:\n",
    "    annotation_name = 'annotation-tfidf-top20-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    f_annotation_new = f'{path_dir_annotation}/annotation.csv'\n",
    "    f_annotation_tr = f'{path_dir_annotation}/annotation-transferred.csv'\n",
    "\n",
    "    # old file:\n",
    "    annotation_name = 'annotation-tfidf-top20-raw-10000'\n",
    "    path_dir_annotation = f'../analysis/{model_name_old}/{annotation_name}/{prop}-pos'\n",
    "    f_annotation_old = f'{path_dir_annotation}/annotation-done.csv'\n",
    "\n",
    "    # load old annotations\n",
    "    context_annotation_dict=dict()\n",
    "    with open(f_annotation_old) as infile:\n",
    "        data = list(csv.DictReader(infile))\n",
    "        for d in data:\n",
    "            c = d['context']\n",
    "            et = d['evidence']\n",
    "            context_annotation_dict[c] = et\n",
    "            #c = d['context']\n",
    "\n",
    "    # load new candidates\n",
    "\n",
    "    with open(f_annotation_new) as infile:\n",
    "        data = list(csv.DictReader(infile))\n",
    "\n",
    "    # fill in old annotations\n",
    "    for d in data:\n",
    "        c = d['context']\n",
    "        if c in context_annotation_dict:\n",
    "            et = context_annotation_dict[c]\n",
    "        else:\n",
    "            et = 'NA'\n",
    "        d['evidence_type'] = et\n",
    "\n",
    "    # write to new file\n",
    "\n",
    "    with open(f_annotation_tr, 'w') as outfile:\n",
    "        writer = csv.DictWriter(outfile, fieldnames = data[0].keys())\n",
    "        writer.writeheader()\n",
    "        for d in data:\n",
    "            writer.writerow(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found file\n",
      "found file\n",
      "found file\n"
     ]
    }
   ],
   "source": [
    "# transfer new annotations to updated f1 scores\n",
    "\n",
    "properties = get_properties()\n",
    "#properties = ['dangerous']\n",
    "model_name_current = 'giga_full_updated'\n",
    "model_name_old = 'giga_full'\n",
    "\n",
    "\n",
    "for prop in properties:\n",
    "    # current file:\n",
    "    annotation_name = 'annotation-tfidf-top_3_3-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    f_annotation_new = f'{path_dir_annotation}/annotation-updated.csv'\n",
    "    f_annotation_tr = f'{path_dir_annotation}/annotation-transferred-updated.csv'\n",
    "\n",
    "    # old file:\n",
    "    annotation_name = 'annotation-tfidf-top_3_5-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    f_annotation_old = f'{path_dir_annotation}/annotation-updated-done.csv'\n",
    "\n",
    "    # load old annotations\n",
    "    if os.path.isfile(f_annotation_old):\n",
    "        print('found file')\n",
    "        context_annotation_dict=dict()\n",
    "        with open(f_annotation_old) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "            for d in data:\n",
    "                c = d['context']\n",
    "                et = d['evidence_type']\n",
    "                context_annotation_dict[c] = et\n",
    "                #c = d['context']\n",
    "\n",
    "        # load new candidates\n",
    "\n",
    "        with open(f_annotation_new) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "\n",
    "        # fill in old annotations\n",
    "        for d in data:\n",
    "            c = d['context']\n",
    "            if c in context_annotation_dict:\n",
    "                et = context_annotation_dict[c]\n",
    "            else:\n",
    "                et = 'NA'\n",
    "            d['evidence_type'] = et\n",
    "\n",
    "        # write to new file\n",
    "\n",
    "        with open(f_annotation_tr, 'w') as outfile:\n",
    "            writer = csv.DictWriter(outfile, fieldnames = data[0].keys())\n",
    "            writer.writeheader()\n",
    "            for d in data:\n",
    "                writer.writerow(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square\n",
      "found file\n",
      "warm\n",
      "found file\n",
      "black\n",
      "found file\n",
      "red\n",
      "found file\n",
      "fly\n",
      "found file\n",
      "dangerous\n",
      "found file\n",
      "wings\n",
      "found file\n",
      "sweet\n",
      "found file\n",
      "hot\n",
      "found file\n",
      "used_in_cooking\n",
      "found file\n",
      "juicy\n",
      "found file\n",
      "green\n",
      "found file\n",
      "made_of_wood\n",
      "found file\n",
      "blue\n",
      "found file\n",
      "yellow\n",
      "found file\n",
      "roll\n",
      "found file\n",
      "female\n",
      "found file\n",
      "cold\n",
      "found file\n",
      "round\n",
      "found file\n",
      "wheels\n",
      "found file\n",
      "lay_eggs\n",
      "found file\n",
      "swim\n",
      "found file\n"
     ]
    }
   ],
   "source": [
    "# transfer giga annotations to wiki\n",
    "\n",
    "properties = get_properties()\n",
    "#properties = ['dangerous']\n",
    "model_name_current = 'wiki_updated'\n",
    "model_name_old = 'giga_full_updated'\n",
    "\n",
    "\n",
    "for prop in properties:\n",
    "    print(prop)\n",
    "    # current file:\n",
    "    annotation_name = 'annotation-tfidf-top_3_3-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name_current}/{annotation_name}/{prop}'\n",
    "    f_annotation_new = f'{path_dir_annotation}/annotation-updated.csv'\n",
    "    f_annotation_tr = f'{path_dir_annotation}/annotation-transferred-updated.csv'\n",
    "\n",
    "    # old file:\n",
    "    annotation_name = 'annotation-tfidf-top_3_3-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name_old}/{annotation_name}/{prop}'\n",
    "    f_annotation_old = f'{path_dir_annotation}/annotation-updated-done.csv'\n",
    "\n",
    "    # load old annotations\n",
    "    if os.path.isfile(f_annotation_old):\n",
    "        print('found file')\n",
    "        context_annotation_dict=dict()\n",
    "        with open(f_annotation_old) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "            for d in data:\n",
    "                c = d['context']\n",
    "                et = d['evidence_type']\n",
    "                context_annotation_dict[c] = et\n",
    "                #c = d['context']\n",
    "\n",
    "        # load new candidates\n",
    "\n",
    "        with open(f_annotation_new) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "\n",
    "        # fill in old annotations\n",
    "        for d in data:\n",
    "            c = d['context']\n",
    "            if c in context_annotation_dict:\n",
    "                et = context_annotation_dict[c]\n",
    "            else:\n",
    "                et = 'NA'\n",
    "            d['evidence_type'] = et\n",
    "\n",
    "        # write to new file\n",
    "\n",
    "        with open(f_annotation_tr, 'w') as outfile:\n",
    "            writer = csv.DictWriter(outfile, fieldnames = data[0].keys())\n",
    "            writer.writeheader()\n",
    "            for d in data:\n",
    "                writer.writerow(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotation_status(model_name, top_cutoff, concept_cutoff):\n",
    "    dir_path = f'../analysis/{model_name}'\n",
    "    dir_annotations = f'{dir_path}/annotation-tfidf-top_{top_cutoff}_{concept_cutoff}-raw-10000-categories'\n",
    "    annotation_dict = defaultdict(set)\n",
    "    line_dict = dict()\n",
    "\n",
    "    for f in os.listdir(dir_annotations):\n",
    "        if  not f.endswith('.csv') and not f.endswith('.ipynb_checkpoints'):\n",
    "            prop = f.split('/')[-1]\n",
    "            full_path = f'{dir_annotations}/{f}'\n",
    "            \n",
    "            #print(full_path)\n",
    "            # get categories:\n",
    "            files = os.listdir(full_path)\n",
    "            # get number of words\n",
    "            path_file = f'{full_path}/annotation-transferred-updated.csv'\n",
    "            with open(path_file) as infile:\n",
    "                lines = infile.read().strip().split('\\n')\n",
    "                not_annotated = [l for l in lines if l.strip().split(',')[1] == 'NA']\n",
    "            line_dict[prop] = (len(lines), len(not_annotated), len(lines)-len(not_annotated))\n",
    "            if 'annotation-updated-done.csv' in files:\n",
    "                annotation_dict['complete'].add(prop)\n",
    "            else:\n",
    "                annotation_dict['incomplete'].add(prop)\n",
    "                \n",
    "    return annotation_dict, line_dict\n",
    "\n",
    "def show_annotation_status(model_name, top_cutoff, concept_cutoff):\n",
    "    annotation_dict, line_dict = get_annotation_status(model_name, \n",
    "                                        top_cutoff, concept_cutoff)\n",
    "    # same category not annotated:\n",
    "    print('completed:\\n')\n",
    "    for prop in sorted(list(annotation_dict['complete'])):\n",
    "        # cats open:\n",
    "        print(prop, line_dict[prop])\n",
    "    print()\n",
    "    print('Incomplete:\\n')\n",
    "    for prop in sorted(annotation_dict['incomplete']):\n",
    "        if prop not in annotation_dict['complete']:\n",
    "            print(prop, line_dict[prop])\n",
    "    return annotation_dict\n",
    "            \n",
    "            \n",
    "def get_evidence_dict(model_name, prop, top_cutoff, concept_cutoff):\n",
    "    \n",
    "    annotation_name = f'annotation-tfidf-top_{top_cutoff}_{concept_cutoff}-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    f_annotation = f'{path_dir_annotation}/annotation-updated-done.csv'\n",
    "    \n",
    "    ev_dict = dict()\n",
    "    \n",
    "    with open(f_annotation) as infile:\n",
    "        data = list(csv.DictReader(infile))\n",
    "    for d in data:\n",
    "        et = d['evidence_type']\n",
    "        ev = d['context']\n",
    "        ev_dict[ev] = et\n",
    "    return ev_dict\n",
    "        \n",
    "            \n",
    "\n",
    "def get_evidence_distribution(model_name, prop, top_cutoff, concept_cutoff):\n",
    "    \n",
    "    # current file:\n",
    "    annotation_name = f'annotation-tfidf-top_{top_cutoff}_{concept_cutoff}-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    f_annotation = f'{path_dir_annotation}/annotation-updated-done.csv'\n",
    "    \n",
    "    ev_dict = get_evidence_dict(model_name, prop, top_cutoff, concept_cutoff)\n",
    "    \n",
    "    ev_cnts = Counter()\n",
    "    \n",
    "    for e, et in ev_dict.items():\n",
    "        ev_cnts[et] += 1\n",
    "        if et != 'u':\n",
    "            ev_cnts['all'] += 1\n",
    "        if et in ['p', 'l', 'n']:\n",
    "            ev_cnts['prop_specific'] += 1\n",
    "        elif et in ['i', 'r', 'b']:\n",
    "            ev_cnts['non-specific'] += 1\n",
    "    \n",
    "    total_contexts = len(ev_dict)\n",
    "    \n",
    "    ev_counts_norm = dict()\n",
    "    for ev, cnt in ev_cnts.items():\n",
    "        ev_counts_norm[ev]  = cnt/total_contexts\n",
    "    return ev_counts_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed:\n",
      "\n",
      "\n",
      "Incomplete:\n",
      "\n",
      "black (821, 634, 187)\n",
      "blue (1820, 1018, 802)\n",
      "cold (591, 382, 209)\n",
      "dangerous (628, 392, 236)\n",
      "female (110, 97, 13)\n",
      "fly (56, 41, 15)\n",
      "green (551, 402, 149)\n",
      "hot (93, 78, 15)\n",
      "juicy (123, 59, 64)\n",
      "lay_eggs (27, 18, 9)\n",
      "made_of_wood (498, 373, 125)\n",
      "red (1276, 781, 495)\n",
      "roll (3486, 1464, 2022)\n",
      "round (1035, 886, 149)\n",
      "square (443, 214, 229)\n",
      "sweet (27, 20, 7)\n",
      "swim (1701, 1225, 476)\n",
      "used_in_cooking (706, 492, 214)\n",
      "warm (1182, 573, 609)\n",
      "wheels (106, 66, 40)\n",
      "wings (333, 234, 99)\n",
      "yellow (112, 108, 4)\n"
     ]
    }
   ],
   "source": [
    "model_name = 'wiki_updated'\n",
    "top_cutoff = 3\n",
    "concept_cutoff = 3\n",
    "ann_dict = show_annotation_status(model_name, top_cutoff, concept_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property</th>\n",
       "      <th>u</th>\n",
       "      <th>all</th>\n",
       "      <th>prop_specific</th>\n",
       "      <th>non-specific</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>l</th>\n",
       "      <th>i</th>\n",
       "      <th>r</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>used_in_cooking</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.327</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sweet</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hot</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.095</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lay_eggs</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.095</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>female</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>green</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>wheels</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.094</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wings</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>juicy</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dangerous</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>round</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>yellow</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cold</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.018</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>made_of_wood</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.034</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>red</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.003</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fly</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>warm</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>black</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.007</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>square</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>swim</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.030</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>roll</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.011</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           property      u    all  prop_specific  non-specific      p      n  \\\n",
       "4   used_in_cooking  0.357  0.643          0.014         0.629  0.007  0.003   \n",
       "1             sweet  0.400  0.600          0.057         0.543  0.057    NaN   \n",
       "6               hot  0.702  0.298          0.036         0.262  0.024  0.012   \n",
       "7          lay_eggs  0.703  0.297          0.027         0.270  0.027    NaN   \n",
       "21           female  0.711  0.289          0.044         0.244    NaN    NaN   \n",
       "10            green  0.839  0.161          0.002         0.159  0.002    NaN   \n",
       "19           wheels  0.840  0.160          0.016         0.143  0.008    NaN   \n",
       "13            wings  0.848  0.152          0.011         0.139  0.002    NaN   \n",
       "17            juicy  0.880  0.120          0.002         0.117  0.002    NaN   \n",
       "3         dangerous  0.883  0.117          0.021         0.096  0.002  0.006   \n",
       "18            round  0.921  0.079          0.004         0.075  0.002    NaN   \n",
       "20           yellow  0.923  0.077          0.019         0.058  0.019    NaN   \n",
       "2              blue  0.924  0.076          0.001         0.074  0.001    NaN   \n",
       "11             cold  0.935  0.065          0.006         0.057  0.001  0.005   \n",
       "9      made_of_wood  0.941  0.059          0.004         0.055  0.004    NaN   \n",
       "15              red  0.947  0.053          0.001         0.053  0.001    NaN   \n",
       "5               fly  0.947  0.053          0.008         0.044  0.006  0.001   \n",
       "8              warm  0.948  0.052          0.004         0.048  0.002  0.000   \n",
       "14            black  0.956  0.044          0.002         0.043  0.001    NaN   \n",
       "16           square  0.960  0.040            NaN         0.040    NaN    NaN   \n",
       "0              swim  0.960  0.040          0.001         0.038  0.001    NaN   \n",
       "12             roll  0.963  0.037          0.002         0.035  0.001    NaN   \n",
       "\n",
       "        l      i      r      b  \n",
       "4   0.003  0.302  0.327    NaN  \n",
       "1     NaN  0.543    NaN    NaN  \n",
       "6     NaN  0.167  0.095    NaN  \n",
       "7     NaN  0.176  0.095    NaN  \n",
       "21  0.044  0.156  0.022  0.067  \n",
       "10    NaN  0.145  0.014    NaN  \n",
       "19  0.008  0.049  0.094    NaN  \n",
       "13  0.009  0.045  0.068  0.027  \n",
       "17    NaN  0.102  0.015    NaN  \n",
       "3   0.013  0.037  0.054  0.005  \n",
       "18  0.002  0.071  0.004    NaN  \n",
       "20    NaN  0.058    NaN    NaN  \n",
       "2     NaN  0.070  0.004    NaN  \n",
       "11    NaN  0.040  0.018    NaN  \n",
       "9     NaN  0.020  0.034    NaN  \n",
       "15    NaN  0.049  0.003    NaN  \n",
       "5   0.001  0.008  0.033  0.003  \n",
       "8   0.001  0.037  0.010    NaN  \n",
       "14  0.001  0.036  0.007    NaN  \n",
       "16    NaN  0.039  0.001    NaN  \n",
       "0     NaN  0.009  0.030    NaN  \n",
       "12  0.001  0.023  0.011    NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'giga_full_updated'\n",
    "properties = ann_dict['complete']\n",
    "top_cutoff = 3\n",
    "concept_cutoff = 3\n",
    "\n",
    "cols = ['property', 'u', 'all', 'prop_specific', 'non-specific', 'p', 'n', 'l', 'i', 'r', 'b']\n",
    "table = []\n",
    "for prop in properties:\n",
    "    d = dict()\n",
    "    d['property'] =  prop\n",
    "    d.update(get_evidence_distribution(model_name, prop, top_cutoff, concept_cutoff))\n",
    "    for c in cols:\n",
    "        if c not in d:\n",
    "            d[c] = np.nan\n",
    "    table.append(d)\n",
    "   \n",
    "cols = ['property', 'u', 'all', 'prop_specific', 'non-specific', 'p', 'n', 'l', 'i', 'r', 'b']\n",
    "df = pd.DataFrame(table)[cols]\n",
    "df = df[cols].sort_values('all', ascending = False).round(3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.round(3).fillna('-').to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evidence strength and distinctiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import stdev\n",
    "import pandas as pd\n",
    "\n",
    "def get_categories(prop, model_name):\n",
    "    analysis_type = 'tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    path_dir = f'../results/{model_name}/{analysis_type}'\n",
    "    path_dir = f'{path_dir}/{prop}'\n",
    "    categories = set()\n",
    "    for d in os.listdir(path_dir):\n",
    "        if '.' not in d:\n",
    "            categories.add(d)\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ev_type</th>\n",
       "      <th>mammal</th>\n",
       "      <th>no-cat</th>\n",
       "      <th>relation</th>\n",
       "      <th>object</th>\n",
       "      <th>communication</th>\n",
       "      <th>measure</th>\n",
       "      <th>bird</th>\n",
       "      <th>all</th>\n",
       "      <th>fish</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>food</th>\n",
       "      <th>animal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>landing</th>\n",
       "      <td>l</td>\n",
       "      <td>0.00109967</td>\n",
       "      <td>0.0384938</td>\n",
       "      <td>0.0305578</td>\n",
       "      <td>0.0599175</td>\n",
       "      <td>0.0615637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00984135</td>\n",
       "      <td>0.0562959</td>\n",
       "      <td>0.0237487</td>\n",
       "      <td>0.0914492</td>\n",
       "      <td>0.0214683</td>\n",
       "      <td>0.0101632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fly</th>\n",
       "      <td>p</td>\n",
       "      <td>0.0016877</td>\n",
       "      <td>0.0211931</td>\n",
       "      <td>0.0264586</td>\n",
       "      <td>0.0184811</td>\n",
       "      <td>0.022011</td>\n",
       "      <td>0.00223312</td>\n",
       "      <td>0.0110777</td>\n",
       "      <td>0.018222</td>\n",
       "      <td>0.0025445</td>\n",
       "      <td>0.0410519</td>\n",
       "      <td>0.0033475</td>\n",
       "      <td>0.00963089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plane</th>\n",
       "      <td>i</td>\n",
       "      <td>0.00468728</td>\n",
       "      <td>0.0181112</td>\n",
       "      <td>0.0435988</td>\n",
       "      <td>0.0142364</td>\n",
       "      <td>0.00361045</td>\n",
       "      <td>0.0122682</td>\n",
       "      <td>0.00622109</td>\n",
       "      <td>0.0149158</td>\n",
       "      <td>0.00102178</td>\n",
       "      <td>0.026819</td>\n",
       "      <td>0.00460734</td>\n",
       "      <td>0.00695006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ev_type      mammal     no-cat   relation     object communication  \\\n",
       "landing       l  0.00109967  0.0384938  0.0305578  0.0599175     0.0615637   \n",
       "fly           p   0.0016877  0.0211931  0.0264586  0.0184811      0.022011   \n",
       "plane         i  0.00468728  0.0181112  0.0435988  0.0142364    0.00361045   \n",
       "\n",
       "            measure        bird        all        fish    vehicle        food  \\\n",
       "landing         NaN  0.00984135  0.0562959   0.0237487  0.0914492   0.0214683   \n",
       "fly      0.00223312   0.0110777   0.018222   0.0025445  0.0410519   0.0033475   \n",
       "plane     0.0122682  0.00622109  0.0149158  0.00102178   0.026819  0.00460734   \n",
       "\n",
       "             animal  \n",
       "landing   0.0101632  \n",
       "fly      0.00963089  \n",
       "plane    0.00695006  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all mean tfidf values per evidence word and category ranked by f1-score\n",
    "\n",
    "\n",
    "# table (1 per property)\n",
    "\n",
    "# word, evidence_type, f1-score, all, cat1, cat2, cat3 \n",
    "\n",
    "# get mean tfidf score + std\n",
    "\n",
    "def get_tfidf_scores(prop, model_name, evidence_dict):\n",
    "    categories = get_categories(prop, model_name)\n",
    "    dir_tfidf = f'../results/{model_name}/tfidf-raw-10000/each_target_vs_corpus_per_category/{prop}'\n",
    "    word_cat_mean_dict = defaultdict(dict)\n",
    "    #n_concepts_cat = []\n",
    "    for cat in categories:\n",
    "        dir_cat_tfidf = f'{dir_tfidf}/{cat}/pos'\n",
    "        f_concepts = os.listdir(dir_cat_tfidf)\n",
    "        word_tfidfs = defaultdict(list)\n",
    "        word_concepts = defaultdict(list)\n",
    "        n_concepts_total = 0\n",
    "        for f in f_concepts:\n",
    "            full_f = f'{dir_cat_tfidf}/{f}'\n",
    "            if full_f.endswith('.csv'):\n",
    "                n_concepts_total += 1\n",
    "                with open(full_f) as infile:\n",
    "                    data = list(csv.DictReader(infile))\n",
    "                for d in data:\n",
    "                    word = d['']\n",
    "                    if word in evidence_dict and float(d['diff']) > 0:\n",
    "                        word_tfidfs[word].append(float(d['target']))\n",
    "                        word_concepts[word].append(full_f.split('/')[-1].split('.')[0])\n",
    "        for word, tfidfs in word_tfidfs.items():\n",
    "            if len(tfidfs) > 0:\n",
    "                mean = sum(tfidfs)/len(tfidfs)\n",
    "            else:\n",
    "                mean = 0\n",
    "            word_cat_mean_dict[word]['ev_type'] = evidence_dict[word]\n",
    "            word_cat_mean_dict[word][cat] = mean\n",
    "    return word_cat_mean_dict\n",
    "\n",
    "    \n",
    "\n",
    "prop = 'fly'\n",
    "model_name = 'giga_full_updated'\n",
    "top_cutoff = 3\n",
    "concept_cutoff = 3\n",
    "evidence_dict = get_evidence_dict(model_name, prop, top_cutoff, concept_cutoff)\n",
    "# make selection\n",
    "evidence_dict_reduced = dict()\n",
    "selected_words = ['fly', 'plane', 'landing']\n",
    "for w in selected_words:\n",
    "    evidence_dict_reduced[w] = evidence_dict[w]\n",
    "# \n",
    "word_cat_dict_tfidf = get_tfidf_scores(prop, model_name, evidence_dict_reduced)\n",
    "df = pd.DataFrame(word_cat_dict_tfidf)\n",
    "df.round(2).T.sort_values('all', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evidence distribution per semantic category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prop_data(prop):\n",
    "    \n",
    "    path = f'../data/aggregated_semantic_info/{prop}.json'\n",
    "    with open(path) as infile:\n",
    "        concept_dict = json.load(infile)\n",
    "    return concept_dict\n",
    "\n",
    "\n",
    "def load_concept_evidence(concept, prop, model_name, categories):\n",
    "    \n",
    "    categories.add('all')\n",
    "    contexts = set()\n",
    "    dir_path = f'../results/{model_name}/tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    \n",
    "    for cat in categories:\n",
    "        f_path = f'{dir_path}/{prop}/{cat}/pos/{concept}.csv'\n",
    "        if os.path.isfile(f_path):\n",
    "            with open(f_path) as infile:\n",
    "                data = list(csv.DictReader(infile))\n",
    "            for d in data:\n",
    "                context = d['']\n",
    "                diff = float(d['diff'])\n",
    "                if diff > 0:\n",
    "                    contexts.add(context)\n",
    "    return contexts  \n",
    "\n",
    "def get_categories(prop, model_name):\n",
    "    analysis_type = 'tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    path_dir = f'../results/{model_name}/{analysis_type}'\n",
    "    path_dir = f'{path_dir}/{prop}'\n",
    "    categories = set()\n",
    "    for d in os.listdir(path_dir):\n",
    "        if '.' not in d:\n",
    "            categories.add(d)\n",
    "    return categories\n",
    "\n",
    "\n",
    "def get_top_ev_categories(prop, model_name, top_cutoff, concept_cutoff):\n",
    "    table = dict()\n",
    "    aggregation_name = f'aggregated-tfidf-raw-10000-categories'\n",
    "    categories = get_categories(prop, model_name)\n",
    "    \n",
    "    path_dir_agg = f'../analysis/{model_name}/{aggregation_name}/{prop}'\n",
    "    evidence_dict = get_evidence_dict(model_name, prop, top_cutoff, concept_cutoff)\n",
    "    \n",
    "    et_context_dict = defaultdict(set)\n",
    "    for c, et in evidence_dict.items():\n",
    "        et_context_dict[et].add(c)\n",
    "    \n",
    "    # get top performance per evidence type for each category\n",
    "    for cat in categories:\n",
    "        path = path = f'{path_dir_agg}/{cat}.csv'\n",
    "        # load file containing all concepts and simply load first one\n",
    "        with open(path) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "        # sort by performance:\n",
    "        perf_data = defaultdict(list)\n",
    "        for d in data:\n",
    "            f1 = d['f1']\n",
    "            perf_data[f1].append(d)\n",
    "        perf_ranked = sorted(list(perf_data.keys()), reverse = True)\n",
    "        for et, contexts in et_context_dict.items():\n",
    "            for f1 in perf_ranked:\n",
    "                data = perf_data[f1]\n",
    "                d_perf = dict()\n",
    "                for k, v in d.items():\n",
    "                    if k != 'context':\n",
    "                        d_perf[k] = round(float(v), 2)\n",
    "                contexts_ev = set()\n",
    "                for d in data:\n",
    "                    context = d['context']\n",
    "                    if context in contexts:\n",
    "                        contexts_ev.add(context)\n",
    "                if contexts_ev:\n",
    "                    d_perf['n_c'] = len(contexts_ev)\n",
    "                    d_perf['contexts'] = ' '.join(contexts_ev)\n",
    "                    table[(cat, et)] = d_perf\n",
    "                    break\n",
    "                \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f1</th>\n",
       "      <th>n_pos</th>\n",
       "      <th>total_pos</th>\n",
       "      <th>n_neg</th>\n",
       "      <th>total_neg</th>\n",
       "      <th>n_c</th>\n",
       "      <th>contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">mammal</th>\n",
       "      <th>i</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>herself actress her lady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>grass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>birth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>pregnant pregnancy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">no-cat</th>\n",
       "      <th>i</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>herself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>about media so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>pregnancy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>baby beautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">relation</th>\n",
       "      <th>i</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>girl her she actress lady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>everyone walk bed university art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>pregnant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>married baby beautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">object</th>\n",
       "      <th>i</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>104</td>\n",
       "      <td>95</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>herself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.67</td>\n",
       "      <td>50</td>\n",
       "      <td>104</td>\n",
       "      <td>23</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>grace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.6</td>\n",
       "      <td>34</td>\n",
       "      <td>104</td>\n",
       "      <td>22</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>birth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.7</td>\n",
       "      <td>42</td>\n",
       "      <td>104</td>\n",
       "      <td>5</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>pregnant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>68</td>\n",
       "      <td>104</td>\n",
       "      <td>10</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>beautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">communication</th>\n",
       "      <th>i</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>walk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>birth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>pregnant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">measure</th>\n",
       "      <th>i</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>herself her she sister actress lady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>associate stories media haired reading bed fri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>pregnant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>married baby beautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">bird</th>\n",
       "      <th>i</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>stories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">all</th>\n",
       "      <th>i</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.19</td>\n",
       "      <td>3</td>\n",
       "      <td>109</td>\n",
       "      <td>97</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>herself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.69</td>\n",
       "      <td>45</td>\n",
       "      <td>109</td>\n",
       "      <td>7</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>stories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.59</td>\n",
       "      <td>35</td>\n",
       "      <td>109</td>\n",
       "      <td>23</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>birth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.69</td>\n",
       "      <td>48</td>\n",
       "      <td>109</td>\n",
       "      <td>12</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>pregnant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>72</td>\n",
       "      <td>109</td>\n",
       "      <td>10</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>beautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">fish</th>\n",
       "      <th>i</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>herself actress she her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>like stories sex friends mind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>birth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>pregnant pregnancy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">female</th>\n",
       "      <th>i</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.82</td>\n",
       "      <td>37</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>haired in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>birth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.37</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>pregnant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.79</td>\n",
       "      <td>35</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>beautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">criminal</th>\n",
       "      <th>i</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>herself sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>original like angel bed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">food</th>\n",
       "      <th>i</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>actress sister lady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>45 associate like walk sex about wine original...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>baby beautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">animal</th>\n",
       "      <th>i</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>actress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>stories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>birth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.62</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>pregnant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>married</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    p     r    f1 n_pos total_pos n_neg total_neg n_c  \\\n",
       "mammal        i  0.89  0.86  0.86     7        10     0        12   4   \n",
       "              u  0.89  0.86  0.86     7        10     0        12   1   \n",
       "              r  0.86  0.82  0.81     6        10     0        12   1   \n",
       "              l  0.89  0.86  0.86     7        10     0        12   2   \n",
       "              b  0.72  0.68  0.66     4        10     1        12   1   \n",
       "no-cat        i     1     1     1     1         1     0        17   1   \n",
       "              u  0.97  0.94  0.95     1         1     1        17   3   \n",
       "              l  0.96  0.89  0.91     1         1     2        17   1   \n",
       "              b  0.96  0.89  0.91     1         1     2        17   2   \n",
       "relation      i  0.17  0.25   0.2     1         2     2         2   5   \n",
       "              u     1     1     1     2         2     0         2   5   \n",
       "              l  0.83  0.75  0.73     1         2     0         2   1   \n",
       "              b   0.5   0.5   0.5     1         2     1         2   3   \n",
       "object        i   0.2   0.2   0.2     3       104    95       142   1   \n",
       "              u  0.69  0.69  0.67    50       104    23       142   1   \n",
       "              r  0.62  0.63   0.6    34       104    22       142   1   \n",
       "              l  0.78  0.73   0.7    42       104     5       142   1   \n",
       "              b  0.82  0.81  0.81    68       104    10       142   1   \n",
       "communication i  0.09  0.09  0.09     1         6     5         5   1   \n",
       "              u     1     1     1     6         6     0         5   1   \n",
       "              r   0.8  0.64   0.6     2         6     0         5   1   \n",
       "              l  0.82  0.82  0.82     5         6     1         5   1   \n",
       "              b  0.87  0.82  0.82     4         6     0         5   1   \n",
       "measure       i  0.25   0.5  0.33     1         1     1         1   6   \n",
       "              u     1     1     1     1         1     0         1  24   \n",
       "              l  0.25   0.5  0.33     1         1     1         1   1   \n",
       "              b     1     1     1     1         1     0         1   3   \n",
       "bird          i     1     1     1     2         2     0         2   1   \n",
       "              u  0.83  0.75  0.73     1         2     0         2   1   \n",
       "              b     1     1     1     2         2     0         2   1   \n",
       "all           i  0.19   0.2  0.19     3       109    97       144   1   \n",
       "              u  0.76  0.72  0.69    45       109     7       144   1   \n",
       "              r  0.61  0.62  0.59    35       109    23       144   1   \n",
       "              l  0.73  0.71  0.69    48       109    12       144   1   \n",
       "              b  0.82  0.81  0.81    72       109    10       144   1   \n",
       "fish          i  0.33  0.33  0.33     1         2     1         1   4   \n",
       "              u     1     1     1     2         2     0         1   5   \n",
       "              r     1     1     1     2         2     0         1   1   \n",
       "              l     1     1     1     2         2     0         1   2   \n",
       "              b  0.83  0.67  0.67     1         2     0         1   1   \n",
       "female        i  0.19  0.02  0.03     1        50     4         4   1   \n",
       "              u  0.94  0.76  0.82    37        50     0         4   2   \n",
       "              r  0.93  0.19  0.21     6        50     0         4   1   \n",
       "              l  0.75  0.26  0.37    13        50     3         4   1   \n",
       "              b  0.94  0.72  0.79    35        50     0         4   1   \n",
       "criminal      i  0.89  0.67  0.71     1         1     2         5   2   \n",
       "              u     1     1     1     1         1     0         5   4   \n",
       "food          i  0.83  0.67  0.67     1         1     1         2   3   \n",
       "              u     1     1     1     1         1     0         2  11   \n",
       "              b  0.83  0.67  0.67     1         1     1         2   2   \n",
       "animal        i  0.06  0.06  0.06     1        16    16        17   1   \n",
       "              u  0.84  0.82  0.81    11        16     1        17   1   \n",
       "              r  0.61  0.61   0.6     8        16     5        17   1   \n",
       "              l   0.8  0.67  0.62     5        16     0        17   1   \n",
       "              b  0.54  0.55  0.54     7        16     6        17   1   \n",
       "\n",
       "                                                          contexts  \n",
       "mammal        i                           herself actress her lady  \n",
       "              u                                              grass  \n",
       "              r                                              birth  \n",
       "              l                                 pregnant pregnancy  \n",
       "              b                                               baby  \n",
       "no-cat        i                                            herself  \n",
       "              u                                     about media so  \n",
       "              l                                          pregnancy  \n",
       "              b                                     baby beautiful  \n",
       "relation      i                          girl her she actress lady  \n",
       "              u                   everyone walk bed university art  \n",
       "              l                                           pregnant  \n",
       "              b                             married baby beautiful  \n",
       "object        i                                            herself  \n",
       "              u                                              grace  \n",
       "              r                                              birth  \n",
       "              l                                           pregnant  \n",
       "              b                                          beautiful  \n",
       "communication i                                                she  \n",
       "              u                                               walk  \n",
       "              r                                              birth  \n",
       "              l                                           pregnant  \n",
       "              b                                               baby  \n",
       "measure       i                herself her she sister actress lady  \n",
       "              u  associate stories media haired reading bed fri...  \n",
       "              l                                           pregnant  \n",
       "              b                             married baby beautiful  \n",
       "bird          i                                             sister  \n",
       "              u                                            stories  \n",
       "              b                                               baby  \n",
       "all           i                                            herself  \n",
       "              u                                            stories  \n",
       "              r                                              birth  \n",
       "              l                                           pregnant  \n",
       "              b                                          beautiful  \n",
       "fish          i                            herself actress she her  \n",
       "              u                      like stories sex friends mind  \n",
       "              r                                              birth  \n",
       "              l                                 pregnant pregnancy  \n",
       "              b                                            married  \n",
       "female        i                                                her  \n",
       "              u                                          haired in  \n",
       "              r                                              birth  \n",
       "              l                                           pregnant  \n",
       "              b                                          beautiful  \n",
       "criminal      i                                     herself sister  \n",
       "              u                            original like angel bed  \n",
       "food          i                                actress sister lady  \n",
       "              u  45 associate like walk sex about wine original...  \n",
       "              b                                     baby beautiful  \n",
       "animal        i                                            actress  \n",
       "              u                                            stories  \n",
       "              r                                              birth  \n",
       "              l                                           pregnant  \n",
       "              b                                            married  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop = 'female'\n",
    "model_name = 'giga_full_updated'\n",
    "top_cutoff = 3\n",
    "concept_cutoff = 3\n",
    "table = get_top_ev_categories(prop, model_name, top_cutoff, concept_cutoff)\n",
    "df = pd.DataFrame(table)\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean per cat\n",
    "\n",
    "properties = get_properties()\n",
    "prop_table = []\n",
    "for prop in properties:\n",
    "    table = get_top_ev_categories(prop, model_name, top_cutoff, concept_cutoff)\n",
    "    type_scores = defaultdict(list)\n",
    "    ev_type_mean_scores = dict()\n",
    "    for (cat, ev_type), f1_dict in table.items():\n",
    "        type_scores[ev_type].append(f1_dict['f1'])\n",
    "    for ev_type, scores in type_scores.items():\n",
    "        mean = sum(scores)/len(scores)\n",
    "        prop_dict = dict()\n",
    "        ev_type_mean_scores[ev_type] = mean\n",
    "    prop_dict['property'] = prop\n",
    "    prop_dict.update(ev_type_mean_scores)\n",
    "    prop_table.append(prop_dict)\n",
    "    \n",
    "cols = ['property', 'p', 'n', 'l', 'i', 'r', 'b', 'u']\n",
    "df = pd.DataFrame(prop_table)\n",
    "df = df[cols].sort_values('p', ascending = False).round(2).fillna('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>l</th>\n",
       "      <th>i</th>\n",
       "      <th>r</th>\n",
       "      <th>b</th>\n",
       "      <th>u</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>used_in_cooking</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>wheels</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>roll</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>-</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fly</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wings</td>\n",
       "      <td>0.88</td>\n",
       "      <td>-</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lay_eggs</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sweet</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>green</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dangerous</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>juicy</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.87</td>\n",
       "      <td>-</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hot</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.74</td>\n",
       "      <td>-</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>red</td>\n",
       "      <td>0.84</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>blue</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>black</td>\n",
       "      <td>0.78</td>\n",
       "      <td>-</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.79</td>\n",
       "      <td>-</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>round</td>\n",
       "      <td>0.77</td>\n",
       "      <td>-</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.66</td>\n",
       "      <td>-</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>swim</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cold</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>warm</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.58</td>\n",
       "      <td>-</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>yellow</td>\n",
       "      <td>0.58</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>made_of_wood</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>square</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>female</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           property     p     n     l     i     r     b     u\n",
       "9   used_in_cooking  0.97  0.81  0.94  0.37  0.98     -  0.94\n",
       "19           wheels  0.92     -  0.87  0.92   0.2     -  0.86\n",
       "15             roll   0.9     -  0.83  0.90  0.93     -  0.28\n",
       "4               fly  0.89  0.82  0.84  0.88   0.9  0.78  0.44\n",
       "6             wings  0.88     -  0.86  0.84   0.9  0.81  0.51\n",
       "20         lay_eggs  0.86     -     -  0.51  0.91     -  0.91\n",
       "7             sweet  0.86     -     -  0.55     -     -  0.88\n",
       "11            green  0.85     -     -  0.90  0.85     -  0.29\n",
       "5         dangerous  0.85  0.91  0.88  0.95  0.95  0.82  0.32\n",
       "10            juicy  0.85     -     -  0.90  0.87     -  0.53\n",
       "8               hot  0.84  0.74     -  0.31  0.91     -  0.89\n",
       "3               red  0.84     -     -  0.81   0.8     -  0.27\n",
       "13             blue  0.82     -     -  0.95  0.91     -  0.38\n",
       "2             black  0.78     -  0.68  0.87  0.79     -  0.20\n",
       "18            round  0.77     -  0.51  0.91  0.66     -  0.22\n",
       "21             swim  0.75     -     -  0.87  0.89     -  0.45\n",
       "17             cold  0.74  0.85     -  0.91  0.83     -  0.08\n",
       "1              warm  0.68  0.82  0.79  0.90  0.58     -  0.87\n",
       "14           yellow  0.58     -     -  0.85     -     -  0.80\n",
       "12     made_of_wood  0.32     -     -  0.88  0.89     -  0.90\n",
       "0            square     -     -     -  0.97  0.83     -  0.13\n",
       "16           female     -     -   0.7  0.44  0.63  0.76  0.89"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllrllr}\n",
      "\\toprule\n",
      "        property &     p &     n &     l &     i &     r &     b &     u \\\\\n",
      "\\midrule\n",
      " used\\_in\\_cooking &  0.97 &  0.81 &  0.94 &  0.37 &  0.98 &     - &  0.94 \\\\\n",
      "          wheels &  0.92 &     - &  0.87 &  0.92 &   0.2 &     - &  0.86 \\\\\n",
      "            roll &   0.9 &     - &  0.83 &  0.90 &  0.93 &     - &  0.28 \\\\\n",
      "             fly &  0.89 &  0.82 &  0.84 &  0.88 &   0.9 &  0.78 &  0.44 \\\\\n",
      "           wings &  0.88 &     - &  0.86 &  0.84 &   0.9 &  0.81 &  0.51 \\\\\n",
      "        lay\\_eggs &  0.86 &     - &     - &  0.51 &  0.91 &     - &  0.91 \\\\\n",
      "           sweet &  0.86 &     - &     - &  0.55 &     - &     - &  0.88 \\\\\n",
      "           green &  0.85 &     - &     - &  0.90 &  0.85 &     - &  0.29 \\\\\n",
      "       dangerous &  0.85 &  0.91 &  0.88 &  0.95 &  0.95 &  0.82 &  0.32 \\\\\n",
      "           juicy &  0.85 &     - &     - &  0.90 &  0.87 &     - &  0.53 \\\\\n",
      "             hot &  0.84 &  0.74 &     - &  0.31 &  0.91 &     - &  0.89 \\\\\n",
      "             red &  0.84 &     - &     - &  0.81 &   0.8 &     - &  0.27 \\\\\n",
      "            blue &  0.82 &     - &     - &  0.95 &  0.91 &     - &  0.38 \\\\\n",
      "           black &  0.78 &     - &  0.68 &  0.87 &  0.79 &     - &  0.20 \\\\\n",
      "           round &  0.77 &     - &  0.51 &  0.91 &  0.66 &     - &  0.22 \\\\\n",
      "            swim &  0.75 &     - &     - &  0.87 &  0.89 &     - &  0.45 \\\\\n",
      "            cold &  0.74 &  0.85 &     - &  0.91 &  0.83 &     - &  0.08 \\\\\n",
      "            warm &  0.68 &  0.82 &  0.79 &  0.90 &  0.58 &     - &  0.87 \\\\\n",
      "          yellow &  0.58 &     - &     - &  0.85 &     - &     - &  0.80 \\\\\n",
      "    made\\_of\\_wood &  0.32 &     - &     - &  0.88 &  0.89 &     - &  0.90 \\\\\n",
      "          square &     - &     - &     - &  0.97 &  0.83 &     - &  0.13 \\\\\n",
      "          female &     - &     - &   0.7 &  0.44 &  0.63 &  0.76 &  0.89 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evidence strength\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evidence_dict(model_name, prop, top_cutoff, concept_cutoff):\n",
    "    \n",
    "    annotation_name = f'annotation-tfidf-top_{top_cutoff}_{concept_cutoff}-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    f_annotation = f'{path_dir_annotation}/annotation-updated-done.csv'\n",
    "    \n",
    "    ev_dict = dict()\n",
    "    \n",
    "    with open(f_annotation) as infile:\n",
    "        data = list(csv.DictReader(infile))\n",
    "    for d in data:\n",
    "        et = d['evidence_type']\n",
    "        ev = d['context']\n",
    "        ev_dict[ev] = et\n",
    "    return ev_dict\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'crashed': 'u',\n",
       " 'similar': 'u',\n",
       " 'visibility': 'u',\n",
       " 'indicating': 'u',\n",
       " 'hunt': 'u',\n",
       " 'northwest': 'u',\n",
       " 'piloted': 'r',\n",
       " 'propeller': 'r',\n",
       " 'conducting': 'u',\n",
       " 'fighter': 'u',\n",
       " 'fighters': ' ',\n",
       " 'supersonic': 'u',\n",
       " 'pilot': 'r',\n",
       " 'flew': 'l',\n",
       " 'runway': 'u',\n",
       " 'flying': 'l',\n",
       " 'flown': 'l',\n",
       " 'aviation': 'r',\n",
       " 'cockpit': 'r',\n",
       " 'downed': 'r',\n",
       " 'wreckage': 'r',\n",
       " 'peruvian': 'u',\n",
       " 'spy': 'b',\n",
       " 'downing': 'r',\n",
       " 'radar': 'r',\n",
       " 'russian': 'b',\n",
       " '270': 'u',\n",
       " 'recorder': 'u',\n",
       " 'missiles': 'r',\n",
       " 'pentagon': 'b',\n",
       " 'fuselage': 'r',\n",
       " 'fired': 'u',\n",
       " 'cuban': 'b',\n",
       " 'us': 'b',\n",
       " 'pakistani': 'b',\n",
       " 'yemeni': 'b',\n",
       " '800': 'u',\n",
       " 'intercept': 'r',\n",
       " 'attacks': 'b',\n",
       " 'pakistan': 'b',\n",
       " 'descended': 'r',\n",
       " 'yemen': 'b',\n",
       " 'strikes': 'b',\n",
       " 'terrorist': 'b',\n",
       " 'terrorists': 'b',\n",
       " 'locate': 'u',\n",
       " 'iranian': 'b',\n",
       " 'confirmed': 'u',\n",
       " 'withstand': 'u',\n",
       " 'controversial': 'u',\n",
       " 'perished': 'u',\n",
       " 'intelligence': 'u',\n",
       " 'gather': 'u',\n",
       " 'thwarted': 'u',\n",
       " 'deciding': 'u',\n",
       " 'publicly': 'u',\n",
       " 'bird': 'i',\n",
       " 'nest': 'r',\n",
       " 'species': 'u',\n",
       " 'birds': 'i',\n",
       " 'wings': 'p',\n",
       " 'found': 'u',\n",
       " 'it': 'u',\n",
       " 'hidden': 'u',\n",
       " 'quail': 'i',\n",
       " 'pigeon': 'i',\n",
       " 'flies': 'l',\n",
       " 'hatched': 'r',\n",
       " 'game': 'i',\n",
       " 'one': 'u',\n",
       " 'near': 'u',\n",
       " 'several': 'u',\n",
       " 'this': 'u',\n",
       " 'commonly': 'u',\n",
       " 'clear': 'u',\n",
       " 'raised': 'u',\n",
       " 'probably': 'u',\n",
       " 'eggs': 'r',\n",
       " 'roasted': 'r',\n",
       " 'outbreaks': 'u',\n",
       " 'manager': 'u',\n",
       " 'owner': 'u',\n",
       " 'chasing': 'u',\n",
       " 'on': 'u',\n",
       " 'but': 'u',\n",
       " 'garden': 'u',\n",
       " 'amp': 'u',\n",
       " 'had': 'u',\n",
       " 'their': 'u',\n",
       " 'home': 'u',\n",
       " 'dog': 'u',\n",
       " 'replaced': 'u',\n",
       " 'beak': 'r',\n",
       " 'dear': 'u',\n",
       " 'nesting': 'r',\n",
       " 'feet': 'u',\n",
       " 'failing': 'u',\n",
       " 'fighting': 'u',\n",
       " 'lake': 'u',\n",
       " '28': 'u',\n",
       " 'distinctive': 'u',\n",
       " '62': 'u',\n",
       " 'bright': 'u',\n",
       " 'following': 'u',\n",
       " 'fat': 'u',\n",
       " 'have': 'u',\n",
       " 'than': 'u',\n",
       " 'plastic': 'u',\n",
       " 'number': 'u',\n",
       " 'go': 'u',\n",
       " 'hours': 'u',\n",
       " 'starting': 'u',\n",
       " 'they': 'u',\n",
       " 'do': 'u',\n",
       " 'large': 'u',\n",
       " '250': 'u',\n",
       " 'turning': 'u',\n",
       " 'weeks': 'u',\n",
       " 'water': 'u',\n",
       " 'includes': 'u',\n",
       " 'young': 'u',\n",
       " 'inside': 'u',\n",
       " 'virus': 'b',\n",
       " 'poultry': 'i',\n",
       " 'detected': 'u',\n",
       " 'chickens': 'i',\n",
       " 'suspected': 'u',\n",
       " 'wild': 'u',\n",
       " 'fowl': 'i',\n",
       " 'farms': 'u',\n",
       " 'farm': 'u',\n",
       " 'feathers': 'r',\n",
       " 'free': 'u',\n",
       " 'said': 'u',\n",
       " 'turkey': 'i',\n",
       " 'pet': 'u',\n",
       " 'dead': 'u',\n",
       " 'culled': 'u',\n",
       " 'wildlife': 'u',\n",
       " 'duck': 'i',\n",
       " 'slaughter': 'u',\n",
       " 'two': 'u',\n",
       " 'so': 'u',\n",
       " 'could': 'u',\n",
       " 'pig': 'u',\n",
       " 'being': 'u',\n",
       " 'flock': 'r',\n",
       " 'thanksgiving': 'r',\n",
       " 'million': 'u',\n",
       " 'foot': 'u',\n",
       " 'baby': 'u',\n",
       " 'them': 'u',\n",
       " 'ostrich': 'i',\n",
       " 'same': 'u',\n",
       " 'least': 'u',\n",
       " 'whether': 'u',\n",
       " 'kind': 'u',\n",
       " 'geese': 'i',\n",
       " 'does': 'u',\n",
       " 'common': 'u',\n",
       " 'appeared': 'u',\n",
       " 'every': 'u',\n",
       " 'farming': 'u',\n",
       " 'sight': 'u',\n",
       " 'brown': 'u',\n",
       " '300': 'u',\n",
       " 'almost': 'u',\n",
       " 'dozen': 'u',\n",
       " 'strange': 'u',\n",
       " 'adding': 'u',\n",
       " 'longer': 'u',\n",
       " 'typical': 'u',\n",
       " 'bought': 'u',\n",
       " 'plants': 'u',\n",
       " 'goose': 'i',\n",
       " 'charge': 'u',\n",
       " 'wash': 'u',\n",
       " 'hens': 'i',\n",
       " 'rabbit': 'u',\n",
       " 'hen': 'i',\n",
       " 'hiding': 'u',\n",
       " 'nobody': 'u',\n",
       " 'wherever': 'u',\n",
       " 'blame': 'u',\n",
       " 'hatching': 'r',\n",
       " 'sparrow': 'i',\n",
       " 'side': 'u',\n",
       " 'like': 'u',\n",
       " '0': 'u',\n",
       " 'chocolate': 'u',\n",
       " 'be': 'u',\n",
       " 'mice': 'u',\n",
       " 'migratory': 'u',\n",
       " 'always': 'u',\n",
       " '20': 'u',\n",
       " 'normally': 'u',\n",
       " 'web': 'u',\n",
       " 'worst': 'u',\n",
       " 'kong': 'u',\n",
       " 'populations': 'u',\n",
       " 'pub': 'u',\n",
       " 'mouse': 'u',\n",
       " 'perched': 'r',\n",
       " 'sweeping': 'u',\n",
       " 'prairie': 'u',\n",
       " 'been': 'u',\n",
       " 'before': 'u',\n",
       " 'away': 'u',\n",
       " 'hard': 'u',\n",
       " 'american': 'u',\n",
       " 'over': 'u',\n",
       " 'flower': 'u',\n",
       " '30': 'u',\n",
       " 'from': 'u',\n",
       " 'would': 'u',\n",
       " 'golden': 'u',\n",
       " 'leg': 'u',\n",
       " 'hit': 'u',\n",
       " 'trade': 'u',\n",
       " 'evolved': 'u',\n",
       " 'announcement': 'u',\n",
       " 'talking': 'u',\n",
       " 'eve': 'u',\n",
       " 'hawk': 'u',\n",
       " 'alternative': 'u',\n",
       " 'nasty': 'u',\n",
       " 'homemade': 'u',\n",
       " 'months': 'u',\n",
       " 'proverbial': 'u',\n",
       " 'honey': 'u',\n",
       " 'serious': 'u',\n",
       " 'neither': 'u',\n",
       " 'chuck': 'u',\n",
       " 'below': 'u',\n",
       " 'ben': 'u',\n",
       " 'field': 'u',\n",
       " 'pudding': 'u',\n",
       " 'netherlands': 'u',\n",
       " 'sent': 'u',\n",
       " 'team': 'u',\n",
       " 'seen': 'u',\n",
       " 'appreciate': 'u',\n",
       " 'unable': 'u',\n",
       " 'increase': 'u',\n",
       " 'research': 'u',\n",
       " 'worry': 'u',\n",
       " 'cages': 'u',\n",
       " 'stupid': 'u',\n",
       " 'engaged': 'u',\n",
       " 'growing': 'u',\n",
       " 'campaign': 'u',\n",
       " 'starts': 'u',\n",
       " 'realized': 'u',\n",
       " 'dick': 'u',\n",
       " 'suggests': 'u',\n",
       " 'habits': 'u',\n",
       " 'acting': 'u',\n",
       " 'weekends': 'u',\n",
       " '51': 'u',\n",
       " 'resulting': 'u',\n",
       " 'maintained': 'u',\n",
       " 'stricken': 'u',\n",
       " 'agent': 'u',\n",
       " 'meets': 'u',\n",
       " 'broke': 'u',\n",
       " 'rain': 'u',\n",
       " 'jumping': 'u',\n",
       " 'epidemic': 'u',\n",
       " 'variation': 'u',\n",
       " 'rolling': 'u',\n",
       " 'friendly': 'u',\n",
       " 'if': 'u',\n",
       " 'hatch': 'u',\n",
       " 'farmers': 'u',\n",
       " 'cat': 'u',\n",
       " 'only': 'u',\n",
       " 'told': 'u',\n",
       " 'cover': 'u',\n",
       " 'some': 'u',\n",
       " '15': 'u',\n",
       " 'started': 'u',\n",
       " 'counting': 'u',\n",
       " 'can': 'u',\n",
       " 'control': 'u',\n",
       " 'sized': 'u',\n",
       " 'her': 'u',\n",
       " 'while': 'u',\n",
       " 'turned': 'u',\n",
       " 'deal': 'u',\n",
       " '23': 'u',\n",
       " 'exotic': 'u',\n",
       " 'even': 'u',\n",
       " 'where': 'u',\n",
       " 'killing': 'u',\n",
       " 'after': 'u',\n",
       " 'kills': 'u',\n",
       " 'die': 'u',\n",
       " '10': 'u',\n",
       " 'different': 'u',\n",
       " 'affected': 'u',\n",
       " 'also': 'u',\n",
       " 'wednesday': 'u',\n",
       " 'used': 'u',\n",
       " 'all': 'u',\n",
       " 'watching': 'u',\n",
       " 've': 'u',\n",
       " 'knew': 'u',\n",
       " 'dance': 'u',\n",
       " 'likes': 'u',\n",
       " 'production': 'u',\n",
       " 'flu': 'r',\n",
       " 'h5n1': 'u',\n",
       " 'outbreak': 'u',\n",
       " 'strain': 'u',\n",
       " 'infected': 'u',\n",
       " 'human': 'u',\n",
       " 'avian': 'r',\n",
       " 'cage': 'u',\n",
       " 'tested': 'u',\n",
       " 'ducks': 'i',\n",
       " 'samples': 'u',\n",
       " 'agriculture': 'u',\n",
       " 'disease': 'u',\n",
       " 'killed': 'u',\n",
       " 'that': 'u',\n",
       " 'animal': 'r',\n",
       " 'tests': 'u',\n",
       " 'rare': 'u',\n",
       " 'people': 'u',\n",
       " 'flocks': 'r',\n",
       " 'national': 'u',\n",
       " 'its': 'u',\n",
       " 'sick': 'u',\n",
       " 'feeding': 'u',\n",
       " 'not': 'u',\n",
       " 'were': 'u',\n",
       " 'roasting': 'r',\n",
       " 'testing': 'u',\n",
       " 'more': 'u',\n",
       " 'slaughtered': 'u',\n",
       " 'turkeys': 'i',\n",
       " 'stuffing': 'r',\n",
       " 'oven': 'r',\n",
       " 'backyard': 'u',\n",
       " 'fly': 'l',\n",
       " 'banned': 'u',\n",
       " 'any': 'u',\n",
       " 'monday': 'u',\n",
       " 'test': 'u',\n",
       " 'lab': 'u',\n",
       " 'africa': 'u',\n",
       " 'ban': 'u',\n",
       " 'head': 'u',\n",
       " 'village': 'u',\n",
       " 'government': 'u',\n",
       " 'third': 'u',\n",
       " 'livestock': 'r',\n",
       " 'contaminated': 'u',\n",
       " 'swan': 'i',\n",
       " '25': 'u',\n",
       " 'animals': 'r',\n",
       " '100': 'u',\n",
       " 'calls': 'u',\n",
       " '90': 'u',\n",
       " 'spokesman': 'u',\n",
       " 'taken': 'u',\n",
       " 'southern': 'u',\n",
       " '500': 'u',\n",
       " 'raising': 'u',\n",
       " 'week': 'u',\n",
       " 'dying': 'u',\n",
       " 'saturday': 'u',\n",
       " 'feather': 'r',\n",
       " 'emerged': 'u',\n",
       " 'according': 'u',\n",
       " 'genes': 'u',\n",
       " 'center': 'u',\n",
       " 'recently': 'u',\n",
       " 'capital': 'u',\n",
       " 'easily': 'u',\n",
       " 'import': 'u',\n",
       " 'keep': 'u',\n",
       " 'amid': 'u',\n",
       " 'reserve': 'u',\n",
       " 'across': 'u',\n",
       " 'north': 'u',\n",
       " '60': 'u',\n",
       " 'hunter': 'u',\n",
       " 'stepped': 'u',\n",
       " 'covered': 'u',\n",
       " 'seven': 'u',\n",
       " 'types': 'u',\n",
       " 'radius': 'u',\n",
       " 'moist': 'u',\n",
       " 'tough': 'u',\n",
       " 'sounds': 'u',\n",
       " 'added': 'u',\n",
       " 'prepared': 'u',\n",
       " 'down': 'u',\n",
       " 'cavity': 'u',\n",
       " 'market': 'u',\n",
       " 'must': 'u',\n",
       " 'shoot': 'u',\n",
       " 'passed': 'u',\n",
       " 'farmer': 'u',\n",
       " 'why': 'u',\n",
       " 'flip': 'u',\n",
       " 'conducted': 'u',\n",
       " 'wing': 'u',\n",
       " '35': 'u',\n",
       " 'rose': 'u',\n",
       " 'month': 'u',\n",
       " 'pass': 'u',\n",
       " 'able': 'u',\n",
       " '40': 'u',\n",
       " 'states': 'u',\n",
       " 'pigeons': 'i',\n",
       " 'doing': 'u',\n",
       " 'mainly': 'u',\n",
       " 'six': 'u',\n",
       " 'word': 'u',\n",
       " 'islands': 'u',\n",
       " 'company': 'u',\n",
       " 'close': 'u',\n",
       " 'grouse': 'u',\n",
       " 'urged': 'u',\n",
       " '2006': 'u',\n",
       " 'quickly': 'u',\n",
       " 'despite': 'u',\n",
       " 'gone': 'u',\n",
       " 'let': 'u',\n",
       " 'pheasant': 'i',\n",
       " 'vice': 'u',\n",
       " 'woods': 'u',\n",
       " '46': 'u',\n",
       " 'lifted': 'u',\n",
       " 'chicks': 'i',\n",
       " 'cooks': 'u',\n",
       " 'regular': 'u',\n",
       " 'appearance': 'u',\n",
       " 'bones': 'u',\n",
       " 'brush': 'u',\n",
       " 'contamination': 'u',\n",
       " 'daily': 'u',\n",
       " 'change': 'u',\n",
       " 'british': 'u',\n",
       " 'compensation': 'u',\n",
       " 'checks': 'u',\n",
       " 'stepping': 'u',\n",
       " 'drive': 'u',\n",
       " 'measure': 'u',\n",
       " 'difficult': 'u',\n",
       " 'refuge': 'u',\n",
       " '48': 'u',\n",
       " 'excrement': 'u',\n",
       " 'raise': 'u',\n",
       " 'cry': 'u',\n",
       " 'continued': 'u',\n",
       " 'indication': 'u',\n",
       " 'numerous': 'u',\n",
       " 'protective': 'u',\n",
       " 'neck': 'u',\n",
       " 'else': 'u',\n",
       " 'juicy': 'u',\n",
       " '65': 'u',\n",
       " 'shooting': 'u',\n",
       " 'putting': 'u',\n",
       " 'questions': 'u',\n",
       " 'ordinary': 'u',\n",
       " 'acre': 'u',\n",
       " 'space': 'u',\n",
       " 'whatever': 'u',\n",
       " '36': 'u',\n",
       " 'disappeared': 'u',\n",
       " 'upon': 'u',\n",
       " 'amazing': 'u',\n",
       " 'fans': 'u',\n",
       " 'rising': 'u',\n",
       " 'rooster': 'i',\n",
       " 'primarily': 'u',\n",
       " 'practice': 'u',\n",
       " 'character': 'u',\n",
       " 'hungry': 'u',\n",
       " 'appropriate': 'u',\n",
       " 'thus': 'u',\n",
       " 'lead': 'u',\n",
       " 'somewhat': 'u',\n",
       " 'reduce': 'u',\n",
       " 'providing': 'u',\n",
       " 'enter': 'u',\n",
       " 'track': 'u',\n",
       " 'inspections': 'u',\n",
       " 'hide': 'u',\n",
       " 'sales': 'u',\n",
       " 'shy': 'u',\n",
       " 'letting': 'u',\n",
       " 'lewis': 'u',\n",
       " 'sides': 'u',\n",
       " 'sisters': 'u',\n",
       " 'memorable': 'u',\n",
       " 'grew': 'u',\n",
       " 'guinea': 'u',\n",
       " 'rearing': 'u',\n",
       " 'complaining': 'u',\n",
       " 'fortune': 'u',\n",
       " 'note': 'u',\n",
       " 'traders': 'u',\n",
       " 'finish': 'u',\n",
       " 'produces': 'u',\n",
       " 'de': 'u',\n",
       " 'sets': 'u',\n",
       " 'pronounced': 'u',\n",
       " 'endless': 'u',\n",
       " 'pen': 'u',\n",
       " 'manages': 'u',\n",
       " 'chick': 'i',\n",
       " 'degree': 'u',\n",
       " 'tend': 'u',\n",
       " 'phrase': 'u',\n",
       " 'grilled': 'r',\n",
       " 'breast': 'r',\n",
       " 'chicken': 'i',\n",
       " 'roast': 'r',\n",
       " 'egg': 'r',\n",
       " 'lamb': 'u',\n",
       " 'veal': 'u',\n",
       " 'tender': 'u',\n",
       " 'bacon': 'u',\n",
       " 'turn': 'u',\n",
       " 'bag': 'u',\n",
       " 'low': 'u',\n",
       " 'out': 'u',\n",
       " 'sheep': 'u',\n",
       " 'sold': 'u',\n",
       " 'because': 'u',\n",
       " 'black': 'u',\n",
       " 'cider': 'u',\n",
       " 'get': 'u',\n",
       " 'often': 'u',\n",
       " 'nicely': 'u',\n",
       " 'fertilized': 'u',\n",
       " 'foie': 'u',\n",
       " 'running': 'u',\n",
       " 'lot': 'u',\n",
       " 'halfway': 'u',\n",
       " 'breed': 'u',\n",
       " 'sitting': 'u',\n",
       " 'set': 'u',\n",
       " 'takes': 'u',\n",
       " '600': 'u',\n",
       " 'begins': 'u',\n",
       " 'truffles': 'u',\n",
       " 'ubiquitous': 'u',\n",
       " 'parent': 'u',\n",
       " 'gras': 'u',\n",
       " 'left': 'u',\n",
       " 'fact': 'u',\n",
       " 'smaller': 'u',\n",
       " 'guess': 'u',\n",
       " 'ahead': 'u'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'giga_full_updated'\n",
    "prop = 'wings'\n",
    "top_cutoff = 3\n",
    "concept_cutoff = 3\n",
    "\n",
    "evidence_dict = get_evidence_dict(model_name, prop, top_cutoff, concept_cutoff)\n",
    "evidence_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import stdev\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tfidf_score(prop, concept, evidence_word, label, \n",
    "                     model_name, top_cutoff, concept_cutoff):\n",
    "    \n",
    "    tfidf_scores = []\n",
    "    dir_res = f'../results/{model_name}/tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    categories = get_categories(prop, model_name)\n",
    "    for cat in categories:\n",
    "        f =  f'{dir_res}/{prop}/{cat}/{label}/{concept}.csv'\n",
    "        if os.path.isfile(f):\n",
    "            with open(f) as infile:\n",
    "                data = list(csv.DictReader(infile))\n",
    "            for d in data:\n",
    "                context = d['']\n",
    "                diff =  float(d['diff'])\n",
    "                if context == evidence_word and diff > 0:\n",
    "                    score = float(d['target'])\n",
    "                    tfidf_scores.append(score)\n",
    "    return tfidf_scores\n",
    "\n",
    "def get_mean(numbers):\n",
    "    if len(numbers) > 0:\n",
    "        mean = sum(numbers)/len(numbers)\n",
    "    else:\n",
    "        mean = 0\n",
    "    return mean\n",
    "\n",
    "  \n",
    "def get_relation_combinations(properties, combinations):\n",
    "    \n",
    "    relation_pair_dict = defaultdict(set)\n",
    "\n",
    "    \n",
    "    for prop in properties:\n",
    "        prop_dict = load_prop_data(prop)\n",
    "        for c, d in prop_dict.items():\n",
    "            ml_label = d['ml_label']\n",
    "            if ml_label in {'all', 'some', 'all-some', 'few-some'}:\n",
    "                l = 'pos'\n",
    "            elif ml_label in {'few'}:\n",
    "                l = 'neg'\n",
    "            relation_pair_dict[l].add((prop, c))\n",
    "            if l == 'pos':\n",
    "                rel_dict = d['relations']\n",
    "                for combination in combinations:\n",
    "                    relations = set([rel for rel, p in rel_dict.items() if p > 0.5])\n",
    "                    if combination == relations:\n",
    "                        l_comb = tuple(sorted(relations))\n",
    "                        relation_pair_dict[l_comb].add((prop, c))\n",
    "    return relation_pair_dict   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg 1545\n",
      "pos 2135\n",
      "('implied_category', 'variability_limited') 21\n",
      "('variability_limited',) 114\n",
      "('implied_category',) 16\n",
      "('implied_category', 'typical_of_concept') 13\n",
      "('typical_of_concept', 'typical_of_property') 4\n",
      "('typical_of_concept',) 4\n",
      "('afforded_unusual',) 20\n",
      "('afforded_usual',) 3\n",
      "\n",
      "{('swim', 'cob'), ('warm', 'brogue'), ('wings', 'roach'), ('wheels', 'tank'), ('dangerous', 'pentobarbital'), ('round', 'pepperoni'), ('roll', 'bike'), ('round', 'patty'), ('round', 'cherry'), ('wheels', 'saloon'), ('lay_eggs', 'neritidae'), ('wings', 'cricket'), ('lay_eggs', 'crane'), ('swim', 'bay'), ('wheels', 'underframe'), ('lay_eggs', 'flounder')}\n",
      "\n",
      "{('square', 'laptop'), ('sweet', 'breadfruit'), ('made_of_wood', 'ladle'), ('round', 'pineapple'), ('roll', 'cart'), ('made_of_wood', 'girder'), ('juicy', 'anjou'), ('fly', 'fowl'), ('round', 'gourd'), ('round', 'sapodilla'), ('round', 'cabbage'), ('square', 'computer'), ('round', 'onion'), ('round', 'lemon'), ('square', 'blackboard'), ('sweet', 'carrot'), ('made_of_wood', 'transom'), ('wings', 'beetle'), ('round', 'nutlet'), ('green', 'fenugreek'), ('red', 'tongue')}\n",
      "\n",
      "{('wheels', 'wheel'), ('made_of_wood', 'club'), ('fly', 'babbler'), ('juicy', 'meat')}\n",
      "\n",
      "{('yellow', 'yolk'), ('dangerous', 'adze'), ('dangerous', 'hippopotamus'), ('black', 'housefly'), ('black', 'pupil'), ('round', 'coconut'), ('round', 'cucurbit'), ('dangerous', 'phencyclidine'), ('wings', 'cock'), ('wings', 'weka'), ('wings', 'weaver'), ('dangerous', 'morphine'), ('yellow', 'buttercup')}\n",
      "\n",
      "set()\n",
      "\n",
      "set()\n",
      "\n",
      "{('red', 'watermelon'), ('red', 'tomato'), ('sweet', 'desert'), ('green', 'jade')}\n",
      "\n",
      "{('lay_eggs', 'stockfish'), ('swim', 'goldeneye'), ('lay_eggs', 'platypus')}\n",
      "\n",
      "{('swim', 'retriever'), ('swim', 'cat'), ('roll', 'windscreen'), ('swim', 'armadillo'), ('swim', 'deer'), ('roll', 'cloth'), ('swim', 'vervet'), ('swim', 'goat'), ('swim', 'painter'), ('roll', 'pen'), ('swim', 'boar'), ('roll', 'pig'), ('swim', 'gnu'), ('swim', 'panther'), ('roll', 'bolt'), ('swim', 'mouse'), ('swim', 'mankind'), ('swim', 'leopard'), ('swim', 'glutton'), ('swim', 'pony')}\n"
     ]
    }
   ],
   "source": [
    "combinations = [\n",
    "                    {'implied_category'},\n",
    "                    {'implied_category', 'variability_limited'},\n",
    "                    {'variability_limited'},\n",
    "                    {'typical_of_property'},\n",
    "                    {'typical_of_concept'},\n",
    "                    {'implied_category', 'typical_of_concept'},\n",
    "                    {'implied_cateogry', 'typical_of_property'},\n",
    "                    {'typical_of_concept', 'typical_of_property'},\n",
    "                    {'afforded_usual'},\n",
    "                    {'afforded_unusual'}\n",
    "                \n",
    "                    ]\n",
    "\n",
    "properties = get_properties()\n",
    "relation_pair_dict = get_relation_combinations(properties, combinations)\n",
    "for rel, pairs in relation_pair_dict.items():\n",
    "    print(rel, len(pairs))\n",
    "print()\n",
    "print(relation_pair_dict[('implied_category',  )]) \n",
    "print()\n",
    "print(relation_pair_dict[('implied_category', 'variability_limited', )])\n",
    "print()\n",
    "print(relation_pair_dict[('typical_of_concept',  )]) \n",
    "print()\n",
    "print(relation_pair_dict[('implied_category', 'typical_of_concept')])\n",
    "print()\n",
    "print(relation_pair_dict[('typical_of_property',  )]) \n",
    "print()\n",
    "print(relation_pair_dict[('implied_category', 'typical_of_property')])\n",
    "print()\n",
    "print(relation_pair_dict[('typical_of_concept', 'typical_of_property')])\n",
    "print()\n",
    "print(relation_pair_dict[('afforded_usual', )])\n",
    "print()\n",
    "print(relation_pair_dict[('afforded_unusual', )])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012380345716773471\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_rel = 'pos'\n",
    "label = 'pos'\n",
    "\n",
    "all_scores = []\n",
    "all_means = []\n",
    "for prop, concept in relation_pair_dict[label_rel]:\n",
    "    evidence_word = prop\n",
    "    if prop == 'lay_eggs':\n",
    "        evidence_word = 'eggs'\n",
    "    elif prop == 'used_in_cooking':\n",
    "        evidence_word = 'cook'\n",
    "    elif prop == 'made_of_wood':\n",
    "        evidence_word = 'wood'\n",
    "    elif prop == 'has_wings':\n",
    "        evidence_word = 'wings'\n",
    "    elif prop == 'has_wheels':\n",
    "        evidence_word = 'wheels'\n",
    "    scores = load_tfidf_score(prop, concept, evidence_word, label, \n",
    "                      model_name, top_cutoff, concept_cutoff)\n",
    "    all_scores.extend(scores)\n",
    "    mean = get_mean(scores)\n",
    "    all_means.append(mean)\n",
    "\n",
    "print(get_mean(all_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0019888443681951185\n"
     ]
    }
   ],
   "source": [
    "label_rel = 'neg'\n",
    "label = 'neg'\n",
    "\n",
    "all_scores = []\n",
    "all_means = []\n",
    "for prop, concept in relation_pair_dict[label_rel]:\n",
    "    evidence_word = prop\n",
    "    if prop == 'lay_eggs':\n",
    "        evidence_word = 'eggs'\n",
    "    elif prop == 'used_in_cooking':\n",
    "        evidence_word = 'cook'\n",
    "    elif prop == 'made_of_wood':\n",
    "        evidence_word = 'wood'\n",
    "    elif prop == 'has_wings':\n",
    "        evidence_word = 'wings'\n",
    "    elif prop == 'has_wheels':\n",
    "        evidence_word = 'wheels'\n",
    "    scores = load_tfidf_score(prop, concept, evidence_word, label, \n",
    "                      model_name, top_cutoff, concept_cutoff)\n",
    "    all_scores.extend(scores)\n",
    "    mean = get_mean(scores)\n",
    "    all_means.append(mean)\n",
    "\n",
    "print(get_mean(all_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0018485234171035732\n"
     ]
    }
   ],
   "source": [
    "label_rel = ('implied_category', )\n",
    "label = 'pos'\n",
    "\n",
    "all_scores = []\n",
    "all_means = []\n",
    "for prop, concept in relation_pair_dict[label_rel]:\n",
    "    evidence_word = prop\n",
    "    if prop == 'lay_eggs':\n",
    "        evidence_word = 'eggs'\n",
    "    elif prop == 'used_in_cooking':\n",
    "        evidence_word = 'cook'\n",
    "    elif prop == 'made_of_wood':\n",
    "        evidence_word = 'wood'\n",
    "    elif prop == 'has_wings':\n",
    "        evidence_word = 'wings'\n",
    "    elif prop == 'has_wheels':\n",
    "        evidence_word = 'wheels'\n",
    "\n",
    "    scores = load_tfidf_score(prop, concept, evidence_word, label, \n",
    "                      model_name, top_cutoff, concept_cutoff)\n",
    "    all_scores.extend(scores)\n",
    "    mean = get_mean(scores)\n",
    "    all_means.append(mean)\n",
    "\n",
    "print(get_mean(all_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011092839659587376\n"
     ]
    }
   ],
   "source": [
    "label_rel = ('variability_limited', )\n",
    "label = 'pos'\n",
    "\n",
    "all_scores = []\n",
    "all_means = []\n",
    "for prop, concept in relation_pair_dict[label_rel]:\n",
    "    evidence_word = prop\n",
    "    if prop == 'lay_eggs':\n",
    "        evidence_word = 'eggs'\n",
    "    elif prop == 'used_in_cooking':\n",
    "        evidence_word = 'cook'\n",
    "    elif prop == 'made_of_wood':\n",
    "        evidence_word = 'wood'\n",
    "    elif prop == 'has_wings':\n",
    "        evidence_word = 'wings'\n",
    "    elif prop == 'has_wheels':\n",
    "        evidence_word = 'wheels'\n",
    "\n",
    "    scores = load_tfidf_score(prop, concept, evidence_word, label, \n",
    "                      model_name, top_cutoff, concept_cutoff)\n",
    "    all_scores.extend(scores)\n",
    "    mean = get_mean(scores)\n",
    "    all_means.append(mean)\n",
    "\n",
    "print(get_mean(all_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006298089086881645\n"
     ]
    }
   ],
   "source": [
    "label_rel = ('implied_category', 'variability_limited')\n",
    "label = 'pos'\n",
    "\n",
    "all_scores = []\n",
    "all_means = []\n",
    "for prop, concept in relation_pair_dict[label_rel]:\n",
    "    evidence_word = prop\n",
    "    if prop == 'lay_eggs':\n",
    "        evidence_word = 'eggs'\n",
    "    elif prop == 'used_in_cooking':\n",
    "        evidence_word = 'cook'\n",
    "    elif prop == 'made_of_wood':\n",
    "        evidence_word = 'wood'\n",
    "    elif prop == 'has_wings':\n",
    "        evidence_word = 'wings'\n",
    "    elif prop == 'has_wheels':\n",
    "        evidence_word = 'wheels'\n",
    "\n",
    "    scores = load_tfidf_score(prop, concept, evidence_word, label, \n",
    "                      model_name, top_cutoff, concept_cutoff)\n",
    "    all_scores.extend(scores)\n",
    "    mean = get_mean(scores)\n",
    "    all_means.append(mean)\n",
    "\n",
    "print(get_mean(all_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025515742044588785\n"
     ]
    }
   ],
   "source": [
    "label_rel = ('afforded_usual', )\n",
    "label = 'pos'\n",
    "\n",
    "all_scores = []\n",
    "all_means = []\n",
    "for prop, concept in relation_pair_dict[label_rel]:\n",
    "    evidence_word = prop\n",
    "    if prop == 'lay_eggs':\n",
    "        evidence_word = 'eggs'\n",
    "    elif prop == 'used_in_cooking':\n",
    "        evidence_word = 'cook'\n",
    "    elif prop == 'made_of_wood':\n",
    "        evidence_word = 'wood'\n",
    "    elif prop == 'has_wings':\n",
    "        evidence_word = 'wings'\n",
    "    elif prop == 'has_wheels':\n",
    "        evidence_word = 'wheels'\n",
    "\n",
    "    scores = load_tfidf_score(prop, concept, evidence_word, label, \n",
    "                      model_name, top_cutoff, concept_cutoff)\n",
    "    all_scores.extend(scores)\n",
    "    mean = get_mean(scores)\n",
    "    all_means.append(mean)\n",
    "\n",
    "\n",
    "print(get_mean(all_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003130250052305159\n"
     ]
    }
   ],
   "source": [
    "label_rel = ('afforded_unusual', )\n",
    "label = 'pos'\n",
    "\n",
    "all_scores = []\n",
    "all_means = []\n",
    "for prop, concept in relation_pair_dict[label_rel]:\n",
    "    evidence_word = prop\n",
    "    if prop == 'lay_eggs':\n",
    "        evidence_word = 'eggs'\n",
    "    elif prop == 'used_in_cooking':\n",
    "        evidence_word = 'cook'\n",
    "    elif prop == 'made_of_wood':\n",
    "        evidence_word = 'wood'\n",
    "    elif prop == 'has_wings':\n",
    "        evidence_word = 'wings'\n",
    "    elif prop == 'has_wheels':\n",
    "        evidence_word = 'wheels'\n",
    "\n",
    "    scores = load_tfidf_score(prop, concept, evidence_word, label, \n",
    "                      model_name, top_cutoff, concept_cutoff)\n",
    "    all_scores.extend(scores)\n",
    "    mean = get_mean(scores)\n",
    "    all_means.append(mean)\n",
    "\n",
    "print(get_mean(all_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021969832408808006\n"
     ]
    }
   ],
   "source": [
    "prop = 'red'\n",
    "concept = 'ambulance'\n",
    "evidence_word = 'red'\n",
    "label = 'pos'\n",
    "#lay_eggs', 'neritidae\n",
    "scores = load_tfidf_score(prop, concept, evidence_word, label, \n",
    "                     model_name, top_cutoff, concept_cutoff)\n",
    "print(get_mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how often direct mentions of property words are mentioned \n",
    "# in the context of the target pairs vs the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
