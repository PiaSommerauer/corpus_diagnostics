{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze based on semantic categories\n",
    "\n",
    "1.) change tfidf so we compare equivalent categories only - done\n",
    "2.) update ranking accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1446\n",
      "1636\n"
     ]
    }
   ],
   "source": [
    "f_original = os.listdir('../contexts/giga_full/vocab')\n",
    "print(len(f_original))\n",
    "f_update = os.listdir('../contexts/giga_full_updated/vocab')\n",
    "print(len(f_update))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1669\n",
      "1874\n"
     ]
    }
   ],
   "source": [
    "f_original = os.listdir('../contexts/wiki/vocab')\n",
    "print(len(f_original))\n",
    "f_update = os.listdir('../contexts/wiki_updated/vocab')\n",
    "print(len(f_update))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_categories(prop, model_name):\n",
    "    analysis_type = 'tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    path_dir = f'../results/{model_name}/{analysis_type}'\n",
    "    path_dir = f'{path_dir}/{prop}'\n",
    "    categories = set()\n",
    "    for d in os.listdir(path_dir):\n",
    "        categories.add(d)\n",
    "    return categories\n",
    "\n",
    "def get_context_cnts(prop, cat, label, model_name):\n",
    "    \n",
    "    analysis_type = 'tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    path_dir = f'../results/{model_name}/{analysis_type}'\n",
    "    path_dir = f'{path_dir}/{prop}'\n",
    "    path_label = f'{path_dir}/{cat}/{label}'\n",
    "    \n",
    "    context_cnt = Counter()\n",
    "    for f in os.listdir(path_label):\n",
    "        full_path = f'{path_label}/{f}'\n",
    "        if full_path.endswith('.csv'):\n",
    "            with open(full_path) as infile:\n",
    "                data = list(csv.DictReader(infile))\n",
    "            for d in data:\n",
    "                context = d['']\n",
    "                diff = float(d['diff'])\n",
    "                if diff > 0:\n",
    "                    context_cnt[context] += 1\n",
    "    return context_cnt\n",
    "    \n",
    "def get_n_concepts_total(prop, cat, model_name):\n",
    "    \n",
    "    analysis_type = 'tfidf-raw-10000/each_target_vs_corpus_per_category'\n",
    "    path_dir = f'../results/{model_name}/{analysis_type}'\n",
    "    path_dir = f'{path_dir}/{prop}'\n",
    "    label = 'pos'\n",
    "    path_pos = f'{path_dir}/{cat}/{label}'\n",
    "    label = 'neg'\n",
    "    path_neg = f'{path_dir}/{cat}/{label}'\n",
    "    \n",
    "    files_pos = [f for f in os.listdir(path_pos) if f.endswith('.csv')]\n",
    "    files_neg = [f for f in os.listdir(path_neg) if f.endswith('.csv')]\n",
    "    \n",
    "    return len(files_pos), len(files_neg)\n",
    "\n",
    "\n",
    "def get_f1_distinctiveness(n_pos, n_neg, total_pos, total_neg):\n",
    "    \n",
    "    tp = n_pos\n",
    "    tn = total_neg - n_neg\n",
    "    fp = n_neg\n",
    "    fn = total_pos - n_pos\n",
    "    \n",
    "    if tp+fp != 0:\n",
    "        p = tp/(tp+fp)\n",
    "    else:\n",
    "        p = 0\n",
    "    if tp+fn != 0:\n",
    "        r = tp/(tp+fn)\n",
    "    else:\n",
    "        r = 0\n",
    "    \n",
    "    if p+r != 0:\n",
    "        f1 = 2 * ((p*r)/(p+r))\n",
    "    else:\n",
    "        f1=0\n",
    "    \n",
    "    return p, r, f1\n",
    "\n",
    "    \n",
    "def aggregate_contexts(prop, cutoff, model_name):\n",
    "    aggregation_name = 'aggregated-tfidf-top20-raw-10000-categories'\n",
    "    path_dir_agg = f'../analysis/{model_name}/{aggregation_name}/{prop}'\n",
    "    os.makedirs(path_dir_agg, exist_ok = True)\n",
    "    \n",
    "    context_cnts_all = Counter()\n",
    "    context_cat_dict = defaultdict(set)\n",
    "\n",
    "    cats = get_categories(prop, model_name)\n",
    "\n",
    "    for cat in cats:\n",
    "        context_cnts_pos = get_context_cnts(prop, cat, 'pos', model_name)\n",
    "        context_cnts_neg = get_context_cnts(prop, cat, 'neg', model_name)\n",
    "        total_pos, total_neg = get_n_concepts_total(prop, cat, model_name)\n",
    "        \n",
    "        context_f1_dict = Counter()\n",
    "        context_score_dict = defaultdict(dict)\n",
    "        \n",
    "        # get distinctiveness\n",
    "        for c, cnt_pos in context_cnts_pos.most_common():\n",
    "            cnt_neg = context_cnts_neg[c]\n",
    "            p, r, f1 = get_f1_distinctiveness(cnt_pos, cnt_neg, total_pos, total_neg)\n",
    "            context_f1_dict[c] = f1\n",
    "            context_score_dict[c] = {'p': p,'r':r, 'f1': f1}\n",
    "        \n",
    "        table = []\n",
    "        for c, f1 in context_f1_dict.most_common():\n",
    "            scores = context_score_dict[c]\n",
    "            d = dict()\n",
    "            d['context'] = c\n",
    "            d.update(scores)\n",
    "            d['n_pos'] = context_cnts_pos[c]\n",
    "            d['total_pos'] = total_pos\n",
    "            d['n_neg'] = context_cnts_neg[c]\n",
    "            d['total_neg'] = total_neg\n",
    "            table.append(d)\n",
    "        \n",
    "        # collect and write to file\n",
    "        f = f'{path_dir_agg}/{cat}.csv'\n",
    "        \n",
    "        header = table[0].keys()\n",
    "        with open(f, 'w') as outfile:\n",
    "            writer = csv.DictWriter(outfile, fieldnames = header)\n",
    "            writer.writeheader()\n",
    "            for d in table:\n",
    "                writer.writerow(d)\n",
    "        \n",
    "\n",
    "                \n",
    "def prepare_annotation(prop, model_name, cutoff=20):\n",
    "    \n",
    "    annotation_name = 'annotation-tfidf-top20-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    os.makedirs(path_dir_annotation, exist_ok = True)\n",
    "    f_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}/annotation.csv'\n",
    "    \n",
    "    # paths aggregated files:\n",
    "    aggregation_name = 'aggregated-tfidf-top20-raw-10000-categories'\n",
    "    path_dir_agg = f'../analysis/{model_name}/{aggregation_name}/{prop}'\n",
    "    \n",
    "    # get categories\n",
    "    cats = get_categories(prop, model_name)\n",
    "    \n",
    "    # collect all contexts and categories \n",
    "    context_cats_dict = defaultdict(set)\n",
    "    \n",
    "    # load top 20 per category\n",
    "    for cat in cats:\n",
    "        path = f'{path_dir_agg}/{cat}.csv'\n",
    "        with open(path) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "        # get top 20\n",
    "        data = data[:cutoff]\n",
    "        contexts = [d['context'] for d in data]\n",
    "        # record categories\n",
    "        for c in contexts:\n",
    "            context_cats_dict[c].add(cat)\n",
    "    \n",
    "    with open(f_annotation, 'w') as outfile:\n",
    "        outfile.write('context,evidence_type,categories\\n')\n",
    "        for c, cats in context_cats_dict.items():\n",
    "            outfile.write(f'{c}, ,{\" \".join(cats)}\\n')\n",
    "\n",
    "def get_properties():\n",
    "    properties = []\n",
    "    for path in os.listdir('../data/aggregated/'):\n",
    "        prop = path.split('.')[0]\n",
    "        if 'female-' not in prop and prop != '':\n",
    "            properties.append(prop)\n",
    "    return properties\n",
    "\n",
    "def get_top_distinctive_contexts(properties, model_name):\n",
    "    aggregation_name = 'aggregated-tfidf-top20-raw-10000-categories'\n",
    "    table = []\n",
    "    for prop in properties:\n",
    "        path_dir_agg = f'../analysis/{model_name}/{aggregation_name}/{prop}'\n",
    "        path = path = f'{path_dir_agg}/all.csv'\n",
    "        # load file containing all concepts and simply load first one\n",
    "        with open(path) as infile:\n",
    "            data = list(csv.DictReader(infile))\n",
    "        # top distinctive context\n",
    "        d = dict()\n",
    "        d['property'] = prop\n",
    "        top_context = data[0]\n",
    "        for k, v in top_context.items():\n",
    "            if k != 'context':\n",
    "                v = float(v)\n",
    "            d[k] = v\n",
    "        table.append(d)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'giga_full_updated'\n",
    "properties = get_properties()\n",
    "cutoff = 20\n",
    "\n",
    "for prop in properties:\n",
    "    aggregate_contexts(prop, cutoff, model_name)\n",
    "    prepare_annotation(prop, model_name, cutoff) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property</th>\n",
       "      <th>context</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f1</th>\n",
       "      <th>n_pos</th>\n",
       "      <th>total_pos</th>\n",
       "      <th>n_neg</th>\n",
       "      <th>total_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>used_in_cooking</td>\n",
       "      <td>add</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.96</td>\n",
       "      <td>93.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>square</td>\n",
       "      <td>built</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.89</td>\n",
       "      <td>70.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>wheels</td>\n",
       "      <td>drove</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.84</td>\n",
       "      <td>51.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sweet</td>\n",
       "      <td>sweet</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.83</td>\n",
       "      <td>65.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cold</td>\n",
       "      <td>variety</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.83</td>\n",
       "      <td>48.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dangerous</td>\n",
       "      <td>killed</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.81</td>\n",
       "      <td>45.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>juicy</td>\n",
       "      <td>pineapple</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.79</td>\n",
       "      <td>58.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>female</td>\n",
       "      <td>herself</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.79</td>\n",
       "      <td>77.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>green</td>\n",
       "      <td>green</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.79</td>\n",
       "      <td>59.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>warm</td>\n",
       "      <td>heavy</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.79</td>\n",
       "      <td>81.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>swim</td>\n",
       "      <td>fish</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.79</td>\n",
       "      <td>53.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>roll</td>\n",
       "      <td>half</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.78</td>\n",
       "      <td>34.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>round</td>\n",
       "      <td>between</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.78</td>\n",
       "      <td>64.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fly</td>\n",
       "      <td>flew</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.77</td>\n",
       "      <td>29.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hot</td>\n",
       "      <td>flame</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.77</td>\n",
       "      <td>62.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>black</td>\n",
       "      <td>fire</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.75</td>\n",
       "      <td>49.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wings</td>\n",
       "      <td>bird</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.74</td>\n",
       "      <td>36.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lay_eggs</td>\n",
       "      <td>eggs</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.74</td>\n",
       "      <td>20.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>made_of_wood</td>\n",
       "      <td>wooden</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.72</td>\n",
       "      <td>46.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>blue</td>\n",
       "      <td>various</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.70</td>\n",
       "      <td>36.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>red</td>\n",
       "      <td>burst</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.68</td>\n",
       "      <td>46.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>yellow</td>\n",
       "      <td>yellow</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.63</td>\n",
       "      <td>22.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           property    context     p     r    f1  n_pos  total_pos  n_neg  \\\n",
       "9   used_in_cooking        add  1.00  0.92  0.96   93.0      101.0    0.0   \n",
       "0            square      built  1.00  0.80  0.89   70.0       87.0    0.0   \n",
       "19           wheels      drove  0.98  0.73  0.84   51.0       70.0    1.0   \n",
       "7             sweet      sweet  0.98  0.71  0.83   65.0       91.0    1.0   \n",
       "17             cold    variety  1.00  0.71  0.83   48.0       68.0    0.0   \n",
       "5         dangerous     killed  0.98  0.69  0.81   45.0       65.0    1.0   \n",
       "10            juicy  pineapple  1.00  0.66  0.79   58.0       88.0    0.0   \n",
       "16           female    herself  0.90  0.71  0.79   77.0      109.0    9.0   \n",
       "11            green      green  0.97  0.66  0.79   59.0       89.0    2.0   \n",
       "1              warm      heavy  0.99  0.65  0.79   81.0      124.0    1.0   \n",
       "21             swim       fish  0.98  0.65  0.79   53.0       81.0    1.0   \n",
       "15             roll       half  0.97  0.65  0.78   34.0       52.0    1.0   \n",
       "18            round    between  0.96  0.66  0.78   64.0       97.0    3.0   \n",
       "4               fly       flew  0.94  0.66  0.77   29.0       44.0    2.0   \n",
       "8               hot      flame  1.00  0.62  0.77   62.0      100.0    0.0   \n",
       "2             black       fire  0.96  0.62  0.75   49.0       79.0    2.0   \n",
       "6             wings       bird  0.97  0.60  0.74   36.0       60.0    1.0   \n",
       "20         lay_eggs       eggs  0.95  0.61  0.74   20.0       33.0    1.0   \n",
       "12     made_of_wood     wooden  0.96  0.57  0.72   46.0       80.0    2.0   \n",
       "13             blue    various  0.82  0.61  0.70   36.0       59.0    8.0   \n",
       "3               red      burst  0.94  0.53  0.68   46.0       87.0    3.0   \n",
       "14           yellow     yellow  0.81  0.51  0.63   22.0       43.0    5.0   \n",
       "\n",
       "    total_neg  \n",
       "9        56.0  \n",
       "0        21.0  \n",
       "19       25.0  \n",
       "7        63.0  \n",
       "17       24.0  \n",
       "5        51.0  \n",
       "10       60.0  \n",
       "16      144.0  \n",
       "11       67.0  \n",
       "1        32.0  \n",
       "21       38.0  \n",
       "15       33.0  \n",
       "18       18.0  \n",
       "4        90.0  \n",
       "8        43.0  \n",
       "2        45.0  \n",
       "6        77.0  \n",
       "20       57.0  \n",
       "12       33.0  \n",
       "13      106.0  \n",
       "3        64.0  \n",
       "14       74.0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get top distinctive contexts per prop\n",
    "\n",
    "model_name = 'giga_full_updated'\n",
    "properties = get_properties()\n",
    "table = get_top_distinctive_contexts(properties, model_name)\n",
    "df = pd.DataFrame(table)\n",
    "df.sort_values('f1', ascending = False).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer old annotations to new files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = get_properties()\n",
    "model_name_current = 'giga_full_updated'\n",
    "model_name_old = 'giga_full'\n",
    "\n",
    "\n",
    "for prop in properties:\n",
    "    # current file:\n",
    "    annotation_name = 'annotation-tfidf-top20-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    f_annotation_new = f'{path_dir_annotation}/annotation.csv'\n",
    "    f_annotation_tr = f'{path_dir_annotation}/annotation-transferred.csv'\n",
    "\n",
    "    # old file:\n",
    "    annotation_name = 'annotation-tfidf-top20-raw-10000'\n",
    "    path_dir_annotation = f'../analysis/{model_name_old}/{annotation_name}/{prop}-pos'\n",
    "    f_annotation_old = f'{path_dir_annotation}/annotation-done.csv'\n",
    "\n",
    "    # load old annotations\n",
    "    context_annotation_dict=dict()\n",
    "    with open(f_annotation_old) as infile:\n",
    "        data = list(csv.DictReader(infile))\n",
    "        for d in data:\n",
    "            c = d['context']\n",
    "            et = d['evidence']\n",
    "            context_annotation_dict[c] = et\n",
    "            #c = d['context']\n",
    "\n",
    "    # load new candidates\n",
    "\n",
    "    with open(f_annotation_new) as infile:\n",
    "        data = list(csv.DictReader(infile))\n",
    "\n",
    "    # fill in old annotations\n",
    "    for d in data:\n",
    "        c = d['context']\n",
    "        if c in context_annotation_dict:\n",
    "            et = context_annotation_dict[c]\n",
    "        else:\n",
    "            et = 'NA'\n",
    "        d['evidence_type'] = et\n",
    "\n",
    "    # write to new file\n",
    "\n",
    "    with open(f_annotation_tr, 'w') as outfile:\n",
    "        writer = csv.DictWriter(outfile, fieldnames = data[0].keys())\n",
    "        writer.writeheader()\n",
    "        for d in data:\n",
    "            writer.writerow(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotation_status(model):\n",
    "    dir_annotations = f'../analysis/{model}/annotation-tfidf-top20-raw-10000-categories'\n",
    "    annotation_dict = defaultdict(set)\n",
    "\n",
    "    for f in os.listdir(dir_annotations):\n",
    "        if  not f.endswith('.csv') and not f.endswith('.ipynb_checkpoints'):\n",
    "            prop = f.split('/')[-1]\n",
    "            full_path = f'{dir_annotations}/{f}'\n",
    "            #print(full_path)\n",
    "            # get categories:\n",
    "            files = os.listdir(full_path)\n",
    "            if 'annotation-done.csv' in files:\n",
    "                annotation_dict['complete'].add(prop)\n",
    "            else:\n",
    "                annotation_dict['incomplete'].add(prop)\n",
    "    return annotation_dict\n",
    "\n",
    "def show_annotation_status(model_name):\n",
    "    annotation_dict = get_annotation_status(model_name)\n",
    "    # same category not annotated:\n",
    "    print('completed:\\n')\n",
    "    for prop in sorted(list(annotation_dict['complete'])):\n",
    "        # cats open:\n",
    "        print(prop)\n",
    "    print()\n",
    "    print('Incomplete:\\n')\n",
    "    for prop in sorted(annotation_dict['incomplete']):\n",
    "        if prop not in annotation_dict['complete']:\n",
    "            print(prop)\n",
    "            \n",
    "\n",
    "def get_evidence_distribution(model_name, prop):\n",
    "    \n",
    "    # current file:\n",
    "    annotation_name = 'annotation-tfidf-top20-raw-10000-categories'\n",
    "    path_dir_annotation = f'../analysis/{model_name}/{annotation_name}/{prop}'\n",
    "    f_annotation = f'{path_dir_annotation}/annotation-done.csv'\n",
    "    \n",
    "    ev_cnts = Counter()\n",
    "    \n",
    "    with open(f_annotation) as infile:\n",
    "        data = list(csv.DictReader(infile))\n",
    "    \n",
    "    total_contexts = len(data)\n",
    "    \n",
    "    for d in data:\n",
    "        et = d['evidence_type']\n",
    "        ev_cnts[et] += 1\n",
    "        if et != 'u':\n",
    "            ev_cnts['all'] += 1\n",
    "    \n",
    "    ev_dict = dict()\n",
    "    for ev, cnt in ev_cnts.items():\n",
    "        ev_dict[ev]  = cnt/total_contexts\n",
    "    return ev_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed:\n",
      "\n",
      "black\n",
      "blue\n",
      "cold\n",
      "dangerous\n",
      "female\n",
      "fly\n",
      "green\n",
      "hot\n",
      "juicy\n",
      "\n",
      "Incomplete:\n",
      "\n",
      "lay_eggs\n",
      "made_of_wood\n",
      "red\n",
      "roll\n",
      "round\n",
      "square\n",
      "sweet\n",
      "swim\n",
      "used_in_cooking\n",
      "warm\n",
      "wheels\n",
      "wings\n",
      "yellow\n"
     ]
    }
   ],
   "source": [
    "model_name = 'giga_full_updated'\n",
    "show_annotation_status(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property</th>\n",
       "      <th>u</th>\n",
       "      <th>all</th>\n",
       "      <th>p</th>\n",
       "      <th>n</th>\n",
       "      <th>l</th>\n",
       "      <th>i</th>\n",
       "      <th>r</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>juicy</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dangerous</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hot</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fly</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>green</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>black</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blue</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    property     u   all     p     n     l     i     r     b\n",
       "7      juicy  0.73  0.27  0.02   NaN   NaN  0.20  0.05   NaN\n",
       "2  dangerous  0.74  0.26  0.01   NaN   NaN  0.09  0.16  0.01\n",
       "6        hot  0.74  0.26  0.01  0.02   NaN  0.10  0.13   NaN\n",
       "3     female  0.75  0.25   NaN   NaN  0.01  0.16  0.01  0.07\n",
       "4        fly  0.82  0.18  0.04  0.01   NaN  0.07  0.06   NaN\n",
       "5      green  0.84  0.16  0.00   NaN   NaN  0.14  0.02   NaN\n",
       "0      black  0.89  0.11  0.00   NaN   NaN  0.10  0.00   NaN\n",
       "1       blue  0.93  0.07  0.00   NaN   NaN  0.05  0.02   NaN"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'giga_full_updated'\n",
    "properties = ['black', 'blue', 'dangerous', 'female', 'fly', 'green', 'hot', 'juicy']\n",
    "\n",
    "table = []\n",
    "for prop in properties:\n",
    "    d = dict()\n",
    "    d['property'] =  prop\n",
    "    d.update(get_evidence_distribution(model_name, prop))\n",
    "    table.append(d)\n",
    "   \n",
    "cols = ['property', 'u', 'all', 'p', 'n', 'l', 'i', 'r', 'b']\n",
    "df = pd.DataFrame(table)\n",
    "df = df.round(2)\n",
    "df[cols].sort_values('all', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
